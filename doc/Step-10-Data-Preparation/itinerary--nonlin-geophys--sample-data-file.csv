"Session or Event Title","Session or Event Abbreviation","Session or Event Type","Session or Event Topic","Session or Event Date","Session or Event Start Time","Session or Event End Time","Session or Event Location","Session or Event Details","Abstract or Placeholder Title","Abstract Final ID","Abstract or Placeholder Start Time","Abstract or Placeholder End Time","Abstract Presenter Name","Abstract Authors","Institutions All","Abstract Status","Abstract Body","Session Abstract Sort Order"
"NG13A. Complex Networks in Geosciences I Posters","NG13A","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Horton and Tokunaga self-similarity for multiplicative coalescent: numerical approach","NG13A-1514","1:40 PM","1:40 PM","A.   Tejedor*","A.   Tejedor*; I.   Zaliapin","University of Nevada, Reno","Sessioned","Body: 	The Horton and Tokunaga branching laws provide a convenient and powerful framework for studying self-similarity in branching structures represented by random tree graphs. The Horton self-similarity, described by the Horton exponent R, is a weaker property that addresses the principal branching in a tree; it is a counterpart of the power-law size distribution for elements of a branching system. The stronger Tokunaga self-similarity, parameterized by a positive pair (a, c), addresses so-called side branching and implies that different hierarchical levels of a tree have the same statistical structure. The Horton and Tokunaga self-similarity have been empirically established in numerous observed and modeled systems and proven for the following paradigmatic models: (i) the critical binary Galton–Watson branching process with finite progeny, also known in hydrology as Shreve’s random topology model, (ii) level-set tree representation of white noise and (iii) random walk, and (iv) Kingman’s coalescent process. This work addresses the problem of testing the Tokunaga self-similarity hypothesis and statistical estimation of Horton and Tokunaga parameters in a single finite tree. We use critical binary Galton-Watson trees to illustrate and quantify finite-size effects that influence estimation as well as compare among estimation techniques based on regression and maximum likelihood approaches. Next, we apply the developed testing and estimation procedure to study the multiplicative coalescent process. The results of our numerical experiments suggest that the multiplicative coalescent is Tokunaga self-similar with parameters (a, c) = (1, 2), the same as that for the critical binary Galton-Watson process and level-set tree representation of a random walk. \n","1"
"NG13A. Complex Networks in Geosciences I Posters","NG13A","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","A graph theoretic approach to global earthquake sequencing: A Markov chain model","NG13A-1515","1:40 PM","1:40 PM","K.   Vasudevan*","K.   Vasudevan*; M. S.  Cavers","University of Calgary; University of Calgary","Sessioned","Body: We construct a directed graph to represent a Markov chain of global earthquake sequences and analyze the statistics of transition probabilities linked to earthquake zones.   For earthquake zonation, we consider the simplified plate boundary template of Kagan, Bird, and Jackson (KBJ template, 2010).   We demonstrate the applicability of the directed graph approach to hazard-related forecasting using some of the properties of graphs that represent the finite Markov chain.  We extend the present study to consider Bird’s 52-plate zonation (2003) describing the global earthquakes at and within plate boundaries to gain further insight into the usefulness of digraphs corresponding to a Markov chain model.\n","2"
"NG13A. Complex Networks in Geosciences I Posters","NG13A","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Interpretation of link fluctuations in climate networks during El Niño periods","NG13A-1516","1:40 PM","1:40 PM","E. A.  Martin*","E. A.  Martin*; M.   Paczuski; J.   Davidsen","University of Calgary","Sessioned","Body: Recent work has shown that the topologies of functional climate networks are sensitive to El Ni\~{n}o events. One important interpretation of the findings was that parts of the globe act in correlated relationships which become weaker, on average, during El Ni\~{n}o periods (this was shown using monthly averaged data where no time lag is required, and with daily averaged data where time lags were utilized).  In contrast to this, we show that El Ni\~{n}o periods actually exhibit higher correlations then ``Normal'' climate conditions, while still having lower correlations then La Ni\~{n}a periods. We also find that previous analyses show sensitivities to parameters such as time lags and the precise definition of El Ni\~{n}o events.\n","3"
"NG13A. Complex Networks in Geosciences I Posters","NG13A","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","How rivers split","NG13A-1517","1:40 PM","1:40 PM","H. F.  Seybold*","H. F.  Seybold*; R.   Yi; O.   Devauchelle; A.   Petroff; D.   Rothman","MIT;  Institut de Physique du Globe; Rockefeller University","Sessioned","Body: River networks have fascinated mankind for centuries.  They exhibit a striking geometry with similar shapes repeating on all scales.  Yet, how these networks form and create these geometries remains elusive.Recently we have shown that channels fed by subsurface flow split at a characteristic angle of 2π/5 unambiguously consistent with our field measurements in a seepage network on the Florida Panhandle (Fig.1). Our theory is based only on the simple hypothesis that the channels grow in the direction at which the ground water enters the spring and classical solutions of subsurface hydrology.Here we apply our analysis to the ramification of large drainage basins and extend our theory to include slope effects.  Using high resolution stream networks from the National Hydrography Dataset (NHD), we scrutinize our hypothesis in arbitrary channel networks and investigate the branching angle dependence on Horton-Strahler order and the maturity of the streams.\n","4"
"NG13A. Complex Networks in Geosciences I Posters","NG13A","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Evaluation of Radial Basis Function Neural Networks in Subsurface Seismic Characterization","NG13A-1518","1:40 PM","1:40 PM","T.   Zhao*","T.   Zhao*; K.   Ramachandran","The University of Tulsa","Sessioned","Body: Neural network provides a mathematical non-linear mapping technique that has been employed in many scientific and engineering studies. A radial basis function (RBF) neural network is a kind of supervised non-linear neural network with two main advantages: mathematically simple and computationally cheap. The structure of a typical RBF network has three parts: an input layer, an output layer and a hidden layer. In this study we are interested in the performance of a RBF neural network with respect to hidden layers and arrive at an optimal structure for a RBF network with a fixed number of nodes. Subsurface seismic characterization requires building a relationship (commonly non-linear) between seismic attributes and rock/fluid properties. With such a relationship, the rock/fluid properties computed from well logs can be extended to interwell points. Neural networks are powerful tools to obtain this non-linear relationship. Well logs are separated into two groups, a training group and a test group. Optimized seismic attributes and logs from training group act as inputs and outputs, respectively, to train the RBF network; then the network is deployed to the whole data set and the misfit between the calculated results and the test group is obtained. This overall misfit is utilized to evaluate the performance of networks with different structures. The data we use in this study is a part of the Boonsville 3-D seismic data contributed by the Bureau of Economic Geology of the University of Texas at Austin. Since there are limited numbers of wells with sonic curves, a log prediction using RBF networks is used. A typical single-layer RBF network is used for simplicity. An impedance inversion is applied to constrain the characterization process.\n","5"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Co-evolution of perennial stream and water balance under climate control","NG13B-1519","1:40 PM","1:40 PM","D.   Wang*","D.   Wang*; L.   Wu","University of Central Florida","Sessioned","Body: Streams are categorized into perennial and temporal streams based on flow durations.  Perennial stream is the basic network, and temporal stream (ephemeral or intermittent) is the expanded network.  Connection between perennial stream and runoff generation at the mean annual scale exists since one of the hydrologic functions of perennial stream is to deliver runoff.  The partitioning of precipitation into runoff and evaporation at the mean annual scale, on the first order, is represented by the Budyko hypothesis which quantifies the ratio of evaporation to precipitation (E/P) as a function of climate aridity index (Ep/P, ratio of potential evaporation to precipitation).  Perennial stream densities for 185 watersheds in the United States are computed based on the high resolution national hydrography dataset (NHD).  It is found that pernnial stream density strongly depends on Ep/P.  Similarity between normalized perennial stream density and the ratio of base flow to precipitation demonstrates the co-evolution of perennial stream network and water balance.\n","1"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Linking structural and functional connectivity in a simple runoff-runon model over soils with heterogeneous infiltrability","NG13B-1520","1:40 PM","1:40 PM","M.   Harel*","M.   Harel*; E.   Mouche","LSCE","Sessioned","Body: Runoff production on a hillslope during a rainfall event may be simplified as follows. Given a soil of constant infiltrability I, which is the maximum amount of water that the soil can infiltrate, and a constant rainfall intensity R, runoff is observed wherever R is greater than I. The infiltration rate equals the infiltrability where runoff is produced, R otherwise. When ponding time, topography, and overall spatial and temporal variations of physical parameters, such as R and I, are neglected, the runoff equation remains simple.In this study, we consider soils of spatially variable infiltrability. As runoff can re-infiltrate on down-slope areas of higher infiltrabilities (runon process), the resulting process is highly non-linear. The stationary runoff equation is:Qn+1 = max (Qn + (R - In)*Δx , 0)where Qn is the runoff arriving on pixel n of size Δx [L2/T], R and In the rainfall intensity and infiltrability on that same pixel [L/T]. The non-linearity is due to the dependence of infiltration on R and Qn, that is runon. This re-infiltration process generates patterns of runoff along the slope, patterns that organise and connect differently to each other depending on the rainfall intensity and the nature of the soil heterogeneity. In order to characterize the runoff patterns and their connectivity, we use the connectivity function defined by Allard (1993) in Geostatistics.Our aim is to assess, in a stochastic framework, the runoff organization on 1D and 2D slopes with random infiltrabilities (log-normal, exponential and bimodal distributions) by means of numerical simulations. Firstly, we show how runoff is produced and organized in patterns along a 2D slope according to the infiltrability distribution. We specifically illustrate and discuss the link between the statistical nature of the infiltrability and that of the flow-rate, with a special focus on the relations between the connectivities of both fields: the structural connectivity (infiltrability patterns) and the functional connectivity (runoff patterns). In a second step, we demonstrate how, on a 1D geometry defined by different uncorrelated infiltrability distributions, these interactions between infiltrability and resulting runoff field can be quantified by the Queueing Theory.\n","2"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","The application of frequency trend attribute analysis to stratigraphic division and sand body correlation","NG13B-1521","1:40 PM","1:40 PM","J.   Xu*","J.   Xu*","China University of Geosciences","Sessioned","Body: This paper focuses on improving the accuracy of sequence cycles during automatic division and correlation, and also on solving the problems like difficult division, subjectivity and multiple solutions for high frequency sequence. According to the outcrop studies and analyses of the overlay series, the cycle structures of the layers convert to simulated signals by numerical method. Based on the signal characteristics, the method of frequency trend attribute analysis was proposed. By using this method, frequency trend lines can be extracted from the simulation signals (Fig.1). The frequency trend lines indicate the overlay series, cycle structures and the changes of both the sedimentary environment and base level. And the precise stratigraphic division and isochronous comparison were realized automatically by using the method (Fig.2). By analyzing the logging data of the well, the validity of this method has been verified by analyzing the well log data.\n","3"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Activator-inhibitor systems on heterogeneous ecological networks","NG13B-1522","1:40 PM","1:40 PM","C.   Nicolaides*","C.   Nicolaides*; L.   Cueto-Felgueroso; R.   Juanes","MIT","Sessioned","Body: The consideration of activator-inhibitor systems as complex networks has broadened our knowledge of non-equilibrium reaction-diffusion processes in heterogeneous systems. For example, the Turing mechanism represents a classical model for the formation of self-organized spatial structures in non-equilibrium activator-inhibitor systems. The study of Turing patterns in networks with heterogeneous connectivity has revealed that, contrary to other models and systems, the segregation process takes place mainly in vertices of low degree. In this paper, we study the formation of vegetation patterns in semiarid ecosystems from the perspective of a heterogeneous interacting ecological network. The structure of ecological networks yields fundamental insight into the ecosystem self-organization. Using simple rules for the short-range activation and global inhibition, we reconstruct the observed power-law distribution of vegetation patch size that has been observed in semiarid ecosystems like the Kalahari transect.\n","4"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Utilizing observations of vegetation patterns to infer ecosystem parameters and test model predictions","NG13B-1523","1:40 PM","1:40 PM","G.   Penny*","G.   Penny*; K. E.  Daniels; S. E.  Thompson","University of California, Berkeley; North Carolina State University","Sessioned","Body: Periodic vegetation patterns arise globally in arid and semi-arid environments, and are believed to indicate competing positive and negative feedbacks between resource availability and plant uptake at different length scales. The patterns have become the object of two separate research themes, one focusing on observation of ecosystem properties and vegetation morphology, and another focusing on the development of theoretical models and descriptions of pattern behavior. Given the growing body of work in both directions, there is a compelling need to unify both strands of research by bringing together observations of large-scale pattern morphology with predictions made by various models. Previous attempts have employed spectral analysis on pattern images and inverse modeling on one-dimensional transects of patterns images, yet have not made a concerted effort to rigorously confront predictions with observational data in two dimensions. This study makes the first steps towards unification, utilizing high resolution landscape-scale images of vegetation patterns over multiple years at five different locations, including Niger, Central Mexico, Baja California, Texas, and Australia. Initial analyses of the observed patterns reveal considerable departures from the idealized morphologies predicted by models. Pattern wavelengths, while clustered around a local average, vary through space and are frequently altered by pattern defects such as missing or broken bands. While often locally homogeneous, pattern orientation also varies through space, allowing the correlations between landscape features and changes in local pattern morphology to be explored. Stationarity of the pattern can then be examined by comparing temporal changes in morphology with local climatic fluctuations. Ultimately, by identifying homogeneous regions of coherent pattern, inversion approaches can be applied to infer model parameters and build links between observable pattern and landscape features and the inferred ecosystem and hydrological properties.\n","5"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Self-organized geodynamics of karst limestone landscapes and coupled terra rossa/bauxite formation","NG13B-1524","1:40 PM","1:40 PM","E.   Merino*","E.   Merino*; Y.   Wang; A.   Banerjee","Indiana University; Sandia National Laboratories; Indian Statistical Institute","Sessioned","Body: Why do flat limestones overlain by terra rossa or bauxite systematically adopt so-called karst geomorphology, which consists of sets of roughly regularly spaced wormholes, or funnels, or sinkholes, or tower karst?  The idea that the funnels and sinkholes are located at the intersections of preexisting sets of subvertical fractures is untenable.   New field and petrographic evidence (Merino & Banerjee, J. Geology, 2008) revealed that, rather than ‘residual’ or ‘detrital’ (the only options that have been on the table for decades), the terra rossa/bauxite clays and Al- and Fe-oxyhydroxides grow authigenically at the base of the terra rossa, replacing  the underlying limestone at a generally downward-moving reaction front several centimeters thick.  The clay-for-limestone replacement, which preserves solid volume (because it takes place by clay-growth-driven pressure solution of calcite), releases H+ ions.  These dissolve more calcite, generating considerable leached porosity in a narrow zone that travels with the replacement front.   We proposed (Merino & Banerjee, J. Geology, 2008) that the moving leached-porosity maximum created at the front could trigger the reactive-infiltration instability (Chadam et al, IMA J. Appl. Math., 1986), causing the replacement-and-leaching reaction front to become regularly fingered, with the fingers jumping in scale to funnels, these to sinks, and these, when deep enough and merged together laterally, to tower karst.  This new geodynamics  would account both for the world-wide association of terra rossa and bauxite with karst limestones, and for the stunning, self-organized geomorphology of karst itself.  We are testing these ideas through linear stability analysis of a simplified reaction-transport system of equations and through numerical solution of the full non-linear system of reaction-transport equations applicable, including aqueous speciation.  Preliminary calculations (Banerjee & Merino, J. Geology, 2011) suggest that the replacement-and-leaching front is self-accelerating.  The linear stability analysis may help to delineate climatic and hydrologic conditions for the development of spatial patterns of karst landscape and to predict the spacing of the patterns.\n","6"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","The effect of wettability on capillary fracturing in granular media","NG13B-1525","1:40 PM","1:40 PM","M.   Trojer*","M.   Trojer*; M.   Szulczewski; R.   Juanes","Massachusetts Institute of Technology; Montanuniversitaet Leoben","Sessioned","Body: During multiphase flow in a granular medium, capillary pressures can overcome cohesive forces between the grains and cause grain displacements that macroscopically resemble fracture patterns. These patterns were recently studied in experiments of air displacing water in a thin bed of glass beads, for which air is a strongly non-wetting fluid (Holtzman et al. 2012). The experiments showed that the transition from viscous fingering and capillary fingering to capillary fracturing could be predicted by a single dimensionless number called the fracturing number, which is the ratio of the capillary forces that promote grain displacements to the frictional forces that resist displacements. Here, we extend those experiments to study exclusively how the wettability of the invading fluid affects fracturing by visually observing the morphology of the pattern. As in the previous work, we inject a less viscous fluid into a thin bed of glass beads saturated with a more viscous fluid. However, we now vary the fluids to change the wettability of the invading fluid from perfectly non-wetting to wetting. We hypothesize that the emergence of fracturing can be predicted by a modified fracturing number that includes the contact angle to account for the effect of wettability on the capillary pressure. Since the contact angle is a function of the capillary number, we expect the emergence of fracturing will depend on the capillary number when the invading fluid is partially wetting.\n","7"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Cracking dynamics and morphology of desiccating clay overlying a granular substrate","NG13B-1526","1:40 PM","1:40 PM","K.   DeCarlo*","K.   DeCarlo*; N.   Shokri","Boston University","Sessioned","Body: Desiccation cracks are a common phenomenon present in many environmental, hydrological and engineering applications, including soil physics, where they act as preferential pathways for transport processes; and geotechnical engineering, where they compromise the structural stability of buildings and waste containment facilities.  Thus better understanding of its physics and dynamics has many applications.  We conducted a comprehensive investigation to delineate the effects of a discrete and discontinuous substrate on the cracking dynamics, patterns and morphology of an overlying thin layer of clay.  Square glass containers (40x40x2.5 cm3) packed with a thin layer of kaolinite clay overlying seven types of a silica sand substrate differing in particle size distribution were used in our laboratory experiments.  Both layers were saturated with water.  The container was mounted on a digital balance to record the evaporation rate, and an automatic imaging system was used to record the general dynamics and patterns of cracking on the evaporating surface with a 5 second time interval.  Images were then used to quantify crack dynamics, propagation velocities and patterns as a function of substrate texture.  Results indicate an increasing crack density and smaller characteristic crack length with decreasing substrate particle size, attributed to the decreased coefficient of friction of the underlying wet sand with increasing particle size.  Additionally, our results suggest that the onset and propagation of the earliest cracks are closely related to the saturation and stress gradients of the desiccating clay surface, with initially high velocities that decay to small but non-zero values as they approach the saturated zones of the clay.  The majority of macroscale cracking in all cases occurred within the early stages of the evaporation process.  Obtained results also show that cracking duration is inversely related to the standard deviation of the particle size of each substrate, with cracking duration increasing as particle size standard deviation decreases.   Finally, the fractal characteristics and density correlation function of the final crack patterns were analyzed.  The fractal dimension was nearly constant in all cases and equal to 1.54.  A crossover length scale was identified that separates the fractal regime from the uniform crack density regime.  For length scales larger than the crossover length scale, the density correlation function asymptotically approaches the crack density of the clay surface in all cases.  Our results provide new insights regarding the formation, patterns, dynamics and scaling characteristics of desiccation cracks.  \n","8"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Salinity effects on the dynamics and patterns of desiccation cracks","NG13B-1527","1:40 PM","1:40 PM","N.   Shokri*","N.   Shokri*; P.   Zhou","Boston University; Ecole des Ponts ParisTech","Sessioned","Body: Cracking arising from desiccation is a ubiquitous phenomenon encountered in various industrial and geo-environmental applications including drying of clayey soil, cement, ceramics, gels, and many more colloidal suspensions. Presence of cracks in muddy sediments modifies the characteristics of the medium such as pore structure, porosity, and permeability which in turn influence various flow and transport processes. Thus it remains a topic of great interest in many disciplines to describe the dynamics of desiccation cracking under various boundary conditions. To this end, we conducted a comprehensive study to investigate effects of NaCl concentrations on cracking dynamics and patterns during desiccation of Bentonite. Mixtures of Bentonite and NaCl solutions were prepared with NaCl concentration varying from 2 to 10 percent in 0.5 percent increment (totally 17 configurations). The slurry was placed in a Petri dish mounted on a digital balance to record the evaporation dynamics. The atmospheric conditions were kept constant using an environmental chamber. An automatic camera was used to record the dynamics of macro-cracks (mm scale) at the surface of desiccating clay each minute. The obtained results illustrate the significant effects of salt concentration on the initiation, propagation, morphology and general dynamics of macro-cracks. We found that higher salt concentrations results in larger macro cracks’ lengths attributed to the effects of NaCl on compressing the electric double layer of particles at increasing electrolyte concentrations which reduce considerably the repulsive forces among the particles and causing instability of the slurry and flocculation of the colloidal particles. Rheological measurements by means of a stress controlled rheometer revealed that the yield stress of the slurry decreases as NaCl concentration increases which may indicate aggregation of larger units in the slurry as a result of flocculation causing larger cracks’ lengths due to drying. At the end of each round of the experiment, a detailed visualization was conducted using Scanning Electron Microscopy to investigate the patterns and morphology of cracks at micro-scale as influenced by the salt concentration. Our results provide new insights and finding about the effects of salt concentrations on desiccation cracks at different scales ranging from a few mm to few microns.\n","9"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Evolving fracture patterns: columnar joints, mud cracks, and polygonal terrain","NG13B-1528","1:40 PM","1:40 PM","L.   Goehring*","L.   Goehring*","MPI Dynamics and Self-Organization","Sessioned","Body: Contraction cracks can form captivating patterns, such as the artistic craquelure sometimes found in pottery glazes, to the cracks in dried mud, or the polygonal networks covering the polar regions of Earth and Mars.  Two types are frequently encountered: those with irregular rectilinear patterns, such as that formed by an homogeneous slurry when dried (or cooled) uniformly, and more regular hexagonal patterns, such as those typified by columnar joints. Once cracks start to form in a thin contracting layer, they will sequentially break the layer into smaller and smaller pieces.  A rectilinear crack pattern encodes information about the order of cracks, as later cracks tend to intersect with earlier cracks at right angles.  In this manner they relieve the stresses perpendicular to the pre-existing crack.   In a hexagonal pattern, in contrast, the angles between all cracks at a vertex are near 120°.  In this presentation it will be shown how both types of pattern can arise from identical forces, and that a rectilinear, T-junction dominated pattern will develop into to a hexagonal pattern, with Y-junctions, if allowed to. Such an evolution can be explained as the result of three conditions: (1) if cracks advance through space, or heal and recur, that the previous positions of a crack tip acts as a line of weakness, guiding the next iteration of cracking; (2) that the order of opening of cracks can change in each iteration; and (3) that crack tips curve to maximise the local strain energy release rate.  The ordering of crack patterns are seen in a number of systems: columnar joints in starch and lava; desiccation cracks in clays that are repeatedly wetted and dried; cracks in eroding gypsum-cemented sand layers; and the cracks in permafrost known as polygonal terrain.  These patterns will each be briefly explored, in turn, and shown to obey the above principles of crack pattern evolution. \n","10"
"NG13B. Pattern Formation in Earth System Sciences I Posters","NG13B","Poster","Nonlinear Geophysics (NG)","03-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Length scale of viscous fingers in multiphase flow through porous media","NG13B-1529","1:40 PM","1:40 PM","L.   Cueto-Felgueroso*","L.   Cueto-Felgueroso*; R.   Juanes","MIT","Sessioned","Body: When a less viscous fluid displaces a more viscous one in a porous medium, the displacement front is unstable, and the hydrodynamic instability that ensues is referred to as viscous fingering. The displacement pattern is characterized by branching structures, with an intrinsic length scale that depends on the fluid properties, essentially viscosity and surface tension between the fluids, as well as the structure of the porous space, the wetting properties of the system, and the injection rate. Here we present a continuum model of two-phase flow in porous media that reproduces the experimental patterns of displacement. We describe the properties of our model in simple quasi-1D displacements, and in unstable two-dimensional flow. Using our macroscopic model, we discuss the scaling properties of the intrinsic finger length scale.\n","11"
"NG14A. Complex Networks in Geosciences II","NG14A","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","A new dynamical mechanism for major climate shifts <i>(Invited)</i>","NG14A-01","4:00 PM","4:15 PM","A.   Tsonis*","A.   Tsonis*","University of Wisconsin-Milwaukee","Sessioned","Body: We construct a network of observed climate modes in the period 1900–2000 and investigate their collective behavior. The results indicate that this network synchronized several times in this period. If when the network enters synchronization the coupling strength between the modes is increasing then at some strength threshold the synchronous state is destroyed, after which a new climate state emerged. These shifts are associated with significant changes in global temperature trend and in ENSO variability. The latest such event in the 20th century is known as the great climate shift of the 1970s. Extending this analysis in the 21st century confirms that another synchronization of these modes, associated with an increase in coupling occurred in 2001/02. This suggests that a break in the global mean temperature trend from the consistent warming over the 1976/77–2001/02 period may have occurred. We also find the evidence for such type of behavior in three forced and unforced climate simulations using state-of-the-art models. This is the first time that this mechanism, which appears consistent with the theory of synchronized chaos, is discovered in a physical system of the size and complexity of the climate system.\n","1"
"NG14A. Complex Networks in Geosciences II","NG14A","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Extending generalized Horton laws to test embedding algorithms for topologic river networks <i>(Invited)</i>","NG14A-02","4:15 PM","4:30 PM","R.   Mantilla*","R.   Mantilla*","The University of Iowa-IIHR","Sessioned","Body: River networks in the landscape can be described as topologic rooted trees embedded in a three-dimensional surface.  We examine the problem of embedding topologic binary rooted trees (BRTs) by investigating two space-filling embedding procedures: Top-Down, previously developed in the context of random self-similar networks (RSNs), and Bottom-Up, a new procedure developed here.  The concept of generalized Horton laws is extended to interior sub catchments and create a new set of scaling laws that are used to test the embedding algorithms.  Two embedding strategies are analyzed with respect to the scaling properties of the distribution of accumulated areas and network magnitude for complete order streams.  One important finding is that the presence or absence of the equality of distributions given by the generalized Horton laws is a powerful test to diagnose river network models that describe the topology/geometry of natural drainage systems.  We present some examples of applying the embedding algorithms to self similar trees (SSTs) and to RSNs.  A technique is presented to map the resulting tiled region into a three-dimensional surface that corresponds to a landscape drained by the chosen network. The results presented are a significant first step toward the goal of creating realistic embedded topologic trees, which are also required for the study of peak flow scaling in river networks in the presence of spatially variable rainfall and flood-generating processes.\n","2"
"NG14A. Complex Networks in Geosciences II","NG14A","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Cryosphere (C)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Geodesy (G)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Paleoceanography and Paleoclimatology (PP)Planetary Sciences (P)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Analytical results for time-dependent cumulative damage in a localized load sharing fibre bundle model with additional ageing","NG14A-03","4:30 PM","4:45 PM","S.   Lennartz-Sassinek*","S.   Lennartz-Sassinek*; Z.   Danku; F.   Kun; I. G.  Main; M.   Zaiser","University of Edinburgh; University of Edinburgh; University of Debrecen","Sessioned","Body: Damage growth in earth materials is a complex process which is of interest in many fields of science. One of the most fundamental models is the fibre bundle model which consists of a network of parallel fibres. One distinguishes between models with localized load sharing (LLS) and models with equal load sharing (ELS). While the models with ELS can easily be treated by mean field theory, the behaviour of models with LLS is usually more complicated. Here, we consider a fibre bundle model with LLS where, in addition, we introduce a time scale by incorporating a time dependent ageing of the fibres due to the accumulation of damage driven by the locally acting stress in a chemically active environment. If the accumulated damage exceeds a random threshold, the fibres will fail. The non-trivial time dependence of the cumulative damage in the system (number of broken fibres) can be attributed to different mechanisms that dominate at different time scales. We include this information into an analytical description of the damage accumulation process and show that the analytical description is in agreement with the numerical results. \n","3"
"NG14B. Pattern Formation in Earth System Sciences II","NG14B","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Pattern formation in poroelastic systems","NG14B-01","4:45 PM","5:00 PM","C. W.  MacMinn*","C. W.  MacMinn*; J. S.  Wettlaufer; E. R.  Dufresne","Yale University","Sessioned","Body: Poroelastic effects, where fluid flow through a porous solid is coupled to elastic deformation of the solid, play an important role in many natural and engineering systems. In geophysics, poroelasticity has been studied intensely in the context of pressure buildup and dissipation during fluid injection or extraction, such as in carbon dioxide sequestration or oil recovery.Due to the highly nonlinear nature of the fluid-solid coupling in these systems, instability-driven pattern formation is both likely and very poorly understood. Here, we use laboratory experiments to explore pattern formation in a model poroelastic system. We study the paradigmatic problem of fluid injection into a quasi-two-dimensional porous medium, and we show that poroelasticity results in a nonlocal coupling between the fluid and the solid that drives pattern formation in even relatively simple fluid flows.\n","1"
"NG14B. Pattern Formation in Earth System Sciences II","NG14B","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Fingering and fracturing in granular media <i>(Invited)</i>","NG14B-02","5:00 PM","5:15 PM","R.   Juanes*","R.   Juanes*; R.   Holtzman; M.   Szulczewski","MIT; Hebrew University of Jerusalem","Sessioned","Body: Here, we describe the phenomenon of capillary fracturing in granular media. We study the displacement of immiscible fluids in deformable, non-cohesive granular media. Experimentally, we inject air into a thin bed of water-saturated glass beads and observe the invasion morphology.  The control parameters are the injection rate, the bead size, and the confining stress.  We identify three invasion regimes: capillary fingering, viscous fingering, and capillary fracturing, where capillary forces overcome frictional resistance and induce the opening of conduits. We derive two dimensionless numbers that govern the transition among the different regimes: a modified capillary number and a fracturing number.  The experiments and analysis predict the emergence of fracturing in fine-grained media under low confining stress, a phenomenon that likely plays a fundamental role in many natural processes such as primary oil migration, methane venting from lake sediments, and the formation of desiccation cracks.\nURL : http://juanesgroup.mit.edu\n","2"
"NG14B. Pattern Formation in Earth System Sciences II","NG14B","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Multiple stable states and pattern formation in tidal environments <i>(Invited)</i>","NG14B-03","5:15 PM","5:30 PM","M.   Marani*","M.   Marani*","Duke University; University of Padova","Sessioned","Body: Tidal environments display typical and widely occurring patterns on several scales. At the large scale, characteristic tidal morphological structures can be identified: subtidal areas, which are permanently flooded, tidal flats, usually non-vegetated expanses located between mean low water level and mean sea level, and tidal marshes, vegetated landforms located between mean sea level and mean high water level. At a smaller scale, marshes display zonation patterns, patches of nearly homogeneous vegetation species characterized by very sharp transitions in species composition and in the associated soil elevation. This contribution describes modelling and observational results which identify a common mechanism for the emergence of bio-geomorphic patterns in tidal environments. Our analyses show that the coupled dynamics of inorganic sediment transport and local biogenic soil formation leads to multiple stable states. Such states correspond to distinct geomorphic structures at the large scale (subtidal platforms, tidal flats, and marshes) and to zonation patterns at the marsh scale. In both cases the interaction between biotic and biotic processes turns out to be crucial for the emergence of the observed patterns.\n","3"
"NG14B. Pattern Formation in Earth System Sciences II","NG14B","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Instabilities in biofilms: The Kinneyia Fossil <i>(Invited)</i>","NG14B-04","5:30 PM","5:45 PM","K. R.  Thomas*","K. R.  Thomas*; L.   Goehring; H.   Porada; R.   Wittig; S.   Herminghaus","Max-Planck Institute for Dynamics and Self-Organisation; University Goettingen","Sessioned","Body: Kinneyia structures are a wrinkle-type fossil pattern most often observed in ancient siliclastic sediment surfaces. Characterised by millimetre-scale ripples with flat-topped crests, these fossils are generally found in areas that were formally littoral habitats. Thin-section observations indicate that Kinneyia formed in surfaces covered by ancient microbial mats. However, to date there has been no conclusive explanation as to the process involved in the formation of these fossils.We propose that the key mechanism involved in the formation of the Kinneyia pattern is a Kelvin-Helmholtz-type instability induced in a viscoelastic film under flowing water. A ripple corrugation is spontaneously induced in the film, which grows in amplitude over time.  Such a mechanism is expected to result in a ripple instability with a wavelength proportional to the thickness of the film. Experiments carried out using viscoelastic models microbial mats confirm this prediction, showing a wavelength roughly three times the thickness of the film. The behaviour is independent on the viscoelastic properties of the film. This model corresponds well with the fossil records, which show a reduced wavelength at the boundaries of the fossilised structures where the mat is expected to have been thinner. Fossils were collected from two ancient shallow sea bed sites in Namibia from the terminal Proterozoic period. The fossils are seen to overlay a storm deposit of 15-30cm in thickness. The ripples form on top of this deposit in the veneer, which sedimented after the storm event. Analysis of the shape of the fossilised patterns indicates a similar relationship between the wavelength and amplitude of the ripples to that observed experimentally. A strong directional dependence of the ripples is also observed.\n","4"
"NG14B. Pattern Formation in Earth System Sciences II","NG14B","Oral","Nonlinear Geophysics (NG)","03-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Earth and Planetary Surface Processes (EP)Hydrology (H)","Experiments on the rippling instability of icicles <i>(Invited)</i>","NG14B-05","5:45 PM","6:00 PM","S. W.  Morris*","S. W.  Morris*; A.   Chen","University of Toronto","Sessioned","Body: Icicles form when cool water drips from an overhanging support into air whose temperature is below freezing.  The latent heat produced is transferred into the surrounding air via a thin film of water flowing over the ice surface.  Predicting the evolving morphology of an icicle is a complex free-boundary growth problem. Theory suggests that overall, icicles have self-similar shapes which are related to those of stalactites.  The ice-water interface can also become unstable to form ripple patterns on the surface of icicles. We conducted controlled icicle experiments and analyzed the evolution of the rippling instability as functions of the ambient temperature, feed water supply rate, air motion and water purity. The rippling instability is tied to the purity of the water.  Adding surfactants to pure feed water does not produce ripples.  Ripples appear when small concentrations of salt are added to the feed water.  The ripple amplitudes grow with salt concentration.\n","5"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","On the long-term variability of Jupiter and Saturn zonal winds","NG21A-01","8:00 AM","8:15 AM","A.   Sanchez-Lavega*","A.   Sanchez-Lavega*; E.   Garcia-Melendo; R.   Hueso; N.   Barrado-Izagirre; J.   Legarreta; J. F.  Rojas","Universidad Pais Vasco UPV/EHU; Fundacio Observatori Esteve DuranPV/EHU","Sessioned","Body: We present an analysis of the long-term variability of Jupiter and Saturn zonal wind profiles at their upper cloud level as retrieved from cloud motion tracking on images obtained at ground-based observatories and with different spacecraft missions since 1979, encompassing about three Jovian and one Saturn years. We study the sensitivity and variability of the zonal wind profile in both planets to major planetary-scale disturbances and to seasonal forcing. We finally discuss the implications that these results have for current model efforts to explain the global tropospheric circulation in these planets.  Acknowledgements: This work has been funded by Spanish MICIIN AYA2009-10701 with FEDER support, Grupos Gobierno Vasco IT-464-07 and UPV/EHU UFI11/55.   [1]	Sánchez-Lavega A., et al., Icarus, 147, 405-420 (2000). [2]	García-Melendo E., Sánchez LavegaA., Icarus, 152, 316-330 (2001)[3]	Sánchez-Lavega A., et al., Nature, 423, 623-625 (2003).[4]	García-Melendo E., et al., Geophysical Research Letters, 37, L22204 (2010).\n","1"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Generation of Multiple Jets and Equatorial Superrotation in the Atmospheres of Gas Giant Planets <i>(Invited)</i>","NG21A-02","8:15 AM","8:30 AM","J.   Liu*","J.   Liu*; T.   Schneider","Caltech","Sessioned","Body: The atmospheres of gas giant planets in our solar system (Jupiter and Saturn) exhibit alternating prograde (eastward) and retrograde (westward) jets of different speeds and widths, with an equatorial jet that is prograde (superrotating). The jets are variously thought to be driven by differential radiative heating of the upper atmosphere or by intrinsic heat fluxes emanating from the deep interior. However, existing models do not reproduce the flow configuration and thermal structure observed in the atmospheres of Jupiter and Saturn.  Here a three-dimensional general circulation model is used to show that the difficulties in accounting for Jupiter and Saturn's jets and thermal structure resolve if the effects of differential radiative heating and intrinsic heat fluxes are considered together, and if upper-tropospheric dynamics are linked to a magnetohydrodynamic (MHD) drag that acts deep in the atmosphere and affects the zonal flow away from but not near the equator. Multiple off-equatorial jets form as a result of baroclinic instability owing to the differential radiative heating of the upper atmosphere. Equatorial superrotation occurs when intrinsic heat fluxes are strong enough that Rossby waves generated convectively in the equatorial region transport angular momentum toward the equator. The zonal flow extends deeply into the atmosphere, with its speed changing with depth up to layers with significant MHD drag. Mean meridional circulations adjust entropy gradients and the zonal flow such that the zonal flow is in thermal wind balance with the entropy gradients, and convergence or divergence of angular momentum fluxes in the upper troposphere balances the MHD drag at depth.  Convection homogenizes entropy along the spin axis and adjusts the interior to a convectively and inertially nearly neutral state.           The different speeds and widths of the off-equatorial jets depend, among other factors, on the magnitude of MHD drag, the differential radiative heating of the atmosphere, and the altitude of the jets, which are vertically sheared. The direction and magnitude of the equatorial jet depend on the internal heat flux, the meridional gradient of the solar radiation, and the MHD drag. The strength of superrotating equatorial jets scales approximately with the square of their width. When they are sufficiently strong, their width, in turn, scales with the equatorial Rossby radius and thus depends on the thermal stratification of the equatorial atmosphere.  The simulations have closed energy and angular momentum balances that are consistent with observations of the giant planets. They exhibit temperature structures closely resembling those observed and make predictions of the thermal and gravitational signals of the Jupiter's deep zonal winds that will be observable by NASA's JUNO mission.\n","2"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Formation of zonal jets on the giant planets and detection of their depth by gravity measurements","NG21A-03","8:30 AM","8:45 AM","Y.   Kaspi*","Y.   Kaspi*","Weizmann Institute of Science","Sessioned","Body: The four giant planets of the solar system are dominated at the cloud level by strong east-west zonal jets. Using a hierarchy of dynamical models, including both a shallow terrestrial-type general circulation model (GCM), and a convectively forced deep anelastic GCM, we study and compare different mechanisms which can form such jets. Systematic experiments with these models highlight the role of planetary rotation rate, size, mass and atmospheric mass in controlling the number, strength and latitudinal extent of the zonal jets. A key question is how deep do the observed zonal jets on the giant planets extend into their deep fluid interior. The Juno mission to Jupiter and Cassini Solstice mission to Saturn will perform close flybys of these planets enabling them to measure high-precision gravity data, which can give information about the depth of the circulation. Here, we systematically determine the gravity signature of the jets for a variety of plausible deep flow configurations, showing what constraints can be placed on the depth of the jets from the spacecraft measurements of the gravity field. For this analysis we use both GCMs and a thermal-wind analysis in which the decay depth of the jets, from the observed cloud level wind, is continuously varied along angular momentum surfaces to create this wide range of vertical velocity profiles. This approach allows a systematic study of the relation between the depth of the jets and the resulting measurable gravity harmonics. For Jupiter and Saturn we show that the signature of deep jets will appear at gravity harmonic J10 and beyond, which is likely to be measurable by Juno and Cassini. On Uranus and Neptune due to their lower masses, yet strong broad zonal winds the signature of deep dynamics can appear even at J4. We show how the already known values of J4 for Uranus and Neptune can put constraints on the depth to which jets penetrate on these planets.\n","3"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Anelastic models of the zonal winds in gas giants <i>(Invited)</i>","NG21A-04","8:45 AM","9:00 AM","T.   Gastine*","T.   Gastine*; J.   Wicht","Max Planck Institute for Solar System Research","Sessioned","Body: The banded structures observed at the surfaces of Jupiter and Saturn areassociated with eastward and westward zonal flows. In both gas giants, weobserve a large amplitude prograde equatorial jet, which is flanked bymultiple alternating zonal winds of weaker amplitudes. The depth of these jetsis however poorly known and highly debated. Theoretical scenarios encompassshallow models, that assume that these zonal flows are restricted to theouter weather layer; as well as deep models that suppose that the jetspenetrate deeper down in the molecular envelope. The latter idea has beensupported by 3-D numerical simulations using the so-called Boussinesqapproximation, that assumes the reference state to be constant with radius(e.g. Heimpel et al., 2005). While this approximation is well-adapted toweakly-stratified fluids (e.g. iron cores of Earth-like planets), it becomesmore questionable in the gas giants interiors, where the density contrastis huge ($\rho_{\hbox{bot}}/\rho_{\hbobx{top}}\sim 10^4$). The anelasticapproximation, already employed in recent models of the gas giants (e.g.Jones & Kuzanyan 2009; Gastine & Wicht 2012), thus provides a more realisticframework to simulate the interior dynamics of such planets.We present here the results of a systematic parameter study where we explorethe dependence of convection and zonal flows on density stratification. Whilethe density contrast affects the convective flow amplitude and the typicallengthscale of convection, global quantities and zonal jets properties arefound to be fairly independent of the density contrast. Notwithstanding thesecommon properties, compressibility effects also yield interesting differencesto Boussinesq approaches. For instance, in the strongly stratified models, themain force balance can significantly vary with depth. While the flow in thedeep interior is dominated by rotation, buoyancy can indeed become larger thanCoriolis force close to the surface. This transitional regime has a visiblesignature in the surface zonal winds: the main prograde equatorial jetpresents a small decrease in amplitude at the equator. This dimple is relevantto Jupiter, where a decay of 50 m.s$^{-1}$ is observed in the main equatorialband. This suggests that convection in the gas giants interiors could possiblyoperate in this regime.\n","4"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Differential Rotation and Magnetic Field Generation in Giant Gas Planets","NG21A-05","9:00 AM","9:15 AM","G. A.  Glatzmaier*","G. A.  Glatzmaier*","University of California","Sessioned","Body: Observations of the zonal winds and magnetic fields on the surfaces of giant planets like Jupiter and Saturn beg the questions of what flows and fields exist well below their surfaces and how they are maintained.  In roughly four years, NASA's Juno mission to Jupiter and the Cassini Solstice mission at Saturn will provide near-surface measurements of the magnetic fields of these giant planets that will help to answer these questions.  Until then, theoretical models and computer simulations continue to provide predictions for what the NASA missions at Jupiter and Saturn will discover.  A major question is how deep below the surface do the latitudinally-banded zonal winds extend, i.e., what is the subsurface differential rotation.  If the zonal winds are maintained only within the shallow Jovian atmosphere, they should play no significant role in the dynamo mechanism because the dynamo operates well below the surface where the electrical conductivity is high.  On the other hand, latitudinally banded magnetic field structures measured by Juno at Jupiter and Cassini at Saturn would support the prediction that the zonal winds on these giant planets extend deep below their surfaces.  Computer simulations of convective dynamos with electrical conductivity increasing by several orders of magnitude with depth are presented.  Examples are shown of how the magnetic field structures, for different simulated patterns of differential rotation, would appear as a function of the eccentric orbital radius of the spacecraft.\n","5"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Atmospheric circulation of extrasolar giant planets <i>(Invited)</i>","NG21A-06","9:15 AM","9:30 AM","A. P.  Showman*","A. P.  Showman*","University of Arizona","Sessioned","Body: Of the many known extrasolar planets, over 100have orbital semi-major axes less than 0.1 AU, and a significantfraction of these hot Jupiters and Neptunes are known to transit their stars, allowing them to be characterized with the Spitzer, Hubble,and groundbased telescopes.  The stellar flux incident on these planets is expected to drive an atmospheric circulation that shapes the day-nighttemperature difference, infrared light curves, spectra, albedo,and atmospheric composition, and recent Spitzer infrared light curvesshow evidence for dynamical meteorology in these planets'atmospheres.   Here, I will survey basic dynamical ideas and detailed3D numerical models that illuminate the atmospheric circulation of these exotic, tidally locked planets.   These models suggest that, generally, the circulation will be characterized by broad, fast zonal jets,with day-night temperature contrasts at the photosphere that may vary from small in some cases to large in others.  I will discuss the dynamical mechanisms for maintaining the fast zonal jets that develop in these models, as well as the mechanisms for controlling the temperaturepatterns, including the day-night temperature contrasts.   Thesemechanisms help to explain current observations, and they predict regime transitions for how the wind and temperature patterns should vary with the incident stellar flux, strength of atmospheric drag,and other parameters.  These transitions are observable and insome cases are already becoming evident in the data. I will also compare the circulation of the hot Jupiters to that of young, massive giant planets being directly imaged around other stars, which will bethe subject of a new observational vanguard over the next decade.To emphasize the similarities as well as differences, I will ground this discussion in our understanding of the more familiar atmospheric dynamical regime of Earth, as well as our local giant planets Jupiter, Saturn, Uranus, and Neptune.\n","6"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Superrotation in terrestrial atmospheres and tropical wave-mean flow interaction <i>(Invited)</i>","NG21A-07","9:30 AM","9:45 AM","J.   Mitchell*","J.   Mitchell*; G. K.  Vallis; P.   Wang; J. R.  Dias Pinto; J. A.  Biello","UCLA; Princeton/GFDL; Universidade de São Paulo; UC Davis","Sessioned","Body: Two out of the four terrestrial bodies in the Solar System with thick atmospheres, Titan and Venus, have superrotating atmospheres that spin faster than the underlying surface.  Superrotating equatorial jets are also common to Jupiter and Saturn, but their formation and maintenance may involve a different mechanism.  Earth develops a transient superrotating jet during the westward phase of the Madden-Julian Oscillation, which may have been a persistent feature during past climates, for example the Eocene.  We use a hierarchy of numerical and analytical tools to isolate and describe the mechanism by which spontaneous superrotation of terrestrial atmospheres occur.  Numerical simulations of high-Rossby-number atmospheres started from a state of rest robustly form superrotation provided thermal and frictional damping are sufficiently weak.  Motivated by these numerical results, we demonstrate a linear instability of the shallow water system that resembles the spinup phase of the numerical simulations, and draw comparisons with phenomena on Titan, Venus and Earth.\n","7"
"NG21A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics I","NG21A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","8:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Laboratory Exploration of Multiple Zonal Jet Regimes","NG21A-08","9:45 AM","10:00 AM","C. A.  Smith*","C. A.  Smith*; K. G.  Speer; R. W.  Griffiths","Florida State University; Florida State University; Australian National University","Sessioned","Body: The differentially heated, rotating annulus has classically been used to study wave interactions within a single, baroclinic jet.  At high rotation rates, the baroclinic instability of the flow leads to a transition to a turbulent, eddy-dominated regime.  In the presence of a topographic beta effect, the flow has been observed to produce multiple, meandering zonal jets that are qualitatively similar to those found in planetary atmospheres and in the Antarctic Circumpolar Current (ACC).Our study builds on previous annulus experiments [1] by making observations further within this new regime.  We observe with PIV and other techniques how the structure of the flow responds to changes in various parameters such as tank geometry, gradient in the Coriolis parameter, rotation rate, and differential thermal forcing.  By not employing the more typical direct forcing of small scales, but by applying a large scale forcing over the annulus gap width, this study allows the varying effects of eddy scale selection, enstrophy cascade, etc. to naturally generate flow that more closely resembles planetary atmospheres and the ACC. We seek nondimensional parameters that significantly control zonation in a real fluid.  These observations will provide a metric for the comparison of various theoretical models for multiple zonal jet formation.  Other properties of the jets, such as their migration, meandering, bifurcation, and merging, can also be observed in an idealized situation and compared to numerical simulations.  Ultimately, this will aid the testing and development of sub-grid-scale parameterizations for the multiple zonal jet regime that remain robust in the face of multiple forcing parameters.[1] Wordsworth, R. D., Read, P. L., & Yamazaki, Y. H. (2008). Turbulence, waves, and jets in a differentially heated rotating annulus experiment Physics of Fluids, 20(12), 126602.\n","8"
"NG22A.* Scaling and Correlations and Their Use in Forecasting Natural Hazards I","NG22A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","10:20 AM","11:20 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Statistical Scaling of Severe Tornadoes and Severe Tornado Outbreaks <i>(Invited)</i>","NG22A-01","10:20 AM","10:35 AM","D. L.  Turcotte*","D. L.  Turcotte*; B. D.  Malamud","Univ California; King's College London","Sessioned","Body: The standard measures of the intensity of a tornado in the USA and many other countries are the Fujita and Enhanced Fujita scales. These scales are based on the damage that a tornado causes. Another measure of the strength of a tornado is its path length of touchdown, L. Here we consider severe tornadoes, which we define as L ≥ 10 km, in the continental USA (USA Storm Prediction Center Severe Weather Database). We find that for the period 1982-2011, for individual severe tornadoes (L ≥ 10 km): (i) There is a strong linear scaling between the number of severe tornadoes in a year and their total path lengths in that year. (ii) The cumulative path length data suggests that the longest severe tornado path length (or greater) expected in a year (on average) is L = 115 km and in a decade (on average) is L = 215 km. (iii) The noncumulative frequency-length statistics of severe tornado touchdown path lengths, 20 < L < 200 km, is well approximated by an inverse power-law relationship with exponent near 3. We then take the total path length of severe tornadoes in a convective day (12:00-12:00 UTC), LD, as a measure of the strength of a 24-hour USA tornado outbreak. We find that: (i) For 1982-2011, the numbers of severe tornadoes in a USA convective day outbreak have a strong power-law relationship (exponent 0.80) with their convective day total path lengths, LD, over the range 20 < LD < 1000 km/dy. (ii) For 1952-2011, the cumulative severe tornado outbreak path length data suggests that the longest daily outbreak path length total (or greater) expected in a year (on average) is LD = 480 km and in a decade (on average) is LD = 120 km. (iii) For 1982−2011, the noncumulative frequency-length statistics of tornado outbreaks, 10 < LD <1000 km/dy, is well approximated by an inverse power-law relationship with exponent near 1.8. Finally, we consider the frequency path-length scaling of severe tornadoes (L ≥ 10 km) during two tornado outbreaks, 27 April 2011 (67 severe tornadoes) and 25 May 2011 (16 severe tornadoes), and find similar statistical distributions with robust scaling. We believe that our robust scaling results provide evidence that touchdown path lengths can be used as quantitative measures of the systematic properties of severe tornadoes and severe tornado outbreaks.\n","1"
"NG22A.* Scaling and Correlations and Their Use in Forecasting Natural Hazards I","NG22A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","10:20 AM","11:20 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Shoreline Position Dynamics: Measurement and Analysis","NG22A-02","10:35 AM","10:50 AM","C. C.  Barton*","C. C.  Barton*; B.   Rigling; N.   Hunter; S. F.  Tebbens","Wright State University; Wright State University; Wright State University; Wright State University","Sessioned","Body: The dynamics of sandy shoreline position is a fundamental property of complex beach face processes and is characterized by the power scaling exponent. Spectral analysis was performed on the temporal position of four sandy shorelines extracted from four shore perpendicular profiles each resurveyed approximately seven times per year over twenty-seven years at the Field Research Facility (FRF) by the U.S. Army Corps of Engineers, located at Kitty Hawk, NC. The four shorelines we studied are mean-higher-high-water (MHHW), mean-high-water (MHW), and mean-low-water (MLW) and mean-lower-low-water (MLLW) with elevations of 0.75m, 0.65m, -0.33m, and -0.37m respectively, relative to the NGVD29 geodetic datum.Spectral analysis used to quantify scaling exponents requires data evenly spaced in time. Our previous studies of shoreline dynamics used the Lomb Periodogram method for spectral analysis, which we now show does not return the correct scaling exponent for unevenly spaced data. New to this study is the use of slotted resampling and a linear predictor to construct an evenly spaced data set from an unevenly spaced data set which has been shown with synthetic data to return correct values of the scaling exponents. A periodogram linear regression (PLR) estimate is used to determine the scaling exponent β of the constructed evenly spaced time series.This study shows that sandy shoreline position exhibits nonlinear self-affine dynamics through time. The times series of each of the four shorelines has scaling exponents ranging as follows:  MHHW, β = 1.3-2.2; MHW, β = 1.3-2.1; MLW, β = 1.2-1.6; and MLLW, β = 1.2-1.6.  Time series with β greater than 1 are non-stationary (mean and standard deviation are not constant through time) and are increasingly internally correlated with increasing β. The range of scaling exponents of the MLW and MLLW shorelines, near β = 1.5, is indicative of a diffusion process.  The range of scaling exponents for the MHW and MHHW shorelines indicates spatially variable dynamics higher on the beach face.\n","2"
"NG22A.* Scaling and Correlations and Their Use in Forecasting Natural Hazards I","NG22A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","10:20 AM","11:20 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Trends and Correlation Estimation in Climate Sciences: Effects of Timescale Errors <i>(Invited)</i>","NG22A-03","10:50 AM","11:05 AM","M.   Mudelsee*","M.   Mudelsee*; M. A.  Bermejo; T.   Bickert; D.   Chirila; J.   Fohlmeister; P.   Köhler; G.   Lohmann; K.   Olafsdottir; D.   Scholz","Alfred Wegener Institute for Polar and Marine Research; Climate Risk Analysis; MARUM – Center for Marine Environmental Sciences; Heidelberg Academy of Sciences; University of Mainz","Sessioned","Body: Trend describes time-dependence in the first moment of a stochastic process, and correlation measures the linear relation between two random variables. Accurately estimating the trend and correlation, including uncertainties, from climate time series data in the uni- and bivariate domain, respectively, allows first-order insights into the geophysical process that generated the data. Timescale errors, ubiquitious in paleoclimatology, where archives are sampled for proxy measurements and dated, poses a problem to the estimation. Statistical science and the various applied research fields, including geophysics, have almost completely ignored this problem due to its theoretical almost-intractability. However, computational adaptations or replacements of traditional error formulas have become technically feasible. This contribution gives a short overview of such an adaptation package, bootstrap resampling combined with parametric timescale simulation. We study linear regression, parametric change-point models and nonparametric smoothing for trend estimation. We introduce pairwise-moving block bootstrap resampling for correlation estimation. Both methods share robustness against autocorrelation and non-Gaussian distributional shape. We shortly touch computing-intensive calibration of bootstrap confidence intervals and consider options to parallelize the related computer code. Following examples serve not only to illustrate the methods but tell own climate stories: (1) the search for climate drivers of the Agulhas Current on recent timescales, (2) the comparison of three stalagmite-based proxy series of regional, western German climate over the later part of the Holocene, and (3) trends and transitions in benthic oxygen isotope time series from the Cenozoic. Financial support by Deutsche Forschungsgemeinschaft (FOR 668, FOR 1070, MU 1595/4-1) and the European Commission (MC ITN 238512, MC ITN 289447) is acknowledged.\nURL : http://www.climate-risk-analysis.com\n","3"
"NG22A.* Scaling and Correlations and Their Use in Forecasting Natural Hazards I","NG22A","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","10:20 AM","11:20 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Bayesian Analysis of Non-Gaussian Long-Range Dependent Processes","NG22A-04","11:05 AM","11:20 AM","N. W.  Watkins*","N. W.  Watkins*; T.   Graves; C.   Franzke; R. B.  Gramacy","Statistics Laboratory;  British Antarctic Survey;  The University of Chicago; 6-8 Greencoat Place","Sessioned","Body: Recent studies have strongly suggested that surface temperatures exhibit long-range dependence (LRD). The presence of LRD would hamper the identification of deterministic trends and the quantification of their significance. It is well established that LRD processes exhibit stochastic trends over rather long periods of time. Thus, accurate methods for discriminating between physical processes that possess long memory and those that do not are an important adjunct to climate modeling.We have used Markov Chain Monte Carlo algorithms to perform a Bayesian analysis of Auto-Regressive Fractionally-Integrated Moving-Average (ARFIMA) processes, which are capable of modeling LRD. Our principal aim is to obtain inference about the long memory parameter,  $d$,with secondary interest in the scale and location parameters. We have developed a reversible-jump method enabling us to integrate over different model forms for the short memory component. We initially assume Gaussianity, and have tested the method on both synthetic and physical time series such as the Central England Temperature.Many physical processes, for example the Faraday time series from Antarctica, are highly non-Gaussian. We have  therefore  extended this work by weakening the Gaussianity assumption. Specifically, we assume a symmetric $\alpha$-stable distribution for the innovations. Such processes provide good, flexible, initial models for non-Gaussian processes with long memory. We will present a study of the dependence of the posterior variance $\sigma_d$ of the memory parameter $d$  on the length of the time series considered. This will  be compared with equivalent error  diagnostics for other measures of $d$.\n","4"
"NG22B. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics I","NG22B","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Exploring the effect of rainfall and catchment properties on the scaling of peak flows <i>(Invited)</i>","NG22B-01","11:20 AM","11:35 AM","W. F.  Krajewski*","W. F.  Krajewski*; T. B.  Ayalew; R.   Mantilla","University of Iowa","Sessioned","Body: Several studies have shown that peak discharges (Q_p) observed in a nested river network following a runoff generating rainfall event exhibit a power law with respect to drainage area (A) as Q_p=αA^θ.  However, what aspects of the rainfall-runoff processes control the scaling exponent (θ) is not fully understood.  We investigate, using a river network based rainfall-runoff model called CUENCAS and three different river basins in Iowa, how the interplay between rainfall intensity and duration, the hillslope velocity, the channel routing velocity and the river network affect the scaling exponent.  We show that, for a given river network, rainfall duration controls the magnitude of the scaling exponent, which is consistent with previous studies.  Most importantly, we show that the scaling exponent starts at a value greater than the scaling exponent of the width function maxima and converges asymptotically to unity as the rainfall duration increases.  A similar effect is found when hillslope velocities and channel velocities are varied, indicating that it is the combined effect of these factors that control the exact value of the scaling exponent.  In addition, we test the scenario of nonlinear channel routing velocity and show that changes in scaling exponent depend on the hillslope velocities imposed in the simulation.  In particular we show that, when realistic hisllope velocities are imposed in the system, the basin response scales linearly with rainfall intensity for both the linear and the nonlinear channel velocity case.  Finally we show that, for the nonlinear channel velocity case and under the assumption that runoff loss mechanism is uniform in space, nonlinearities manifest in systematic changes in the time to peak rather than in the magnitude of the peak discharge.\n","1"
"NG22B. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics I","NG22B","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Nature and Inference of Scaling in Temporal Rainfall <i>(Invited)</i>","NG22B-02","11:35 AM","11:50 AM","D.   Veneziano*","D.   Veneziano*; C.   Lepore","MIT","Sessioned","Body: We pursue three objectives related to the scaling of temporal rainfall: 1. Develop methods for the analysis of scaling within rainstorms, 2. Explain the difference in scaling results when considering the whole record inclusive of storms and inter-storm periods (continuous analysis) or only the storms (within-storm analysis), and 3. Examine whether scaling follows a beta-lognormal model or a more general beta-log-Levy model. Regarding objective 1, there are well-established techniques for continuous scaling analysis but not for the analysis within storms. For the latter, we develop methods based on the partition coefficients and show how to correct for bias and maximize the estimation accuracy. To pursue objective 2 we use historic records, synthetic time series, and toy rainfall models to show that the continuous results reflect mainly the alternation of dry and wet periods and are insensitive to the fluctuations of rainfall intensity inside the storms. Moreover, we find that the rain support is not fractal. From this we conclude that the results from traditional continuous analysis are spurious. By contrast, there is evidence of within-storm scaling. Inside the storms there is higher intermittency (higher intensity fluctuations) and lower lacunarity (more compact rain support) than in the continuous record. These results have important implications on downscaling and the evaluation of rainfall extremes. Concerning objective 3, we note that popular multifractal models for rainfall are of the log-Levy (“universal”) type. A key parameter of those models is the stability index 0 < α ≤ 2, with α = 2 corresponding to lognormal models. To account for the alternation of dry and wet periods (also in within-storm analysis), one should add a “beta component” and thus use beta-log-Levy or beta-lognormal models. By using simulations with α = 2, we show that standard estimators of α are negatively biased and the hypothesis of beta-lognormal multifractality inside the storms is statistically acceptable. This is an important finding because the estimation of   is notoriously difficult and lognormal distributions are much easier to work with than the more general log-Levy distributions. \n","2"
"NG22B. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics I","NG22B","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Model Physics and Referential Indeterminacy in Multiscale Soil-Precipitation Feedbacks <i>(Invited)</i>","NG22B-03","11:50 AM","12:05 PM","A. P.  Barros*","A. P.  Barros*; J.   Erlingis; X.   Sun","Duke University","Sessioned","Body: Soil-precipitation feedbacks are examined through a modeling study to investigate whether and how land-atmosphere interactions modulate the diurnal cycle of rainfall under distinct hydrometeorological regimes in the Southern Great Plains and in South America.  High resolution simulations using the Weather Research and Forecasting (WRF V3.1) model in various experimental configurations with regard to model physics and land-use, land-cover and soil characteristics are examined in detail.  The results provide insight on the dependence of sensitivity analysis and feedback studies of soil-precipitation feedbacks on model physics and model structure, and why establishing physical cause-effect relationships remains elusive.\n","3"
"NG22B. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics I","NG22B","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","The Search for Causality in Hydrometeorological Multifractals: A Breakdown Coefficients Approach","NG22B-04","12:05 PM","12:20 PM","A.   Carsteanu*","A.   Carsteanu*; C. A.  Fernandez Yañez; R.   Martínez Novelo","ESFM - IPN","Sessioned","Body: Earlier studies have depicted the behavior of breakdown coefficients of multifractal processes, computed at different scales, in order to point out possible temporal asymmetries. It has been found [Arnéodo et al, 1998, EPJ-B2, 277-282] that such an asymmetry is typical of the stock market, but other multifractally cascading processes, such as e.g. isotropic turbulence, appear to be temporally symmetric in their breakdown coefficients (therein computed from wavelet coefficients at different scales). Motivated by the correlation detected in breakdown coefficients of temporal rainfall, between scales as well as along time (up to the event scale) [Cârsteanu and Foufoula-Georgiou, 1996, JGR 101(D21), 26363–26370], the present work explores the possible origins of such correlations, in terms of information circulation across scales.\n","4"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","A Moist Convection Study with Gas Giant WRF Model","NG23A-1541","1:40 PM","1:40 PM","D.   YANG*","D.   YANG*; A. P.  Ingersoll; S.   Ewald","CALTECH","Sessioned","Body: Moist convection (MC) has been observed on giant planets through lightning flashes, and likely plays an important role in vertical energy transport and maintaining the zonal jets. In this study, we will study MC and its interaction with large-scale circulation on Jupiter and Saturn using the Weather Research and Forecasting (WRF) model. The WRF model is a mesoscale atmosphere model, a fully compressible, non-hydrostatic model, but also with a hydrostatic option. It has numerous options for treating clouds, precipitation, radiation and the planetary boundary layer. To apply the WRF model to a giant planet, we will change Earth’s parameter values to the those of the planet. The planetary parameters are gravity, rotation and radius. The atmospheric parameters are the molecular mass and specific heat of the dry gas. The parameters of the lower boundary are surface pressure, temperature and the mixing ratios of various condensable species. On Jupiter the water cloud base is ~ 6 bar. We will set the lower boundary below the water cloud base. The first step of this research is to test how deep the lower boundary must be. If the mesoscale dynamics of the upper layer does not change when we vary the depth of the lower boundary, then it is deep enough. In this study, we will address a scientific question: Why is MC on Jupiter and Saturn more energetic and less frequent than that on Earth? If MC is infrequent, unlike that in the tropics on earth, convective available potential energy (CAPE) can be accumulated, and the strength can be very vigorous. We will drive the model by specifying the net radiative flux divergence, and let the temperature profile evolve with time. The equilibrium temperature profile will be examined. We will also identify how CAPE is accumulated in our model.\n","1"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Formation of jets and water clouds on Jupiter","NG23A-1542","1:40 PM","1:40 PM","Y.   Lian*","Y.   Lian*; A. P.  Showman","Ashima Research; Lunar and Planetary Lab, the University of Arizona","Sessioned","Body: Ground-based and spacecraft observations show that Jupiter exhibits multiple banded zonal jet structures. These banded jets correlate with dark and bright clouds, often called belts and zones. The mechanisms that produce these banded zonal jets and clouds are poorly understood. Our previous studies showed that the latent heat released by condensation of water vapor could produce equatorial superrotation along with multiple zonal jets in the mid-to-high latitudes. However, that previous work assumed complete and instant removal of condensate and therefore could not predict the cloud formation.  Here we present an improved 3D Jupiter model to investigate some effects of cloud microphysics on large-scale dynamics using a closed water cycle that includes condensation, three-dimensional advection of cloud material by the large-scale circulation, evaporation and sedimentation. We use a simplified Betts-Miller scheme to relax the temperature and water vapor towards moist adiabat and saturation profile respectively when atmospheric columns become conditionally unstable, and apply a dry convective adjustment scheme in region deeper than the cloud base to mix heat and tracers. We further assume that the liquid particles are well mixed within the clouds during condensation. Other physics parameterizations included in our model are the bottom drag and internal heat flux as well as the Newtonian heating. We find that the active water cycle can produce numerous convective storms and multiple banded jets with equatorial superrotation. However the clouds are sporadic and not coherent with the jet structures. Here we will discuss the jet-forming mechanism compared to our previous studies and cloud morphologies under the influence of large-scale dynamics.\n","2"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Atmospheric Circulation of Hot Jupiters: Insensitivity to Initial Conditions","NG23A-1543","1:40 PM","1:40 PM","B.   Liu*","B.   Liu*; A. P.  Showman","Kavli Institute for Astronomy  & Astrophysics; University of Arizona","withdrawn","","3"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Analysis of 2-cm Thermal Emission from Saturn: Distribution of Ammonia Gas in the Cloud Layer","NG23A-1544","1:40 PM","1:40 PM","A.   Laraia*","A.   Laraia*; A. P.  Ingersoll; M. A.  Janssen; S.   Gulkis","California Institute of Technology; Jet Propulsion Laboratory","Sessioned","Body: Ammonia gas, a condensable gas in Saturn’s atmosphere, is the main opacity source at 2-cm wavelength. Thus an analysis of spatially resolved 2-cm thermal emission from Saturn provides information about the distribution of ammonia within the atmosphere. Assuming that the temperature falls off adiabatically with height, high 2-cm brightness temperatures indicate low column ammonia vapor abundance and low brightness temperatures indicate high abundance. In this work we perform an analysis of four 2-cm brightness temperature maps of Saturn, obtained from the radar instrument on board the Cassini spacecraft. The weighting function for this instrument peaks in the cloud layer near the 1 bar pressure level, depending on the column abundance of ammonia. 	We observe anomalies in brightness temperature within 10° of the equator, with relatively high brightness temperatures around ±10° surrounding a band of lower brightness temperatures directly on the equator and extending to ±3°. The temperatures off the equator are ~10 K higher than those at the equator in some cases. These observations are qualitatively consistent with Fletcher et al (2011), who presented an analysis of 4.6-5.1 μm thermal spectra from Cassini VIMS data and found high ammonia abundance at the equator and low abundance just off it. To compare with Fletcher et al we used an atmospheric testbed model, which provides forward calculation of microwave radiances, to get information about the physical parameters of Saturn’s atmosphere, namely the relative humidity (RH) of ammonia in the cloud layer and the deep abundance of ammonia. We present a realm of possibilities for the parameter regime in which Saturn lies, in terms of ammonia RH and deep abundance. 	Our analysis brings us to the question: what dynamical processes are occurring in the equatorial region that cause such a drastic difference between the ammonia vapor abundance directly on the equator and that just off it? We speculate on a few possibilities that may lead to this latitudinal structure of ammonia vapor, and compare the thermal emission from Saturn as a function of latitude to the outgoing longwave radiation from Earth in the vicinity of the Hadley Cell.  \n","4"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","A Preliminary Study on the Circulation of an ocean covering a Synchronously Rotating Planet","NG23A-1545","1:40 PM","1:40 PM","H.   Matsuo*","H.   Matsuo*; M.   Ishiwatari; S.   Takehiro; Y.   Hayashi; K.   Nakajima","Kyushu Univ.; Hokkaido Univ.; Kyoto Univ.; Center for Planetary Science; Kobe Univ.; Kyushu Univ.","Sessioned","Body: Recently, nearly 800 extrasolar planets have been detected. It seems that some of them present into habitable zone, in which planets can have ocean, and such planets rotate synchronously with their central stars. Ocean is necessary for life, and the circulation makes climate mild by heat transport on the earth. The earth is the only planet that has ocean in the solar system so that it has not been understood what oceanic circulation is like in another planets. The purpose of this study is prediction of oceanic circulation on extrasolar planets by using numerical simulation. As a first step, elementary consideration is made. The planet is almost entirely covered with ocean and whose rotation period corresponds with its orbital period. On synchronously rotating planets, the thermal contrast between day-hemisphere and night-hemisphere would be extreme. However, it may be lessend if there is significant zonal heat transport. The circulation in such conditions has not been known well.We performed a numerical experiment based on the linear shallow water equation, assuming that both the evaporation and the precipitation occur only on day-hemisphere (Noda et al., 2011). With these distributions of the evaporation and the precipitation, one may anticipate the circulation occurs in only day-hemisphere. However, the resulting calculation is characterized with zonally uniform zonal flow, which also covers night hemisphere. In addition, the intensity of the flow increases with time. That behavior can be understood by constructing asymptotic solution which is first degree in time. The importance of Coriolis force, which bends meridional flow to zonal flow, is identified. It is implied that, even when only day-hemisphere has the evaporation and precipitation, there may be significant amount of heat can be transported from the day-hemisphere to the night-hemisphere by the strong zonal flow. The growth of zonal flow would be stopped when the evaporation and the precipitation are balanced with mass transport in the bottom Ekman layer.\n","5"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Thermodynamics of a dry atmosphere at different surface exchange rates and rotation speeds","NG23A-1546","1:40 PM","1:40 PM","F.   Ragone*","F.   Ragone*; S.   Pascale; V.   Lucarini; Y.   Wang","University of Hamburg; University of Reading; University of Oxford","Sessioned","Body: We study the combined effect of the rotation speed Ω and of the surface ex- change rate – quantified by a surface turbulent relaxation timescale τ – on the dissipative properties of an Earth-like dry atmosphere. The rotation speed Ω is varied between one tenth and eight times that of the Earth Ω ≈ 7.29 x 10−5 rad−1 and τ from 45 minutes to 500 days. We study the circulation regimes induce by such parametric variations through two key dimensionless parame- ters, the thermal Rossby number Ro and the frictional dimensionless number Ff. An extensive analysis is performed by using nonequilibrium thermo- dynamics diagnostic tools such as material entropy production, efficiency, meridional heat transport and kinetic energy dissipation. The thermal dis- sipation associated with the sensible heat flux is found to depend mainly on the surface properties and to be almost independent from the rotation rate whereas the dissipation of kinetic energy depends in a non trivial way on both. Slowly rotating, axisymmetric circulations (Ro > 1) have the highest mechanical dissipation when the surface drag is strong (Ff ≈ 10−3) but the highest efficiency for Ff ≈ 10. For 0.01 < Ro < 1 the peak is reached for Ff ≈ 103 (τ ∼ 3 d), corresponding to the maximum activity of the baroclinic eddies, the maximum meridional heat transport and the highest efficiency. At high rotation rates (Ro < 10−2) there is a dramatic drop in the intensity of the atmospheric energy cycle and in the meridional heat transport as the at- mosphere tends towards the radiative-convective equilibrium profile. When τ is interpreted as an internal parameter, our results also confirm the vagueness of the Maximum Entropy Production Principle, since its applicability seems to be dependent on both the dissipative functions and the dynamical regime. This study suggests the effectiveness of using fundamental nonequilibrium thermodynamics to investigate the properties of planetary atmospheres.\n","6"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","The vertical structure of Jupiter and Saturn zonal winds from nonlinear simulations of major vortices and planetary-scale disturbances","NG23A-1547","1:40 PM","1:40 PM","E.   Garcia-Melendo*","E.   Garcia-Melendo*; J.   Legarreta; A.   Sanchez-Lavega","Fundacio Privada Observatori Esteve Duran; Universidad del Pais Vasco UPV/EHU","Sessioned","Body: Direct measurements of the structure of the zonal winds of Jupiter and Saturn below the upper cloud layer are very difficult to retrieve. Except from the vertical profile at a Jupiter hot spot obtained from the Galileo probe in 1995 and measurements from cloud tracking by Cassini instruments just below the upper cloud, no other data are available. We present here our inferences of the vertical structure of Jupiter and Saturn zonal wind across the upper troposphere (deep down to about 10 bar level) obtained from nonlinear simulations using the EPIC code of the stability and interactions of large-scale vortices and planetary-scale disturbances in both planets.Acknowledgements: This work has been funded by Spanish MICIIN AYA2009-10701 with FEDER support, Grupos Gobierno Vasco IT-464-07 and UPV/EHU UFI11/55.   [1]	García-Melendo E., Sánchez-Lavega A., Dowling T.., Icarus, 176, 272-282 (2005).[2]	García-Melendo E., Sánchez-Lavega A., Hueso R., Icarus, 191, 665-677 (2007).[3]	Sánchez-Lavega A., et al., Nature, 451, 437- 440 (2008).[4]	Sánchez-Lavega A., et al., Nature, 475, 71-74 (2011). \n","7"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Tidal Torques are the Answer","NG23A-1548","1:40 PM","1:40 PM","H.   Houben*","H.   Houben*","Bay Area Environmental Rsrch","withdrawn","","8"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Mean Flow Generation by Two-Dimensional Roll Convection","NG23A-1549","1:40 PM","1:40 PM","J.   Fitzgerald*","J.   Fitzgerald*; B.   Farrell","Harvard University; Harvard University","Sessioned","Body: Fluid convection often gives rise to the formation of large-scale mean flows coexisting with the convective motion. This phenomenon is observed in both 2D numerical simulations (Thompson, 1970) and 3D laboratory experiments (Krishnamurti and Howard, 1981). In both cases, the mean flow forms in a periodic domain so that support against diffusion must be provided by up-gradient momentum fluxes. In two dimensions, convection drives the jet formation responsible for the transition from the low to high confinement state in tokamak plasmas. In three dimensions, spontaneous reorientation of a convectively driven large-scale flow in the Earth’s interior has been suggested as a mechanism for the reversal of the Earth’s magnetic field. In this contribution, the mechanism of mean flow generation in two-dimensional Rayleigh-Bénard convection is analyzed using a quasilinear (mean-field) approach. Previous theoretical models (such as Hermiz et al., 1995) predict the existence of a parameter range in which mean flow formation is prevented by vertical vorticity advection. The quasilinear system, on the other hand, predicts that mean flow formation occurs under all parameter conditions. The reason for this discrepancy is explained, and the mean flow dynamics of the quasilinear model are further explored and tested for robustness using the fully nonlinear equations of motion.\n","9"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","A quasigeostrophic model of zonal wind generation on the gas giant planets ","NG23A-1550","1:40 PM","1:40 PM","D.   Laycock*","D.   Laycock*; M.   Dumberry","University of Alberta","Sessioned","Body: The mechanism responsible for generating the surface winds of Jupiter and Saturn, which are dominated by a mean azimuthal mode with a broad prograde equatorial jet and smaller jets of alternating directions at higher latitudes, has yet to be fully understood.  While the results of recent three dimensional numerical models of thermal convection in a thin spherical shell are broadly in agreement with observations of the gas giants, computational constraints restrict these models to non-dimensional parameters many orders of magnitude more modest than planetary values and it is unknown whether these results scale to more realistic parameter regimes.  Rapid planetary rotation produces rigid two dimensional quasigeostrophic (QG) flow in these models, with columnar structures aligned with, and nearly invariant along, the axis of planetary rotation and spanning the entire width of the convection shell.  In the present work we exploit this symmetry of the system to develop a 2D QG model of zonal wind generation by integrating the equations of motion over axial Taylor columns to average over small departures from rigidity.  Evolving the axially averaged variables in the equatorial plane collapses the problem into two dimensions, greatly reducing computation requirements while still capturing the essential dynamics of zonal wind generation.  To build such a model we have extended the standard QG framework tothe geometry inside the planetary tangent cylinder circumscribing the convection shell's inner boundary.  In this polar region axial convection, transporting heat into the bottom and out of the top of convection shell, is possible and is responsible for forcing the turbulence required for jet generation.  Thus, in addition to the traditional QG equations, we must also solve the averaged axial flow equation to model this effect.  Numerical simulations of our 2D QG model demonstrate that this approach yields banded zonal winds similar to 3D models at a fractionof the computational cost.  Such a model allows for an exploration of regions of parameter spaceinaccessible to current models, as well as an investigation of the longer timescale evolution of zonal winds.\n","10"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Zonal winds and flows generated by harmonic forcing in planetary atmospheres, subsurface oceans and cores","NG23A-1551","1:40 PM","1:40 PM","A.   Sauret*","A.   Sauret*; D.   Cebron; M.   Le Bars; S.   Le Dizès; P.   Le Gal","CNRS and Aix-Marseille University; ETH; UCLA","Sessioned","Body: A huge amount of energy is stored in the spin and orbital motions of any planet, and under certain circumstances, harmonic forcings such as libration, precession and tides are capable of conveying a portion of this energy to drive intense three-dimensional flows in its liquid layers. These mechanisms are studied here by combining theoretical, experimental and numerical approaches. At first, we focus on the effect of longitudinal librations, corresponding to oscillations of the rotation rate of a planet. This boundary forcing systematically leads to a correction to the mean solid body rotation through non-linear interactions in the Ekman layers. This geostrophic zonal wind is well described by an analytical approach. Additionally, at sufficiently large libration amplitude or small Ekman number, the oscillating flow is periodically unstable with respect to centrifugal instability. The resulting Taylor-Görtler vortices generated in the Ekman layers then generate inertial waves in the bulk with well-defined characteristics and temporal signatures. Inertial waves can also be resonantly excited by any harmonic forcing, when the forcing frequency ranges between plus and minus twice the rotation rate. In any case, the nonlinear self-interaction of excited inertial waves may drive an intense and localised axisymmetric jet, which becomes unstable at low Ekman number following a shear instability, generating space-filling turbulence. This generic mechanism is illustrated here by an experimental study of tidal forcing in a spherical shell.\n","11"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Prediction of Rare Transitions in Planetary Atmosphere Dynamics Between Attractors with Different Number of Zonal Jets","NG23A-1552","1:40 PM","1:40 PM","F.   Bouchet*","F.   Bouchet*; J.   Laurie; O.   Zaboronski","Ecole Normale Superieure de Lyon and CNRS; Warwick University","Sessioned","Body: We describe transitions between attractors with either one, two or more zonal jets in models of turbulent atmosphere dynamics. Those transitions are extremely rare, and occur over times scales of centuries or millennia. They are extremely hard to observe in direct numerical simulations, because they require on one hand an extremely good resolution in order to simulate accurately the turbulence and on the other hand simulations performed over an extremely long time. Those conditions are usually not met together in any realistic models. However many examples of transitions between turbulent attractors in geophysical flows are known to exist (paths of the Kuroshio, Earth's magnetic field reversal, atmospheric flows, and so on). Their study through numerical computations is inaccessible using conventional means. We present an alternative approach, based on instanton theory and large deviations. Instanton theory provides a way to compute (both numerically and theoretically) extremely rare transitions between turbulent attractors. This tool, developed in field theory, and justified in some cases through the large deviation theory in mathematics, can be applied to models of turbulent atmosphere dynamics. It provides both new theoretical insights and new type of numerical algorithms. Those algorithms can predict transition histories and transition rates using numerical simulations run over only hundreds of typical model dynamical time, which is several order of magnitude lower than the typical transition time. We illustrate the power of those tools in the framework of quasi-geostrophic models. We show regimes where two or more attractors coexist. Those attractors corresponds to turbulent flows dominated by either one or more zonal jets similar to midlatitude atmosphere jets. Among the trajectories connecting two non-equilibrium attractors, we determine the most probable ones. Moreover, we also determine the transition rates, which are several of magnitude larger than a typical time determined from the jet structure. We discuss the medium-term generalization of those results to models with more complexity, like primitive equations or GCMs.\nURL: http://perso.ens-lyon.fr/freddy.bouchet/\n","12"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Exploring the Giant Saturnian Storm in 2010: A Model of Moist Convection","NG23A-1553","1:40 PM","1:40 PM","C.   Li*","C.   Li*; A. P.  Ingersoll","California Institute of Technology","Sessioned","Body: A giant planet-encircling storm occurred on Saturn at the end of year 2010. The storm produced lightning at a rate greater than 10 SEDs per second. It stirred up its latitude band and wrapped around the planet, and after 6 months it died. These kinds of storms are rare and episodic. They happen every 20-30 years. In this study, we discuss the role of moist convection to the development of the storm. The study is composed of three parts. First, thermodynamics on Saturn suggests that strong convection is prohibited by the water-loading-effect when the troposphere is warm. After 20~30 years, the troposphere has cooled below a critical value so that deep convection starts to develop at the base of the cloud. Second, a linear perturbation analysis of Rossby waves in an easterly jet is performed to narrow down the choices of free parameters. Based on the observed features of the storm (propagation phase speed, typical wave length, etc), the Rossby radius of deformation is calculated to be around 2000 km. Third, a 2D numerical model is developed to simulate the propagation of the storm, with moist convection parameterized as an anticyclonic vorticity source. The simulated storm has a well-defined head and a wavy tail that resemble the observation.\n","13"
"NG23A. Jets and Zonal Flows in Planetary and Astrophysical Fluid Dynamics II Posters","NG23A","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)","Testing Stochastic Structural Stability Theory predictions for turbulent jet formation and equilibration in barotropic beta-plane turbulence using nonlinear and quasi-linear simulations  ","NG23A-1554","1:40 PM","1:40 PM","B.   Farrell*","B.   Farrell*; N.   Constantinou; P.   Ioannou","Harvard Univ;  National and Kapodistrian University of Athens","Sessioned","Body: Coherent large scale  jets that are not forced directly at the jet scale are a prominent feature of planetary turbulence. These jets arise through systematic organization of the turbulent Reynolds stresses.  Understanding the mechanism producing  the required systematic eddy momentum flux convergence, and how the jets and associated eddy field mutually adjust to maintain statistically steady finite amplitude jets constitute fundamental theoretical problems. Stochastic Structural Stability Theory (SSST) provides a dynamics for the evolution of the statistical mean state of a turbulent system that is quasi-linear in that it retains  the perturbation-mean flow interaction  while  parameterizing stochastically the  perturbation-perturbation interactions and external forcing.  The result is a dynamics for the turbulent state which is closed at second order.  This system allows formulation of a stability theory that predicts the emergence of jets from homogeneous turbulence as well as the equilibration of these jets at finite amplitude.  Comparison of the predictions of SSST with quasi-linear and nonlinear simulations of barotropic turbulence on a beta-plane will be presented.  These examples show that SSST accurately predicts both the initial emergence and the finite amplitude equilibration of jets in beta-plane turbulence provided that the stochastic parameterization of turbulence used in the perturbation dynamics approximates the spectrum of the background turbulence in which the jets form\n","14"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Precursor-based Forecast of El Nino Episodes One Year Ahead via Climate Networks","NG23B-1555","1:40 PM","1:40 PM","A.   Bunde*","A.   Bunde*; J.   Ludescher; M.   Bogachev; A.   Gozolchiani; S.   Havlin","Giessen University; Bar-Ilan University","Sessioned","Body: Although the El Nino Southern Oscillation (ENSO) is the most prominent phenomenon of climate variability and affects weather and climate in large parts of the world, an efficient prediction has only been achieved up to six months ahead. Here we develop a dynamical network approach which allows a prediction of El Nino about one year ahead with a  hit rate above 0.5 at a very small false alarm rate (about 0.1). In the considered network, the nodes are grid points in the Pacific and the strengths of the links (teleconnections) between them are characterized by the cross-correlations of the observed atmospheric surface temperatures at the grid points. We focus on the time span between 1950 and 2011 where high quality observational data are available. We find that well before an El-Nino episode, the links between the El Nino basin and the rest of the Pacific tend to strengthen, and show explicitly that this feature can be used for an efficient forecast of the next El Nino episode about one year in advance.\n","1"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Long-term memory and extremes in  historical  temperature reconstructions","NG23B-1556","1:40 PM","1:40 PM","J.   Ludescher*","J.   Ludescher*; A.   Bunde","Giessen University","Sessioned","Body: We analyze the long-term memory in temperature  reconstructions for Central Europe which are based on tree-ring widths [1] and chronological records [2] and compare the results with multiproxy temperature reconstructions of the extra tropical region of the Northern Hemisphere [3], instrumental data for Central Europe of the last century and recent millennium simulations (last version, as of 2012, of the MPI-ESM-P model based on ECHAM6). We use the standard methods for detecting long-term memory, (i) detrended fluctuation analysis (DFA2) and (ii) wavelet techniques (WT2), and analyze also (iii) conditional averages and (iv) the distribution of the persistence lengths. In addition, we study (v) the distribution of the return intervals for various return periods. Our results provide coherent evidence that all temperature reconstructions cannot be described by an AR1 process, but are long-term correlated. For both the tree ring based and multi proxy reconstructions, the Hurst exponent H is close to 1, while for the instrumental and model data as well as for the reconstruction based on chronological records H is between 0.6 and 0.7. The inconsistency between the different reconstructions and the output of the millennium runs is severe and raises concern on the usefulness of tree-ring widths to reconstruct the temperature of the past.\n","2"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Long-Range Correlations and Extreme Space Weather","NG23B-1557","1:40 PM","1:40 PM","A. S.  Sharma*","A. S.  Sharma*; T.   Veeramani","Univ Maryland; Indian Institute of Technology Madras","Sessioned","Body: An essential feature of space weather is the overlap in the physical time scales with those of its driver, viz. the turbulent solar wind. This requires the analysis of the data of both the driver and its response in order to isolate the intrinsic nature of space wether and its extremes. The extensive databases of geospace storms and substorms, consisting of geomagnetic indices and solar wind variables  are used to analyze the nature of the long-range correlations. The detrended fluctuation anlasis is used to compute the scaling exponents from the auto-correlation and mutual-information functions. The scaling exponent of the auroral electrojet index  show a break at 5 hrs, which separates a Brownian feature from long-range correlations. The solar wind data on the other hand yields a single scaling exponent, thus showing that of the two regimes of geomagnetic activity one is correlated with the solar wind.  A new technique of fluctuation analysis that uses nonlinear dynamical predictions to remove the trends is used to analyze this feature of space weather in more detail.\n","3"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Annual Shoreline Dynamics along the Outer Banks, North Carolina","NG23B-1558","1:40 PM","1:40 PM","S. F.  Tebbens*","S. F.  Tebbens*; R. M.  Myers; C. C.  Barton; S. M.  Burroughs; A.   Murray","Wright State Univ; Wright State Univ; University of Tampa; Duke University","Sessioned","Body: Shorelines undergo continuous change, primarily in response to the action of waves. In 2006 and 2007, repeat NSF-funded LIDAR surveys were collected along a 175 km stretch of the Atlantic coast on the Outer Banks, North Carolina, United States by the National Center for Airborne Laser Mapping (NCALM). Our previous analysis of annual shoreline change between 1997 and 1998 documented nonlinear patterns in shoreline position change. Our previous work also documented spatial variability, where different regions of the Outer Banks exhibit different patterns of coastal change during the same time interval. The 2006 and 2007 LIDAR surveys also exhibit self-affine scaling.  A self-affine time series is one in which the relationship between power spectral density versus frequency is a power law and the scaling exponent of the power law characterizes the change across the frequencies analyzed.  The scaling exponent can also be determined using wavelet analysis.  The change in shoreline position between the 2006 and 2007 surveys for the relatively undeveloped, low lying Core Banks is characterized by the lowest scaling exponent, 0.8.  For regions north of the Core Banks, with higher dunes and more anthropogenic impact, scaling exponents range from 1.2 to 1.5 and are consistent with a diffusion process.   Higher scaling exponents, near 2.0, that characterized annual change north of Cape Hatteras between 1997 and 1998 were not observed for the change that occurred between 2006 and 2007.  For both time intervals, the magnitude of the scaling exponent generally increases from south to north.\n","4"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Spectral Analysis of Unevenly Sampled Data via Uniform Resampling","NG23B-1559","1:40 PM","1:40 PM","B.   Rigling*","B.   Rigling*","Wright State University","Sessioned","Body: Acquisition of data in the field often cannot be precisely controlled, resulting in samples in time that occur sporadically without a uniform inter-sample interval and/or with irregular gaps.  Spectral analysis of unevenly sampled and gapped data is problematic because nearly all spectral analysis techniques require uniformly sampled data in time without gaps.  Processing data that is unevenly spaced using conventional spectral methods can result in significant and unpredictable errors and biases.We present a two step method for transforming an unevenly spaced data set into a uniformly spaced data set that permits use of conventional spectral analysis methods.  In the first step, a slotted resampling is used to map the unevenly spaced data to an evenly spaced sampling, which can result in gapped samples for which no value was effectively measured.  The second step iteratively fits an autoregressive model to the existing samples in order to fill in the gaps with samples that are statistically consistent.  While unable to recover the missing data, this method does mitigate biases that can be introduced by gaps and allows the data to be processed with conventional spectral analysis techniques.Our method has been extensively tested using uniformly spaced  synthetic self-affine  time series data sets with scaling exponents ranging from zero to three.  Gap patterns taken from natural data sets are introduced to the synthetic data set.  The gapped data set is transformed, the spectral analysis is performed, and the scaling exponent is measured and compared to the scaling exponent of the original data set.  The results show that the method is robust and that the accuracy of the scaling exponent is good to the first/second decimal place. In contrast to the results of our method, the often used Lomb periodogram method for spectral analysis of uneven/gapped data is shown to return highly inaccurate values of the scaling exponent.\n","5"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","New significance test methods for Fourier analysis of geophysical time series","NG23B-1560","1:40 PM","1:40 PM","Z.   Zhang*","Z.   Zhang*; J. C.  Moore","Beijing Normal University","Sessioned","Body: When one applies the discrete Fourier transform to analyze finite-length time series, discontinuities at the data boundaries will distort its Fourier power spectrum. In this paper, based on a rigid statistics framework, we present a new significance test method which can extract the intrinsic feature of a geophysical time series very well. We show the difference in significance level compared with traditional Fourier tests by analyzing the Arctic Oscillation (AO) and the Nino3.4 time series. In the AO, we find significant peaks at about 2.8, 4.3, and 5.7 yr periods and in Nino3.4 at about 12 yr period in tests against red noise. These peaks are not significant in traditional tests.\nURL: http://www.nonlin-processes-geophys.net/18/643/2011/npg-18-643-2011.html\n","6"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Spatial patterns of soil water storage and its multi-scale controls","NG23B-1561","1:40 PM","1:40 PM","A.   Biswas*","A.   Biswas*","CSIRO; University of Saskatchewan","Sessioned","Body: Information on the spatio-temporal distribution of soil water storage (SWS) has important climatic, ecologic and hydrologic applications. Different factors and processes operating at different intensities and at different space-time scales result in strong spatio-temporal variability in SWS. Such variability makes hydrological prediction difficult. This study was undertaken to examine the similarity of the spatial patterns of SWS at multiple scales, and their dominant controls. SWS up to 1.4 m depth was measured using a neutron probe and time domain reflectometry along a 576 m long transect for a period of 5 years. The site was within the hummocky landscape of the Canadian Prairie pothole region. There was visual as well as statistical similarity in the spatial patterns of SWS over time, which indicated a resemblance in the underlying processes controlling the patterns in the field. The patterns were more similar for measurements completed within a season (intra-season) or between the same seasons in different years (inter-annual), less similar when comparing different seasons within the same year (inter-season). The use of wavelet transformation and wavelet coherency helped examine the scales and locations of similarity of the spatial patterns. The Hilbert-Huang transform was introduced to untangle complex nonlinear spatial patterns at different scales and identify scale specific controls. Similarity in spatial patterns were also observed at different (multiple) spatial scales. The strongest similarity was at the scale contributed from the macro-topography and dominant landscape features. Variations in landform units and local topographic features changed the hydrologic controls of SWS at medium scales (18 to 72 m). Micro-topographical variability was reflected in the spatial patterns at small scales over time. Similarity between spatial patterns at different soil depths was also observed. Quantitative information on the spatial patterns of SWS enables: (i) use of surface water measurements to make inferences on deep layer hydrological processes and groundwater dynamics, (ii) identification of locations in the field that best represent field averaged SWS and can be used to improve sampling efficiency, and (iii) identification of hydrologically homogeneous units which can be used to design representative sampling. The scale information can be used to improve prediction of both surface and subsurface hydrological processes to support environmental management.\n","7"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Detecting Randomness: the Sensitivity of Statistical Tests to Deviations from a Constant Rate Poisson Process","NG23B-1562","1:40 PM","1:40 PM","A. J.  Michael*","A. J.  Michael*","USGS","Sessioned","Body: Detecting trends in the rate of sporadic events is a problem for earthquakes and other natural hazards such as storms, floods, or landslides. I use synthetic events to judge the tests used to address this problem in seismology and consider their application to other hazards.Recent papers have analyzed the record of magnitude ≥7 earthquakes since 1900 and concluded that the events are consistent with a constant rate Poisson process plus localized aftershocks (Michael, GRL, 2011; Shearer and Stark, PNAS, 2012; Daub et al., GRL, 2012; Parsons and Geist, BSSA, 2012). Each paper removed localized aftershocks and then used a different suite of statistical tests to test the null hypothesis that the remaining data could be drawn from a constant rate Poisson process. The methods include KS tests between event times or inter-event times and predictions from a Poisson process, the autocorrelation function on inter-event times, and two tests on the number of events in time bins: the Poisson dispersion test and the multinomial chi-square test. The range of statistical tests gives us confidence in the conclusions; which are robust with respect to the choice of tests and parameters.  But which tests are optimal and how sensitive are they to deviations from the null hypothesis? The latter point was raised by Dimer (arXiv, 2012), who suggested that the lack of consideration of Type 2 errors prevents these papers from being able to place limits on the degree of clustering and rate changes that could be present in the global seismogenic process.I produce synthetic sets of events that deviate from a constant rate Poisson process using a variety of statistical simulation methods including Gamma distributed inter-event times and random walks. The sets of synthetic events are examined with the statistical tests described above.  Preliminary results suggest that with 100 to 1000 events, a data set that does not reject the Poisson null hypothesis could have a variability that is 30% to 10% greater than the inherent variability of a Poisson process, respectively. E.g., if there are 1000 events in a century-long data set, then a Poisson process predicts that there will be 100±10 (1 s.d.) events in a decade.  But given the limits of the data there could be 100±11 events. Or if there are 100 events in a century, then the prediction of 10±3 events in a decade widens to 10±4.  For a smaller data set of 20 events per century, the increase in possible variability is 300% and the decadal forecast of 2±1.4 events becomes 2±4. Thus, the existing statistical tests are able to produce useful limits on forecasts for moderate-sized data sets but not for very small ones.Will we obtain similar results if we apply these tests to atmospheric events, which undergo annual and other cycles? Binning the data could minimize the effect of these cycles on these methods. However, based on these synthetic data sets, binning reduces the sensitivity of the tests, especially for larger data sets.  In seismology, the effects of localized clustering can be addressed either by removing the aftershocks or transforming the event times such that the known clustering appears to be Poisson in transformed time and doing the tests in that transformed space. If similar approaches are appropriate for other natural hazards, then we can use the same methods across different fields.\n","8"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","1/f and the Earthquake Problem:Scaling constraints that facilitate operational earthquake forecasting","NG23B-1563","1:40 PM","1:40 PM","m. r.  yoder*","m. r.  yoder*; J. B.  Rundle; D. L.  Turcotte","University of California Davis; University of California Davis; Santa Fe Institute; California State University Chico","Sessioned","Body: The difficulty of forecasting earthquakes can fundamentally be attributed to the self-similar, or “1/f”, nature of seismic sequences. Specifically, the rate of occurrence of earthquakes is inversely proportional to their magnitude m, or more accurately to their scalar moment M. With respect to this “1/f problem,” it can be argued that catalog selection (or equivalently, determining catalog constraints) constitutes the most significant challenge to seismicity based earthquake forecasting. Here, we address and introduce a potential solution to this most daunting problem. Specifically, we introduce a framework to constrain, or partition, an earthquake catalog (a study region) in order to resolve local seismicity. In particular, we combine Gutenberg-Richter (GR), rupture length, and Omori scaling with various empirical measurements to relate the size (spatial and temporal extents) of a study area (or bins within a study area) to the local earthquake magnitude potential – the magnitude of earthquake the region is expected to experience. From this, we introduce a new type of time dependent hazard map for which the tuning parameter space is nearly fully constrained. In a similar fashion, by combining various scaling relations and also by incorporating finite extents (rupture length, area, and duration) as constraints, we develop a method to estimate the Omori (temporal) and spatial aftershock decay parameters as a function of the parent earthquake's magnitude m. From this formulation, we develop an ETAS type model that overcomes many point-source limitations of contemporary ETAS. These models demonstrate promise with respect to earthquake forecasting applications. Moreover, the methods employed suggest a general framework whereby earthquake and other complex-system, 1/f type, problems can be constrained from scaling relations and finite extents.\n","9"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Application of the fractional Levy motion to precipitation data","NG23B-1564","1:40 PM","1:40 PM","Y.   Kuzuha*","Y.   Kuzuha*; S.   Tachinami; C.   Gomi","Mie University","Sessioned","Body: We applied the fractional Lévy motion model to precipitation data, referring to Lavallée (2004) and Lavallée (2008). The data we used were from the Global Preciptiation Climatology Centre (GPCC) monthly precipitation dataset. These data consist of 360 (longitude) × 180 (latitude) × 1336 (monthly, 1901–2012). First, we constructed four datasets: time series of average monthly precipitation of the top (maximum) 1000 precipitation observation stations, top 10, top 100, and top 500. Next, according to Lavallée (2004) and Lavallée (2008), using Fourier transformation, convolution (filtering) and inverse Fourier transformation, we obtained random variables Xt (Lavallée, 2004) from Yt (precipitation). We transformed from Yt to Xt. Finally, we fitted the Lévy law to Xt. As a preliminary result, we present examples of the values of the Lévy law parameters: alpha, beta, gamma, and delta for the “top 100” dataset. Parameters obtained were (1.17, 0.0, 257.6, 0.28; maximum likelihood), (1.10, 0.0, 250.0, -0.99; quantile algorithm), and (1.20, 0.0, 265.1, 0.57; empirical characteristic function algorithm). We used J. P. Nolan’s algorithm. The values are quite sensitive to the algorithm that is used. At the Fall meeting, we will present considerations and results obtained using precipitation data other than those of the GPCC.J. P. Nolan, http://academic2.american.edu/~jpnolan/stable/stable.htmlLavallée (2004), Stochastic modeling of climatic variability in dendrochronology, GRL, 31, L15202.Lavallée (2008), On the random nature of earthquake sources and ground motions; a unified theory, Advances in Geophysics, 50, chapter 16.Acknowledgement: We thank Dr. D. Lavallee for his comments and suggestions.\n","10"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Earthquakes and tidal records in the Mediterranean sea: case studies.","NG23B-1565","1:40 PM","1:40 PM","A.   Vecchio*","A.   Vecchio*; M.   Anzidei; V.   Carbone; V.   Capparelli; I.   Guerra; G.   Arena","Universita' della Calabria; Istituto Nazionale di Geofisica e Vulcanologia; Ispra","Sessioned","Body: We show and discuss the analysis of tidal data from some selected tide gauge stations located in the Mediterranean sea, including the Italian tide gauge network consisting in 30 stations. Our goal is to study the effects of large and moderate magnitude earthquakes on tidal oscillations. We focus on three seismic events: i) the March 11th, 2011, M 9.0 Tohoku-Oki earthquake, generating a giant tsunami offshore the Honshu island (Japan) that propagated in the Oceans. We show that the tidal stations located in the Mediterranean have recorded a weak signal that disturbed the daily tidal trends; ii) the May 21th, 2003, M 6.8 Boumerdès earthquake in northern Algeria, that generated a small tsunami event that reached the coast of Southern Europe; iii) the Dicember 17th, 2008, M 5.3 earthquake located in the Tyrrhenian sea. Finally, we also analyzed a sea level data set containing an anomalous tidal signal not related to earthquakes, felt along Thyrrhenian coast of Italy on July 2012. Tidal data were reduced for inverse barometric correction and analyzed by an advanced filtering technique that decomposes the records through oscillating modes, identifying the contributions at different timescales. In particular we focused on the dynamical behavior of the main tidal components (24 and 12 hours) and of low-frequency processes and trends. \n","11"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Nonlinear study of seismicity in the Mexican subduction zone by means of visual recurrence analysis","NG23B-1566","1:40 PM","1:40 PM","A.   Ramirez Rojas*","A.   Ramirez Rojas*; R. L.  Moreno-Torres","Universidad Autónoma Metropolitana; Universidad Autónoma Metropolitana","Sessioned","Body: The subduction in the Mexican South Pacific coast might be approximated as a subhorizontal slab bounded at the edge by the steep subduction geometry of the Cocos plate beneath the Caribbean plate to the east and of the Rivera plate beneath North America to the west. Singh et al. (1983), reported a study that takes into account the geometry of the subducted Rivera and Cocos plates beneath the North American lithosphere defining, according their geometry, four regions: Jalisco, Michoacán, Guerrero and Oaxaca. In this work we study the seismicity occurred in Mexico, for each region, by means of the visual recurrence analysis (VRA). Our analysis shows important differences between each region that could be associated with nonlinear dynamical properties of each region. Singh, S.K., M. Rodriguez, and L. Esteva (1983), Statistics of small earthquakes and frequency of occurrence of large earthquakes along the Mexican subduction zone, Bull. Seismol. Soc. Am. 73, 6A, 1779-1796.\n","12"
"NG23B.* Scaling and Correlations and Their Use in Forecasting Natural Hazards II Posters","NG23B","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Paleoceanography and Paleoclimatology (PP)Seismology (S)","Evidence of self organization in great Sumatra earthquakerecurrence times: Implications for coupling of tidal forcing and tectonic stress accumulation ","NG23B-1567","1:40 PM","1:40 PM","R. K.  Tiwari*","R. K.  Tiwari*; K.   Puli","CSIR-National Geophysical Research Institute","Sessioned","Body:   We analyzed inter- event time series of earthquake activities (M≥ 5) of Sumatra region spanning over 1973 to 2009 using techniques of nonlinear dynamics. The earthquake data were taken from the USGS catalogue centered on latitude 3.240N and longitude 95.825E. As a first step, in our analyses we computed the rank order statistics which revealed mixed response of earthquake dynamics indicating distinct breaks in slope of the rank order. This suggests that earthquake dynamics in this region is partly unstable and partly “self-organized” with a random tail. Comparison of return maps of the earthquakes inter- event time series with those representing random, stochastic and chaotic processes shows a quasi-deterministic behavior of earthquake genesis in the region. We further assessed the dimensionality of earthquake-generating mechanisms using a nonlinear predictor technique on two dimensional phase portrait constructed by recurrence time series. The nonlinear forecasting analysis suggests that the earthquake processes in the Sumatra region evolve on a non-random low-dimensional chaotic plane. Further, “K2” Entropy revealed a coherent structure indicating the deterministic dynamical pattern. This analysis is consistent with “self-organized” processes which could be explained invoking earth’s internal dynamics, where, impulsively derived interdependencies cascades through the stress generated by tectonic plate movement. Our results, however, do not preclude the role of coupling of the above self-organized system with tidal forcing. Evidence for such a coupling in this region exists as ‘triggering force”.Keywords:  Sumatra Earthquakes, Quasi-deterministic, Stochastic, Chaotic, Self-organized, K2 entropy, Phase portrait.\nURL: http://www.ngri.org.in\n","13"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Spectral Gap Energy Transfer in Atmospheric Boundary Layer ","NG23C-1568","1:40 PM","1:40 PM","S.   Bhushan*","S.   Bhushan*; K.   Walters; A. P.  Barros; M.   Nogueira","Mississippi State University; Duke University","Sessioned","Body: Experimental measurements of atmospheric turbulence energy spectra show E(k) ~ k-3 slopes at synoptic scales (~ 600 km – 2000 km) and k-5/3 slopes at the mesoscales (< 400 km). The -5/3 spectra is presumably related to 3D turbulence which is dominated by the classical Kolmogrov energy cascade. The -3 spectra is related to 2D turbulence, which is dominated by strong forward scatter of enstrophy and weak forward scatter of energy. In classical 2D turbulence theory, it is expected that a strong backward energy cascade would develop at the synoptic scale, and that circulation would grow infinitely. To limit this backward transfer, energy arrest at macroscales must be introduced. The most commonly used turbulence models developed to mimic the above energy transfer include the energy backscatter model for 2D turbulence in the horizontal plane via Large Eddy Simulation (LES) models, dissipative URANS models in the vertical plane, and Ekman friction for the energy arrest.One of the controversial issues surrounding the atmospheric turbulence spectra is the explanation of the generation of the 2D and 3D spectra and transition between them, for energy injection at the synoptic scales. Lilly (1989) proposed that the existence of 2D and 3D spectra can only be explained by the presence of an additional energy injection in the meso-scale region. A second issue is related to the observations of dual peak spectra with small variance in meso-scale, suggesting that the energy transfer occurs across a spectral gap (Van Der Hoven, 1957). Several studies have confirmed the spectral gap for the meso-scale circulations, and have suggested that they are enhanced by smaller scale vertical convection rather than by the synoptic scales. Further, the widely accepted energy arrest mechanism by boundary layer friction is closely related to the spectral gap transfer.This study proposes an energy transfer mechanism for atmospheric turbulence with synoptic scale injection, wherein the generation of 2D and 3D spectra is explained using spectral gap energy transfer. The existence of the spectral gap energy transfer is validated by performing LES for the interaction of large scale circulation with a wall, and studying the evolution of the energy spectra both near to and far from the wall. Simulations are also performed using the Advanced Weather and Research Forecasting (WRF-ARW) for moist zonal flow over Gaussian ridge, and the energy spectra close and away from the ground are studied. The energy spectra predicted by WRF-ARW are qualitatively compared with LES results to emphasize the limitations of the currently used turbulence parameterizations. Ongoing validation efforts include: (1) extending the interaction of large scale circulation with wall simulations to finer grids to capture a wider range of wavenumbers; and (2) a coupled 2D-3D simulation is planned to predict the entire atmospheric turbulence spectra at a very low computational expense.The overarching objective of this study to develop turbulence modeling capability based on the energy transfer mechanisms proposed in this study. Such a model will be implemented in WRF-ARW, and applied to atmospheric simulations, for example the prediction of moisture convergence patterns at the meso-scale in the southeast United States (Tao & Barros, 2008).\n","1"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Rainfall Climatology of the US Based on a Multifractal Storm Model","NG23C-1569","1:40 PM","1:40 PM","C.   Lepore*","C.   Lepore*; A.   Molini; D.   Veneziano; S.   Yoon","MIT; Masdar Institute of Science and Technology","Sessioned","Body: Whether the multifractal properties of rainfall are impacted by climatology and therefore deviate from universality is a vexing question in both hydrology and the climate sciences and a crucial issue for rainfall downscaling applications. In a recent paper, Veneziano and Lepore (The Scaling of Temporal Rainfall, WRR, 2012) suggested a rainfall model with alternating storms and dry inter-storm periods and beta-lognormal multifractal rainfall intensity inside the storms. The parameters of the model are the rate of storm arrivals $\lambda$, the mean value $m_D$ and coefficient of variation $V_D$ of storm duration, the mean rainfall intensity inside the storms $m_I$, and the multifractal parameters $C_\beta$ (lacunarity), $C_{LN}$ (intermittency), and $d_{max}$ (outer limit of the scaling range). We use this model and 200 hourly rainfall records from NOAA to describe the variability of intense rainfall over the continental US. The records are selected based on length (at least 25 years) and data quality (quantization, fraction of unavailable values, periods when rainfall is reported as aggregated total depth…). We conclude that $C_{LN}$ and $d_{max}$ display large systematic variations in space and with season. In particular, $C_{LN}$ decreases as latitude increases, from 0.20-0.25 along the Gulf of Mexico to about 0.12 in New England and 0.08 in the Northwest. This spatial variation is captured in approximation by partitioning the continental US into 11 climatic regions. Seasonal analysis shows that in most regions $C_{LN}$ is highest in the summer and lowest in the winter, following similar variations in the frequency and intensity of convective rainfall. An exception is the Northwest region, where $C_{LN}$ is almost constant throughout the year. The outer scale $d_{max}$ is negatively correlated with $C_{LN}$ and follows opposite trends. The lacunarity parameter $C_\beta$ is lowest (around 0.04) in the Northeast and highest (around 0.07) in Florida and the Midwestern region. Lacunarity tends to be higher in the spring and summer. Analysis in time using consecutive 10-yr windows and data aggregation by climatic region shows virtually no trend and fluctuations that are far smaller than the seasonal and regional effects. We also study the spatial and temporal variation of the non-multifractal parameters $\lambda$, $m_D$, $V_D$, and $m_I$. Finally, we investigate the relationships between the multifractal parameters and (a) indices of atmospheric convection like the convective available potential energy and the frequency of thunderstorms and (b) simple statistical properties of positive hourly rainfall like the coefficient of variation and the probability of exceeding thresholds that are often used to differentiate between convective and frontal regimes or shallow and deep convection. Statistics of the “b” type have the highest positive correlation with $C_{LN}$.\n","2"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Water Storage Dynamics of Saturated and Unsaturated Zones and its Function in Hydrological Modeling","NG23C-1570","1:40 PM","1:40 PM","X.   Chen*","X.   Chen*; Z.   Zhang; M.   Gao; Q.   Song","Hohai University; Hohai University","Sessioned","Body: Subsurface water storage for hydrological processes can be divided into unsaturated soil moisture and saturated water storage (a shallow groundwater aquifer). Surface layer moisture content is a state variable that is either simulated or required as input in many hydrological models. The high or low of the shallow groundwater reservoir fast or slow of saturated flow and flow discharges from the catchment outlet. As a result of heterogeneity of soil properties, topography, land cover, evapotranspiration and precipitation, the soil moisture content and the shallow groundwater reservoir is highly variable in three-dimensional space and time (Engman, 1974; Wood et al., 1992). Expression of heterogeneity of soil moisture content and the shallow groundwater storage is critical for hydrological model development and success in hydrological simulation.    In this study, we developed a new hydrological model with functions of water storage dynamics of saturated and unsaturated zones. A mathematical expression of topographic and soil controlled spatial heterogeneity of soil moisture holding capacity was derived in terms of Van Genuchten model and topographical index. The subsurface store and storage-discharge process is expressed by a horizontal Boussinesq equation with a power law hydraulic conductivity profile (Rupp and Selker, 2005). The “top-down” approach according to unsaturated accounting and the “bottom-up” approach according to baseflow separation were used to integrate both storage dynamics for developing the new model. The top-down and bottom-up methods enable the model parameters to be determined according to watershed soil, topography and flow discharge.Model testing was carried out in a number of nested sub-basins of a watershed (Huangnizhuang River in Huaihe basin) in the humid region in China. Simulation results show that the model is capable of describing spatial and temporal variations of water balance components, including soil moisture content, shallow groundwater storage, evapotranspiration and runoff, over the watershed. References:Engman, E.T., Rogowski, A.S. 1974. A partial area model for storm flow synthesis. Water Resources Research, 10: 464 – 472.Rupp D R, Selker J S. 2005. Drainage of a horizontal Boussinesq aquifer with a power law hydraulic conductivity profile.Water Resource Research, 41, W11422,  doi:10.1029/2005WR004241.Wood, E.F., Lettenmaier, D.P., Zatarian, V.G. 1992. A land surface hydrology parameterization with subgrid variability for general circulation models. Journal of Geophysical Research, 97: 2717 – 2728.\n","3"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Fractal analysis of intraplates seismicity in the central zone of Chile","NG23C-1571","1:40 PM","1:40 PM","D.   Pasten*","D.   Pasten*; V.   Munoz; J. A.  Valdivia","Universidad de Chile; Universidad de Chile; CEDENNA","Sessioned","Body: A fractal and multifractal study in a sample of superfitial interplate andintraplate earthquakes in central zone of Chileis made. The change in the value of the capacity dimension in amodified sample of superficial earthquakes is computed. This analysis ismade in two and three dimensions. Conclude that the intraplates earthquakes present a fractal behaviour, just like the complete data set.\n","4"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Construction of permeability maps from porosity logs using fractal approach","NG23C-1572","1:40 PM","1:40 PM","V. P.  Dimri*","V. P.  Dimri*","Nat''l Geophysical Res. Inst.","Sessioned","Body: Analysis of permeability data from several wells show that permeability follows fractal behaviour. Often permeability is measured using rock samples in the laboratory or using well tests, however, such data is often very sparse and takes long time to generate such data for reservoir simulation purpose. Hence, we present an alternative approach to generate permeability maps using porosity logs from the wells. This approach relies on the fractal dimension analysis of the grain size distribution of the rock samples and tortuosity of the representative rock samples of the reservoir. Our analysis is based on the several real field well logs having porosity measurements. We have compared the permeability values obtained from fractal method from the observed values in the laboratory and it agrees very well. Hence, our method will be useful in generating reliable permeability maps for the reservoir simulation from easily available porosity (Neutron and Density logs) logs.\n","5"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Depth to the bottom of magnetic sources (DBMS) from aeromagnetic data of Central India using modified centroid method for fractal distribution of sources ","NG23C-1573","1:40 PM","1:40 PM","A. R.  Bansal*","A. R.  Bansal*; S.   Anand; M.   Rajaram; V.   Rao; V. P.  Dimri","CSIR-National Geophysical Research Institute; Indian Institute of Geomagnetism","Sessioned","Body: The depth to the bottom of the magnetic sources (DBMS) may be used as an estimate of the Curie – point depth. The DBMSs can also be interpreted in term of thermal structure of the crust. The thermal structure of the crust is a sensitive parameter and depends on the many properties of crust e.g. modes of deformation, depths of brittle and ductile deformation zones, regional heat flow variations, seismicity, subsidence/uplift patterns and maturity of organic matter in sedimentary basins. The conventional centroid method of DBMS estimation assumes random uniform uncorrelated distribution of sources and to overcome this limitation a modified centroid method based on fractal distribution has been proposed. We applied this modified centroid method to the aeromagnetic data of the central Indian region and selected 29 half overlapping blocks of dimension 200 km x 200 km covering different parts of the central India. Shallower values of the DBMS are found for the western and southern portion of Indian shield. The DBMSs values are found as low as close to middle crust in the south west Deccan trap and probably deeper than Moho in the Chhatisgarh basin. In few places DBMS are close to the Moho depth found from the seismic study and others places shallower than the Moho. The DBMS indicate complex nature of the Indian crust.\n","6"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Singularity analysis of multiple upward continuations to detect edges in potential field data","NG23C-1574","1:40 PM","1:40 PM","S.   Lovejoy*","S.   Lovejoy*; Z.   Chen; Q.   Cheng","China University of Geoscience; China University of Geosciences (Wuhan); York University; McGill University","Sessioned","Body: In geophysical applications, a number of filters are available to sharpen, de-noise or enhance the data in order to facilitate the interpretation. However, such filters are often implemented in the Fourier domain. Hence, they are not local, acting on all features simultaneously. Detecting strong gradients and edges in potential field data are one of the important tasks to infer geological structures indicating the edges of source bodies. Edges are identified by local singularity analysis combing multiple depth level upward continuations are provided by authors. Sources close to the surface induce short-wavelength anomalies in the signal, whereas sources deep underground induce long-wavelength anomalies in the signal. Upward continuation allows the data to be smooth, attenuates short wavelengths in the signal stronger than long wavelengths so as to highlight deep sources that might be hidden by shallow sources or noise. A useful of local singularity model based on multifractal theory suggested by Qiuming Cheng has gained significant attention in characterizing mineralization and predicting mineral deposits. Especially, this model has had impressive successes in the weak anomaly identification, interpolation for geochemical data. Thus, we create the multiple upward continuation grids of the observed potential field data at various heights. We recommend to add a small value to shift the raw data (>0), and reduce the magnetic data to the pole firstly or even convert it to pseudogravity. Then the singularity indexes are estimated by the multiple heights versus upward continuations under the power law. We take the airborne gravity data and aeromagnetic data in the East Tianshan mountains with desert cover area in Xinjiang province, China as a case study. The singularity spatial distribution for the gravity data in the East Tianshan mountains area indicates the regional deep faults and The singularity spatial distribution for the aeromagnetic data implies the probable host anomaly geobodies of iron-related ore deposits.\n","7"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Electromagnetic Induction in Rough Geologic Media: The Classical Approach","NG23C-1575","1:40 PM","1:40 PM","C. J.  Weiss*","C. J.  Weiss*; M. E.  Everett; J.   Ge","Virginia Tech; Texas A&M","Sessioned","Body: Electromagnetic (EM) induction methods are well known to be sensitive indicators of electrically conducting subsurface mineral and fluid phases, responding to both the topological connectedness of the conducting phase and galvanic charge buildup on conductivity boundaries.  Key to quantifying the relationship between electromagnetic signatures and the underlying the geohydrology is accurate representation of the infinitely complex, conducting Earth in terms of a finite set of model parameters and their associated physics.  However, field observations of the spatial variability of induced EM fields and their inferred rate of diffusive propagation suggest that simple, piecewise smooth or continuous models of electrical conductivity -- as commonly depicted in numerical modeling -- may not fully capture the relevant electrodynamics in all geologic settings, especially those where the subsurface  is characterized by multi-scale, hierarchical structures such as fractures.   Consistent with such observations is a recasting of the Maxwell Equations in terms of fractional calculus, similar to that done routinely in hydrology for the transport equations to explain anomalous hydrologic diffusion, where the underlying multi-scale complexity is captured efficiently by only a few, simple, model parameters. This study focuses on how geo-complexity ultimately manifests its EM signature in a fractional-calculus sense through three-dimensional modeling of spatially-correlated stochastic realizations of the electrically conducting subsurface.  Preliminary results simulating the response of a frequency-domain, loop-loop system suggest that heterogeneity proximal to the transmitting antenna generates a strong, but relatively smooth response in the near-field vertical magnetic induction when compared to that in the far field.  This finding suggests an exploration strategy based on multi-offset observations may be relevant to quantifying the length scale over which the fractional calculus model holds.\n","8"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Multifractal Scaling of Grayscale Patterns: Lacunarity and Correlation Dimension","NG23C-1576","1:40 PM","1:40 PM","A.   Roy*","A.   Roy*; E.   Perfect","University of Tennessee - Knoxville","Sessioned","Body: While fractal models can characterize self-similarity in binary fields, comprised solely of 0’s and 1’s, the concept of multifractals is needed to quantify scaling behavior in non-binary grayscale fields made up of fractional values. Multifractals are characterized by a spectrum of non-integer dimensions, <i>D<sub>q</sub></i> (-∞ < <i>q</i> < +∞) instead of a single fractal dimension. The gliding-box algorithm is sometimes employed to estimate these different dimensions. This algorithm is also commonly used for computing another parameter, lacunarity, <i>L</i>, which characterizes the distribution of gaps or spaces in patterns, fractals, multifractals or otherwise, as a function of scale (or box-size, <i>x</i>). In the case of 2-dimensional multifractal fields, <i>L</i> has been shown to be theoretically related to the correlation dimension, <i>D<sub>2</sub></i>, by dlog(<i>L</i>)/dlog(<i>x</i>) = <i>D<sub>2</sub></i> - 2. Therefore, it is hypothesized that lacunarity analysis can help in delineating multifractal behavior in grayscale patterns. In testing this hypothesis, a set of 2-dimensional multifractal grayscale patterns was generated with known <i>D<sub>2</sub></i> values, and then analyzed for lacunarity by employing the gliding-box algorithm. The <i>D<sub>2</sub></i> values computed using this analysis gave a 1:1 relationship with the known <i>D<sub>2</sub></i> values, thus empirically validating the theoretical relationship between <i>L</i> and <i>D<sub>2</sub></i>. Lacunarity analysis was further used to evaluate the multifractal nature of natural grayscale images in the form of soil thin sections that had been previously classified as multifractals based on the standard box counting method. The results indicated that lacunarity analysis is a more sensitive indicator of multifractal behavior in natural grayscale patterns than the box counting approach. A weighted mean of the log-transformed lacunarity values at different scales was employed for differentiating between grayscale patterns with various degrees of scale dependent clustering attributes. This new measure, which expresses lacunarity as a single number, should prove useful to researchers who want to explore the correlative influence of texture on, for instance, flow and transport parameters. The advantage of using lacunarity instead of <i>D<sub>2</sub></i> in this context is that it can also be applied to natural grayscale fields that are not strictly multifractals.\n","9"
"NG23C. Scaling and Fractals in Climate, Hydrology, and Exploration Geophysics II Posters","NG23C","Poster","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)","Scaling and universality in microbial size spectra","NG23C-1577","1:40 PM","1:40 PM","A.   Giometto*","A.   Giometto*; F.   Altermatt; F.   Carrara; A.   Maritan; A.   Rinaldo","École Polytechnique Fédérale Lausanne; Eawag: Swiss Federal Institute of Aquatic Science and Technology; Università di Padova; Università di Padova","Sessioned","Body: In this work, focus is placed on the mass distribution of individual organisms of a given species in laboratory communities of protists. The relevance of the work pertains the importance of the variability of body size – currently neglected by most theoretical approaches or simply synthesized by the species’ mean body mass – in a broad spectrum of issues ranging from the interpretation of Kleiber’s law and of intertwined macroecological laws, to the ubiquity of broad, often scale-free community size spectra in nature. Here, it is shown experimentally that single species’ size distributions for thirteen different protists’ species spanning four orders of magnitude exhibit certain regularities well captured by a finite-size scaling distribution. In fact, once suitably rescaled, they collapse onto the same distribution regardless of the vast differences in their size. This is found to apply over four orders of magnitude in mass, thus suggesting the existence of an underlying universal mechanism shaping the size distribution of such organisms. In addition, the theoretical origins of the experimental result are addressed and a simple model of cell growth and division is shown to account for the main features of the observed universality. Environmental forcing of various kinds is shown not to affect the scaling result. It is claimed that this work provides a significant contribution to a number of open problems in ecology, like for instance the long-lasting dispute on linked scaling exponents in macroecological empirical relations. In fact, the characterization of the fluctuations in the mass of organisms enters directly several ecological scaling laws and the embedded account for whole size distributions (as opposed to mean body mass alone) acts as the explanatory variable for a number of current debates.\n","10"
"NG23D. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences I","NG23D","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","2:55 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Stochastic data assimilation methods for ocean state estimation <i>(Invited)</i>","NG23D-01","1:40 PM","2:10 PM","S. R.  Keating*","S. R.  Keating*; A.   Majda; K.   Smith","New York University","Sessioned","Body: Satellite altimetry is now routinely used to measure upper ocean currents and provides an invaluable tool for estimating the state of the ocean. However, contemporary altimetry products do not fully resolve the turbulent spectrum of the ocean and often underestimate eddy transports like the poleward heat flux. In this talk, I will discuss a suite of inexpensive new data assimilation methods for ocean state estimation using stochastic turbulence models for the nonlinear, non-Gaussian dynamics of the unresolved scales. The stochastic model parameters can be estimated on-the-fly, enabling the model to adapt to temporal intermittency in the flow. Moreover, by extracting high-wavenumber information that has been aliased into the low wavenumber band, one can derive ``stochastically superresolved'' velocity fields with a nominal resolution increase of double or more, greatly improving estimates of eddy transport. The skill of these computationally inexpensive strategies is tested in idealized simulations of geostrophic turbulence and high-resolution primitive equation simulations of ocean turbulence with realistic stratification.\nURL : http://www.cims.nyu.edu/~skeating/\n","1"
"NG23D. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences I","NG23D","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","2:55 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","How Do You Determine Whether The Earth Is Warming Up? <i>(Invited)</i>","NG23D-02","2:10 PM","2:40 PM","J. M.  Restrepo*","J. M.  Restrepo*; D.   Comeau; H.   Flaschka","Univ of Arizona; University of Arizona; University of Arizona","Sessioned","Body: How does one determine whether the extreme summer temperatures in the North East of the US, or  in Moscow during the summer of 2010, was an extreme weather fluctuation or the result of a systematic global climate warming trend?It is only under exceptional circumstances that one can determine whether an observational climate signal belongs to a particular statistical distribution. In fact, observed climate signals are rarely statistical and thus there is usually no way to rigorously obtain enough field data to produce a trend or tendency, based upon data alone. Furthermore, this type of datais often multi-scale.We propose a trend or tendency methodology that does not make use of a parametric or a statistical assumption. The most important feature of this trend strategy is that it is defined in very precise mathematical terms. The tendency is easily understood and practical, and its algorithmic realization is fairly robust. In addition to proposing a trend, the methodology can be adopted to generate surrogate statistical models, useful in reduced filtering schemes of time dependent processes.\nURL : www.math.arizona.edu/~restrepo\n","2"
"NG23D. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences I","NG23D","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","1:40 PM","2:55 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Real-time forecasting and predictability of catastrophic failure events: from rock failure to volcanoes and earthquakes","NG23D-03","2:40 PM","2:55 PM","I. G.  Main*","I. G.  Main*; A. F.  Bell; M.   Naylor; M.   Atkinson; R.   Filguera; P. G.  Meredith; N.   Brantut","Univ Edinburgh; University of Edinburgh; University College London","Sessioned","Body: Accurate prediction of catastrophic brittle failure in rocks and in the Earth presents a significant challenge on theoretical and practical grounds. The governing equations are not known  precisely, but are known to produce highly non-linear behavior similar to those of near-critical dynamical systems, with a large and irreducible stochastic component due to material heterogeneity.   In a laboratory setting mechanical, hydraulic and rock physical properties are known to change in systematic ways prior to catastrophic failure, often with significant non-Gaussian fluctuations about the mean signal at a given time, for example in the rate of remotely-sensed  acoustic emissions.    The effectiveness of such signals in real-time forecasting has never been tested before in a controlled laboratory setting, and previous work has often been qualitative in nature, and subject to retrospective selection bias, though it has often been invoked as a basis in forecasting natural hazard events such as volcanoes and earthquakes.   Here we describe a collaborative experiment in real-time data assimilation to explore the limits of predictability of rock failure in a best-case scenario.  Data are streamed from a remote rock deformation laboratory to a user-friendly portal, where several proposed physical/stochastic models can be analysed in parallel in real time, using a variety of statistical fitting techniques, including least squares regression, maximum likelihood fitting, Markov-chain Monte-Carlo and Bayesian analysis.  The results are posted and regularly updated on the web site prior to catastrophic failure, to ensure a true and and verifiable prospective test of forecasting power.  Preliminary tests on synthetic data with known non-Gaussian statistics shows how forecasting power is likely to evolve in the live experiments.  In general the predicted failure time does converge on the real failure time, illustrating the bias associated with the 'benefit of hindsight' in retrospective analyses.  Inference techniques that account explicitly for non-Gaussian statistics significantly reduce the bias, and increase the reliability and accuracy, of the forecast failure time in prospective mode. \nURL: http://www.geos.ed.ac.uk/homes/abell5/Real-time.html\n","3"
"NG23E. Novel Inverse Methods for High-Dimensional and Nonlinear Problems I","NG23E","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","2:55 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Ensemble-based fusion of noisy images <i>(Invited)</i>","NG23E-01","2:55 PM","3:10 PM","D.   McLaughlin*","D.   McLaughlin*","MIT","Sessioned","Body: There is frequently a need in the geosciences and other fields to characterize geometric features that are difficult to detect or observe. Examples of such features include subsurface petroleum or mineral deposits, rainy areas beneath cloud cover, and natural recharge areas. It is possible to characterize the uncertain location and structure of hidden features in terms of ensembles of appropriate images. Nonparametric Bayesian theory provides a conceptual framework for this process. The approach described here uses ensembles of images to convey prior (unconditional), measurement error (likelihood), and posterior (conditional) information. The posterior ensemble gives a useful indication of the range of possible images that are consistent with available measurements. A non-parametric Bayesian approach is not computationally feasible for images of realistic size if the image replicates are described in terms of their pixel values. The Bayesian procedure described in this talk circumvents computational problems by mapping all relevant images into a very small (e.g. two-dimensional) space of image attributes. A Bayesian conditioning process (importance sampling) carried out in this attribute space associates a posterior probability with each prior image. The image attributes are not specified in advance but are inferred entirely from available data, using a multi-dimensional scaling technqiue. A synthetic example based on NEXRAD rainfall data is used to illustrate the concepts. In this example the prior rain storms identified as most likely are quite similar to a specified true storm. The flexibility and data-driven format of the approach make it easy to tailor the characterization process to a range of different problems.\n","1"
"NG23E. Novel Inverse Methods for High-Dimensional and Nonlinear Problems I","NG23E","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","2:55 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Bayesian Total Variation Inversion to Identify Discrete Geologic Structures","NG23E-02","3:10 PM","3:25 PM","J.   Lee*","J.   Lee*; P. K.  Kitanidis","Stanford","Sessioned","Body: The characterization of geologic structure for modeling flow and transport phenomena in the subsurface is essential for cost-effective and reliable decision-making in various field applications such as groundwater supply and contaminant cleanup. Geostatistical inversion approaches have been widely used to tackle subsurface characterization problems and quantify their corresponding uncertainty. However, one often encounters the situation that the subsurface can best be described through a few relatively uniform geologic facies or zones with abrupt changes at their boundaries. While suitable for capturing the large-scale variability with a few measurements, the geostatistical inversion that utilizes Gaussian distributions and covariance functions may not be adequate in this case because it cannot adequately represent and often over-smoothes sharp boundaries between facies. We present a Bayesian inversion approach with the gradient introduced not with a Gauss but with a Laplace prior, also known as total variation prior, for the case that other information indicates that discrete geologic structures are present in the subsurface but their number, locations, and shapes are unknown a priori. Structural (also known as hyper-) parameters are determined in a Bayesian framework by maximizing the marginal distribution of these parameters using the Expectation-Maximization approach; this allows proper weighting of prior versus data information and produces results with degree of variability consistent with the data. We apply our method to several problems such as a time-varying extraction rate estimation at a distant well, a subsurface image reconstruction using linear cross-well seismic tomography, and a laboratory-scale hydraulic tomography problem.  These results are compared with those achieved in the classical geostatistical method and it is shown that the Bayesian inversion approach with total variation prior may be a useful tool to identify discrete geologic structures that are consistent with measurements.\n","2"
"NG23E. Novel Inverse Methods for High-Dimensional and Nonlinear Problems I","NG23E","Oral","Nonlinear Geophysics (NG)","04-Dec-2012","2:55 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Wavelet-based reconstruction of fossil-fuel CO2 emissions from sparse measurements ","NG23E-03","3:25 PM","3:40 PM","J.   Ray*","J.   Ray*; S. A.  McKenna; V.   Yadav; B.   Van Bloemen Waanders; A. M.  Michalak","Sandia Natl Lab; Carnegie Institution for Science; Sandia National Laboratories","Sessioned","Body: We present a method to estimate spatially resolved fossil-fuel CO2 (ffCO2) emissions from sparse measurements of time-varying CO2 concentrations. It is based on the wavelet-modeling of the strongly non-stationary spatial distribution of ffCO2 emissions. The dimensionality of the wavelet model is first reduced using images of nightlights, which identify regions of human habitation. Since wavelets are a multiresolution basis set, most of the reduction is accomplished by removing fine-scale wavelets, in the regions with low nightlight radiances. The (reduced) wavelet model of emissions is propagated through an atmospheric transport model (WRF) to predict CO2 concentrations at a handful of measurement sites.The estimation of the wavelet model of emissions i.e., inferring the wavelet weights, is performed by fitting to observations at the measurement sites. This is done using Staggered Orthogonal Matching Pursuit (StOMP), which first identifies (and sets to zero) the wavelet coefficients that cannot be estimated from the observations, before estimating the remaining coefficients. This model sparsification and fitting is performed simultaneously, allowing us to explore multiple wavelet-models of differing complexity. This technique is borrowed from the field of compressive sensing, and is generally used in image and video processing.We test this approach using synthetic observations generated from emissions from the Vulcan    database. 35 sensor sites are chosen over the USA. FfCO2 emissions, averaged over 8-day periods, are estimated, at a 1 degree spatial resolutions. We find that only about 40% of the wavelets in emission model can be estimated from the data; however the mix of coefficients that are estimated changes with time. Total US emission can be reconstructed with about ~5% errors. The inferred emissions, if aggregated monthly, have a correlation of 0.9 with Vulcan fluxes. We find that the estimated emissions in the Northeast US are the most accurate.Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-AC04-94AL85000.\n","3"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Closing the loop with fractal interpolating functions for geophysical encoding","NG31A-1565","8:00 AM","8:00 AM","C. E.  Puente*","C. E.  Puente*; H.   Huang; A.   Cortis; B.   Sivakumar","University of California Davis; Lawrence Berkeley National Lab; University of New South Wales","Sessioned","Body: Natural data sets, such as precipitation records, often contain geometries that are too complex to model in their totality with classical stochastic methods. In the past years, we have developed a promising deterministic geometric procedure, the fractal-multifractal (FM) method, capable of generating patterns as projections that share textures and other fine details of individual data sets, in addition to the usual statistics of interest. In this paper, we formulate an extension of the FM method around the concept of “closing the loop” by linking ends of two fractal interpolating functions and then test it on four geometrically distinct rainfall data sets to show that that this generalization can provide excellent results.\n","1"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Improving the Ensemble Predictability of High-impact Events using Forecast Sensitivity","NG31A-1566","8:00 AM","8:00 AM","B.   Ancell*","B.   Ancell*","Texas Tech University","Sessioned","Body: Ensemble prediction using an ensemble Kalman filter involves the propagation of a number of forecasts begun from a distribution of analyses that characterizes the uncertainty of the atmospheric state.  These forecasts then provide a probability distribution of the future atmospheric state, and provide forecasters valuable information regarding the uncertainty of specific, high-impact weather events.  By calculating the forecast sensitivity (ensemble or adjoint) of specific forecast events, it may be possible to identify an ensemble subset that improves the prediction of these events over the full ensemble itself.  The hypothesis tested here is that by weighting forecast error in sensitive regions associated with specific forecast aspects, ensemble subsets can be found that improve forecasts of these aspects.  This study uses an observing system simulation experiment (OSSE) in a perfect model environment to realize these benefits for land-falling, mid-latitude cyclones on the west coast of North America over a full winter season.  Further research within a more realistic framework is discussed based on the results found here.\n","2"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Perturbing model processes to linearize non-Gaussian model error in microphysical parameterization.","NG31A-1567","8:00 AM","8:00 AM","M.   Van Lier-walqui*","M.   Van Lier-walqui*; T.   Vukicevic; D. J.  Posselt","University of Miami; NOAA AOML; University of Michigan","Sessioned","Body: Recent studies have shown the importance of quantifying and representing modelphysics uncertainty within probabilistic forecasts (e.g. Stensrud 2000). Thecharacteristics of microphysical parameterization uncertainty, however, havebeen found to be strongly nonlinear (Posselt & Vukicevic 2010, van Lier-Walquiet al 2012), calling into question the possibility of estimating andpropagating this error using Gaussian statistical techniques such as ensembleKalman methods (Vukicevic & Posselt 2008, Posselt & Bishop 2012). One possibleoption for addressing these issues is choosing new variables over which torepresent and estimate uncertainty. In particular, recent results havesuggested that while probability density functions (PDFs) of microphysicalparmameters are strongly non-Gaussian, PDFs of individual microphysical processtendency output is more `well-behaved' (van Lier-Walqui et al 2012). Here,results are presented of a Monte Carlo estimation of microphysicalparameterization uncertainty using a delayed rejection, adaptive Metropolissampler (Haario 2006), where the uncertain parameters are perturbations onindividual microphysical process tendencies. Shannon information content andBayesian evidence are used to assess the ability of the new uncertainparameters to represent forecast uncertainty. Preliminary results with the newparameters show both the promise and the limitations of the new approach.\n","3"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","A new Method for the Estimation of Initial Condition Uncertainty Structures in Mesoscale Models","NG31A-1568","8:00 AM","8:00 AM","J. D.  Keller*","J. D.  Keller*; L.   Bach; A.   Hense","Hans-Ertel-Center for Weather Research; Deutscher Wetterdienst; University of Bonn","Sessioned","Body: The estimation of fast growing error modes of a system is a key interest of ensemble data assimilation when assessing uncertainty in initial conditions. Over the last two decades three methods (and variations of these methods) have evolved for global numerical weather prediction models: ensemble Kalman filter, singular vectors and breeding of growing modes (or now ensemble transform). While the former incorporates a priori model error information and observation error estimates to determine ensemble initial conditions, the latter two techniques directly address the error structures associated with Lyapunov vectors. However, in global models these structures are mainly associated with transient global wave patterns.When assessing initial condition uncertainty in mesoscale limited area models, several problems regarding the aforementioned techniques arise: (a) additional sources of uncertainty on the smaller scales contribute to the error and (b) error structures from the global scale may quickly move through the model domain (depending on the size of the domain). To address the latter problem, perturbation structures from global models are often included in the mesoscale predictions as perturbed boundary conditions. However, the initial perturbations (when used) are often generated with a variant of an ensemble Kalman filter which does not necessarily focus on the large scale error patterns.In the framework of the European regional reanalysis project of the Hans-Ertel-Center for Weather Research we use a mesoscale model with an implemented nudging data assimilation scheme which does not support ensemble data assimilation at all. In preparation of an ensemble-based regional reanalysis and for the estimation of three-dimensional atmospheric covariance structures, we implemented a new method for the assessment of fast growing error modes for mesoscale limited area models. The so-called self-breeding is development based on the breeding of growing modes technique. Initial perturbations are integrated forward for a short time period and then rescaled and added to the initial state again. Iterating this rapid breeding cycle provides estimates for the initial uncertainty structure (or local Lyapunov vectors) given a specific norm. To avoid that all ensemble perturbations converge towards the leading local Lyapunov vector we apply an ensemble transform variant to orthogonalize the perturbations in the sub-space spanned by the ensemble.By choosing different kind of norms to measure perturbation growth, this technique allows for estimating uncertainty patterns targeted at specific sources of errors (e.g. convection, turbulence). With case study experiments we show applications of the self-breeding method for different sources of uncertainty and different horizontal scales.\n","4"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Adopting Model Uncertainties for Tropical Cyclone Intensity Prediction","NG31A-1569","8:00 AM","8:00 AM","R.   Rios Berrios*","R.   Rios Berrios*; T.   Vukicevic","SUNY - University at Albany; NOAA/OAR/AOML","Sessioned","Body: Tropical cyclone (TC) intensity prediction remains highly uncertain, despite the current efforts in improving the performance of numerical prediction models. This uncertainty has been attributed to many factors, one of them being the poor representations of physical processes within the models. Particularly, TC intensity predictions are sensitive to the choice of the physical parameterizations that represent small-scale processes that would otherwise not be resolved by the models, such as cloud microphysics, planetary boundary layer processes and turbulence. In order to better understand which set of parameterizations should be used to improve TC intensity forecasts, the Generic Inversion by Transfer Function Analysis (GITFA) is introduced in this study. The method produces a joint probability density function (PDF) of inverse estimation solution for a selected set of parameters given the forecast model and observations with their associated errors. This PDF in the parameter space is non-Gaussian for the nonlinear models and provides information about likelihood of the joint values of the parameters that would result in the model forecast within a given range of the uncertainty in the observation space. The PDF of the inverse estimate defines the optimal, mutually correlated ensemble of parameter values.In this study, two physical parameterizations from an axisymmetric model were perturbed to produce different idealized TCs simulations. Results from those simulations were used to form the transfer functions for GITFA to obtain the inverse solutions. Preliminary results show that when the observation is a point within the TC field, such as the maximum wind speed, the optimal range of parameters is poorly constrained. On the other hand, when an entire kinematic field is observed, the optimal parameters can be constrained to a subset of joint range of values. The results suggest that an ensemble of physical parameterizations should be employed to improve TC intensity forecasts and that the ensemble could be optimally derived using inverse solutions constrained by the observations that contain information about the vortex structure.\n","5"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Square Root and Perturbed Observation Ensemble Generation for Kalman and Quadratic Ensemble Filters","NG31A-1570","8:00 AM","8:00 AM","D.   Hodyss*","D.   Hodyss*","Naval Research Laboratory","Sessioned","Body: Ensemble-based Kalman Filter (EnKF) algorithms have proven highly effective in a wide-variety of applications in the geosciences.  However, the application of the EnKF to the highly nonlinear physical process found in geoscience applications may lead in certain situations to non-Gaussian prior distributions and therefore suboptimal or even degenerative behavior.  A new extension of the EnKF will be described here that allows for the explicit effects of skewness in the prior distribution to be accounted for in the data assimilation algorithm.  The algorithm operates as either a global-solve (all observations are considered at once) using a minimization technique and Schur/Hadamard (element-wise) localization or as a serial-solve (each observation is conserved one after the other) algorithm.  The central feature of both configurations is the squaring of the innovation and the ensemble perturbations so as to create an extended state-space that accounts for the second, third and fourth moments of the prior distribution.  Both square-root and perturbed observation ensemble generation techniques will be shown to be implementable within the new framework and will be compared against the corresponding technique within the traditional EnKF.  These new techniques will be illustrated on the Lorenz (1963) attractor as well as in a Boussinesq model of O(10^4) variables configured to simulate nonlinearly evolving Kelvin-Helmholtz waves in shear flow.  It is shown that ensemble sizes of at least 100 members are needed to adequately resolve the third and fourth moments required for the algorithm.  For ensembles of this size it is shown that these new techniques are superior to the EnKF in situations with significant skewness, otherwise the new algorithms reduce to the performance of the EnKF.           \nURL: http://journals.ametsoc.org/doi/abs/10.1175/2011MWR3558.1http://journals.ametsoc.org/doi/abs/10.1175/MWR-D-11-00198.1\n","6"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Impact Assessment and Data Assimilation of NOAA NPP/JPSS Sounding Products and Quality Control Parameters","NG31A-1571","8:00 AM","8:00 AM","S. J.  Fletcher*","S. J.  Fletcher*; S. A.  Boukabara","Colorado State University; NOAA/NESDIS","Sessioned","Body: The introduction of ensemble covariances into the GSI system changes the structure of the background error covariance matrix from using the same static covariance matrix as a one size fits all solution.  The static component plays an important part in the longer and larger scale dynamics but the ensemble component captures the flow in the shorter time scales, usually up to 6 hours.  However, the hybrid system introduces different scales into the analysis and changes the innovation vectors of the observations.  Normally these vectors are based upon the same static background error covariance matrix being used throughout the year, but now this matrix is changing at each cycle.In this paper we start to investigate the impact of the hybrid covariance matrix against NPP/JPSS sounding products from ATMS, CrlS and other NPP satellite data sets.  We shall assess the changes compared to the static version of the GSI for different synoptic situations.  This assessment will be with respect to observational quality controls measures as well as the Chi-Squared measure and the rain-cloud detection..\n","7"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","The Use of a Parallel Data Processing and Error Analysis System (DPEAS) for the Observational Exploration of Complex Multi-Satellite Non-Gaussian Data Assimilation Algorithms","NG31A-1572","8:00 AM","8:00 AM","A. S.  Jones*","A. S.  Jones*; S. J.  Fletcher; S. Q.  Kidder; J. M.  Forsythe","Colorado State University","Sessioned","Body: The CSU/NOAA Data Processing and Error Analysis System (DPEAS) was created to merge, or blend, multiple satellite and model data sets within a single consistent framework. DPEAS is designed to be used at both research and operational facilities to facilitate Research-to-Operations technology transfers. The system supports massive parallelization via grid computing technologies, and hosts data fusion techniques for transference to 24/7 operations in a low cost computational environment. In this work, we highlight the data assimilation and data fusion methodologies of the DPEAS framework that facilitates new and complex multi-satellite non-Gaussian data assimilation algorithm developments.DPEAS is in current operational use at NOAA/NESDIS Office of Satellite and Product Operations (OSPO) and performs multi-product data fusion of global “blended” Total Precipitable Water (bTPW) and blended Rainfall Rate (bRR). In this work we highlight: 1) the current dynamic inter-satellite calibration processing performed within the DPEAS data fusion and error analysis, 2) as well as our DPEAS development plans for future blended products (AMSR-2 and Megha-Tropiques), and 3) layered TPW products using the NASA AIRS data for National Weather Service forecaster use via the NASA SPoRT facility at Huntsville, AL. We also discuss new system additions for cloud verification and prediction activities in collaboration with the National Center for Atmospheric Research (NCAR), and planned use with the USAF Air Force Weather Agency’s (AFWA) global Cloud Depiction and Forecast System (CDFS) facilities.Scientifically, we focus on the data fusion of atmospheric and land surface product information, including global cloud and water vapor data sets, soil moisture data, and specialized land surface products. The data fusion methods include the use of 1DVAR data assimilation for satellite sounding data sets, and numerous real-time statistical analysis methods. Our new development activities to extend the current 1DVAR algorithm to use and test a new non-Gaussian data assimilation method are presented.This research was supported by multiple grants from the NOAA/NESDIS Product System Development and Implementation (PSDI) program, a NASA ROSES grant, and a grant by the Air Force Weather Agency (AFWA) to the DoD Center for Geosciences / Atmospheric Research (CG/AR) at Colorado State University, as well as a subcontract from the National Center for Atmospheric Research (NCAR) to CSU.\n","8"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Including Linearised Moist Physics in NASA's GEOS-6 Perturbation Model","NG31A-1573","8:00 AM","8:00 AM","D. R.  Holdaway*","D. R.  Holdaway*","NASA; USRA","Sessioned","Body: At NASA's Global Modelling and Assimilation Office a 4D-variational data assimilation for the GEOS-6 (Goddard Earth Observing System) cubed sphere dynamical core is nearing completion. In addition to the dynamics and surface drag components of the GEOS adjoint and tangent linear tools the moist physics has now been developed and is presented here.The inclusion of linearised moist physics has previously been shown to increase the accuracy of atmospheric 4D-var data assimilation and adjoint based sensitivity analysis. However, due to the strong non-linearities that can be associated with moist processes, developing a useful linearisation is non-trivial.In the non-linear model GEOS-6 uses the Relaxed Arakawa-Schubert (RAS) scheme for moist convection. An extensive analysis of the RAS scheme has shown dynamical perturbations to to be fairly linear and stable so an exact linearisation of the scheme is developed and used. The large scale condensation scheme that is used in GEOS-6 supports a number of complex highly non-linear processes such as re-evaporation and deposition. Rather than using an exact linearisation of the in situ scheme, which could be very inaccurate, a simple scheme that precipitates super saturation is employed.Despite the largely linear properties of the RAS scheme some convective points can nevertheless be problematic. At some locations unrealistically large perturbation quantities are seen, likely due to non-linearity. It is shown that these problematic points are associated with large gradients, which result from a marked sensitivity to moisture perturbations in the boundary layer. Using finite difference estimates (Jacobian elements) to measure the extent of this sensitivity it is possible to successfully filter problematic points based on the model trajectory. Since the sensitivity is very localised it is possible to perform this check without significant increase to computational efficiency. The benefits of including the linearised moist physics is tested by performing adjoint based observation impact experiments and by examining sensitivity fields. With the problematic points controlled by filtering it is shown that an exact linearisation of the RAS scheme, in conjunction with the simplified large scale moist physics, produces promising results. A positive impact is seen in the use of observation fields and the model produces realistic perturbation structures. Timing tests show there to be only a small increase in the overall adjoint computational efficiency when these linearised moist physics are included.\n","9"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Multi-Resolution Variational Analysis (MRVA):  High-resolution data fusion over global surface","NG31A-1574","8:00 AM","8:00 AM","T. M.  Chin*","T. M.  Chin*","JPL","Sessioned","Body: The Multi-Resolution Variational Analysis method was developedto merge satellite sea surface temperature (SST) measurements with drastically different spatial resolution and coverage. MRVA is a hybrid of the variational analysis technique used commonly in geophysical data interpolation/assimilation andmultiresolution analysis technique based on orthonormal wavelet decomposition,where the former addresses the irregular-sampling and uncertainty estimationissues whilethe latter provides a mathematical framework to controlthe interpolation scale (internal resolution)for each data set as well as inter-sensor bias corrections.Satellite-based SST data are indeed irregularly-sampled by different sensor types. The microwave (MW) sensors have typically coarser 25-km resolution than the infra-red (IR) sensors which can resolve down to a 1-km scale. However, the IR-based measurements are prone to data voids due to cloud contamination, which does not affect MW sensors nearly as much. Scientific and operational needs for the SST data cover a wide range of spatial and temporal scales. For example, a regional or global mean is often examined over a long time period in climate studies, while SST snapshotsof sub-kilometer resolution may be required in biological applications. The focus of the  Multi-scale Ultra-high Resolution (MUR) SST analysis project is to produce a high-resolution daily SST fieldbased on the satellite retrieval data to address these variety of needs.The MRVA method was applied to merge these satellite data to produce the MUR SSTanalysis over a 1-km global grid at a daily frequency.The power spectral density of SST displays aself-similar (power-law) characteristic,and MUR SST shows consistency with this characteristicover a wider range of wavenumber spectrum due to its higher internal resolution.Capability to reproduce such empirical characteristicsis a strength of the MRVA technique.\nURL: http://mur.jpl.nasa.gov\n","10"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Regularized Data Assimilation and Fusion of non-Gaussian States Exhibiting Sparse Prior in Transform Domains","NG31A-1575","8:00 AM","8:00 AM","M.   Ebtehaj*","M.   Ebtehaj*; E.   Foufoula","University of Minnesota; University of Minnesota","Sessioned","Body: Improved estimation of geophysical state variables in a noisy environment from down-sampled observations and background model forecasts has been the subject of growing research in the past decades. Often the number of degrees of freedom in high-dimensional non-Gaussian natural states is quite small compared to their ambient dimensionality, a property often revealed as a sparse representation in an appropriately chosen domain. Aiming to increase the hydrometeorological forecast skill and motivated by wavelet-domain sparsity of some land-surface geophysical states, new framework is presented that recast the classical variational data assimilation/fusion (DA/DF) problem via L_1 regularization in the wavelet domain. Our results suggest that proper regularization can lead to more accurate recovery of a wide range of smooth/non-smooth geophysical states exhibiting remarkable non-Gaussian features. The promise of the proposed framework is demonstrated in multi-sensor satellite and land-based precipitation data fusion, while the regularized DA is performed on the heat equation in a 4D-VAR context, using sparse regularization in the wavelet domain.\n","11"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","Interpolating Sparse Scattered Oceanographic Data Using Flow Information","NG31A-1576","8:00 AM","8:00 AM","G. J.  Streletz*","G. J.  Streletz*; G.   Gebbie; H. J.  Spero; O.   Kreylos; L. H.  Kellogg; B.   Hamann","University of California, Davis; Woods Hole Oceanographic Institution","Sessioned","Body: We present a novel approach for interpolating sparse scattered data in the presence of a flow field.  In order to visualize a scalar field representing a physical quantity such as salinity, temperature, or nutrient concentration in the ocean, the individual measured values of the quantity of interest typically are first converted into a representation of the scalar field on a regular grid.  If the measured values are located at a number of scattered sites, then the reconstruction process will be scattered data interpolation.  Scattered data interpolation itself is a well-known problem space for which many methods exist, including methods involving radial basis functions, statistical approaches such as optimal interpolation, and grid-based methods such as Laplace interpolation.  However, the quality of the reconstruction result obtained using such methods depends upon having a sufficient density of sample points as input.  For cases involving sparse scattered data - such as is the case when using measurements from benthic foraminifera in deep sea sedimentary cores as a proxy for the physical properties of the past ocean - the standard methods may not produce acceptable results.  However, if the scalar field is associated with a known (or partially known) flow field, then the flow field information can be used to enhance the interpolation method in order to compensate for the sparsity of the available scalar field samples.  Our hypothesis is that scalar field values should be more highly correlated along streamlines of the flow field than across such streamlines.  We have investigated and tested such augmented, flow-field-aware scattered data interpolation methods.  In particular, we have modified standard scattered data interpolation methods to use non-Euclidean distance pseudometrics, which we have constructed by employing various relative weightings of distance-along-streamlines versus distance-from-streamlines.  We have tested the resulting methods by applying them to sparse samplings of various scalar fields.  In order to ensure realistic relationships between these scalar fields and the underlying flow field, we create the scalar fields by numerically solving an advection-diffusion equation, using various diffusivities and flow velocities to construct the collection of test cases.  The results obtained by our approach show promise for being able to reconstruct an underlying scalar field from a collection of scattered samples whose sparsity would not otherwise allow high-quality interpolation results.\n","12"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","A Markov Chain Monte Carlo-Based Examination of the Interaction Between Model Physics Uncertainty and Model State","NG31A-1577","8:00 AM","8:00 AM","D. J.  Posselt*","D. J.  Posselt*","University of Michigan","Sessioned","Body: Errors and/or uncertainty in model physics parameterizations are a primary source of forecast error in weather and climate prediction. In particular, simplifying assumptions about the form of the particle size distribution of ice and liquid condensate have an important effect on the details of cloud and precipitation development and feedback on the radiative fluxes, heating rates, and thermodynamic environment. Consequently, efforts are being undertaken to constrain the uncertainty in model physics parameterizations, largely via estimation of the empirical parameters that represent subgrid cloud variability. Nonlinearity in the parameter-state functional relationship presents a significant challenge to model uncertainty characterization using linear Gaussian methodologies.Previous work has shown that model uncertainty can be effectively characterized in off-line one-dimensional models of deep convection using a Markov chain Monte Carlo nonlinear inverse method. In this presentation, model parameter uncertainty is evaluated for models in which changes in parameters are allowed to feed back on the convective scale dynamics and environment. When parameter values are constrained with observations, many aspects of the deep convective structure are also uniquely determined. Where this is not the case, the results of the nonlinear parameter estimation provide guidance as to which observations are required to produce robust estimates of convective dynamics and environment, as well as their uncertainty characteristics.\n","13"
"NG31A. Non-Gaussian and Nonlinear Aspects of Data Assimilation/Fusion and Predictability in the Geosciences II Posters","NG31A","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Space Science Informatics (IN)Global Environmental Change (GC)Hydrology (H)Ocean Sciences (OS)","De-noising and clean reconstruction of seismic signals using Space Lagged Singular Spectral Analysis (SLSSA)","NG31A-1578","8:00 AM","8:00 AM","R.   Rekapalli*","R.   Rekapalli*; R. K.  Tiwari; S.   Tangirala","CSIR-NGRI; CSIR-NGRI","Sessioned","Body: Seismic records represent superposed oscillations of non-stationary and nonlinear signals shaped by the chaotically evolved crustal structures. Such seismic signals are generally assorted with correlated noise and this leads to serious problems in understanding their physical interpretation. We devised and employed a Space Lagged Singular Spectral Analysis (SLSSA) based algorithm to effectively de-noise and enhance seismic signal strength (amplitude) in order to clearly identify concealed layered structures. The SLSSA technique involves reducing rank order of the Hankel matrix by restricting low Eigen values that arise from noise and missing data. The basic noise reduction procedure involves (is performed by) alleviating contributions of fluctuating low Eigen values that arise from spatially uncorrelated noise processes. This is followed by reconstruction of the spatial data series applying appropriate weights based on Eigen values. This rank order reduction procedure does not require any prior information of the noise process. To test the efficacy of this new technique, we first applied the method to synthetic data contaminated with various kinds of noises of known percentages and missing data. Finally, guided by the above theoretical experiment, this method was applied to high resolution seismic reflection data of 60 channels, (8000 samples per channel) with 0.25ms sampling interval of 2s recording time. The new SLSSA algorithm successfully removes noise besides recovering missing signatures. Our analyses of actual seismic signals reveal some significant coal bearing horizons that were hitherto unmapped. Identification of these coal bearing horizons corroborates well with the geological prognosis for the study area. Key Words:  Chaotic, Eigen values, Space Lagged Singular Spectral Analysis (SLSSA), Stochastic.\n","14"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Sparse Solution of High-Dimensional Model Calibration Inverse Problems under Uncertainty in Prior Structural Connectivity ","NG31B-1579","8:00 AM","8:00 AM","M.   Mohammad khaninezhad*","M.   Mohammad khaninezhad*; B.   Jafarpour","University of Southern California","Sessioned","Body: Data limitation and heterogeneity of the geologic formations introduce significant uncertainty in predicting the related flow and transport processes in these environments. Fluid flow and displacement behavior in subsurface systems is mainly controlled by the structural connectivity models that create preferential flow pathways (or barriers). The connectivity of extreme geologic features strongly constrains the evolution of the related flow and transport processes in subsurface formations. Therefore, characterization of the geologic continuity and facies connectivity is critical for reliable prediction of the flow and transport behavior.  The goal of this study is to develop a robust and geologically consistent framework for solving large-scale nonlinear subsurface characterization inverse problems under uncertainty about geologic continuity and structural connectivity. We formulate a novel inverse modeling approach by adopting a sparse reconstruction perspective, which involves two major components: 1) sparse description of hydraulic property distribution under significant uncertainty in structural connectivity and 2) formulation of an effective sparsity-promoting inversion method that is robust against prior model uncertainty. To account for the significant variability in the structural connectivity, we use, as prior, multiple distinct connectivity models. For sparse/compact representation of high-dimensional hydraulic property maps, we investigate two methods. In one approach, we apply the principle component analysis (PCA) to each prior connectivity model individually and combine the resulting leading components from each model to form a diverse geologic dictionary. Alternatively, we combine many realizations of the hydraulic properties from different prior connectivity models and use them to generate a diverse training dataset. We use the training dataset with a sparsifying transform, such as K-SVD, to construct a sparse geologic dictionary that is robust to structural variability in the dataset. To solve the resulting inverse problem, we minimize a sparsity-regularized least-squares data mismatch function. This formulation of the inverse problem is inspired by recent advances in sparse reconstruction and the compressed sensing paradigm. We use several numerical experiments to demonstrate the effectiveness of the proposed methods and their applicability to high-dimensional model calibration inverse problems.\n","1"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Adaptive anchored inversion for Gaussian random fields using nonlinear data","NG31B-1580","8:00 AM","8:00 AM","Z.   Zhang*","Z.   Zhang*","University of Alaska","Sessioned","Body: In a broad and fundamental type of inverse problems' in science, one infers a spatially distributed physical attribute based on observations of processes that are controlled by the spatial attribute in question. The data-generating field processes, known as the forward processes, are usually nonlinear with respect to the spatial attribute, and are often defined non-analytically by a numerical model. The data often contain a large number of elements with significant inter-correlation. We propose a general statistical method to tackle this problem. The method is centered on a parameterization device called anchors and an iterative algorithm for deriving the distribution of anchors conditional on the observed data. The algorithm draws upon techniques of importance sampling and multivariate kernel density estimation with weighted samples. Anchors are selected automatically; the selection evolves in iterations in a way that is tailored to important features of the attribute field. The method and the algorithm are general with respect to the scientific nature and technical details of the forward processes. Conceptual and technical components render the method in contrast to standard approaches that are based on regularization or optimization. Some important features of the proposed method are demonstrated by examples drawn from the earth sciences.\n","2"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Exploiting Laguerre Functions to Regularize Contaminant Source History Recovery Problems","NG31B-1581","8:00 AM","8:00 AM","S. K.  Hansen*","S. K.  Hansen*; B. H.  Kueper","Queen's University","withdrawn","","3"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Joint inversion of receiver function, surface wave dispersion, and magnetotelluric data for 2D crustal modeling","NG31B-1582","8:00 AM","8:00 AM","L. P.  Moreira*","L. P.  Moreira*; M. J.  Friedel; G. S.  Franca","University of Brasilia; United States Geological Survey; University of Colorado","Sessioned","Body: The joint inversion of earthquake seismic (receiver function and Rayleigh dispersion) and natural magnetotelluric (electric and magnetic fields) data is presented for improved crustal imaging. The inversion methodology uses a Gauss-Marquardt-Levenberg algorithm to minimize a multi-component objective function: measurement (difference between calculated and observed measurements), Tikhonov (difference between adjacent parameters of same type), and cross-gradient (differences among adjacent parameters of disparate types). The proposed methodology is evaluated in a controlled test where 1D seismic and 2D magnetotelluric models are solved simultaneously using synthetic data from 15 magnetotelluric stations and 3 seismic stations. Tikhonov procedures is applied to guarantee inversion stability and convergence, whereas the cross-gradient procedure identifies common structure among disparate parameters. The method is then applied to field data collected by USGS in the state of Nevada showing improvement in the crustal image when compared to more traditional inversions demonstrating the potential benefits of the joint inversion of seismic and magnetotelluric data.\n","4"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Inversion of basal boundary conditions for a thermomechanically coupled nonlinear Stokes ice sheet model","NG31B-1583","8:00 AM","8:00 AM","H.   Zhu*","H.   Zhu*; N.   Petra; G.   Stadler; T.   Isaac; T. J.  Hughes; O.   Ghattas","The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin","Sessioned","Body: Modeling the dynamics of polar ice sheets is critical for projectionsof future sea level rise. Yet, there remain large uncertainties in theboundary conditions at the base of the ice sheet. Thus, we target theinversion for basal boundary conditions and the basal geothermal heatflux using surface velocity measurements.The flow of ice sheets and glaciers is modeled as a sheer thinning,viscous incompressible fluid with temperature-dependent viscosity viaa thermomechanically coupled Stokes model.  The inverse problem isformulated as a nonlinear least-squares optimization problem with acost functional that contains the misfit between surface velocityobservations and model predictions. A Tikhonov regularization term isadded to render the problem well-posed and account for observationaland model errors.We use an infinite-dimensional adjoint-based inexact Newton method forthe solution of this least squares optimization problem.  Results fora three-dimensional model problem demonstrate the ability of invertingfor a smoothly varying basal sliding coefficient and geothermal heatflux. This capability will be incorporated into a state-of-the-artcontinental-scale ice sheet dynamics model.\n","5"
"NG31B. Novel Inverse Methods for High-Dimensional and Nonlinear Problems II Posters","NG31B","Poster","Nonlinear Geophysics (NG)","05-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Hydrology (H)","Seismic Wave Propagation Simulation using Circular Hough Transform","NG31B-1584","8:00 AM","8:00 AM","K.   Miah*","K.   Miah*; D. K.  Potter","University of Alberta","Sessioned","Body: Synthetic data generation by numerically solving a two-way wave equation is an essential part of seismic tomography, especially in full-waveform inversion. Finite-difference and finite-element are the two common methods of seismic wave propagation modeling in heterogeneous media. Either time or frequency domain representation of wave equation is used for these simulations.  Hanahara and Hiyane [1] proposed and implemented a circle-detection algorithm based on the Circular Hough transform (CHT) to numerically solve a two-dimensional wave equation.  The Hough transform is generally used in image processing applications to identify objects of various shapes in an image [2]. In this abstract, we use the Circular Hough transform to numerically solve an acoustic wave equation, with the purpose to identify and locate primaries and multiples in the transform domain. Relationships between different seismic events and the CHT parameter are also investigated.       [1] Hanahara, K. and Hiyane, M., A Circle-Detection Algorithm Simulating Wave Propagation, Machine Vision and Applications,  vol. 3, pp. 97-111, 1990. [2 ] Petcher, P. A. and Dixon, S.,  A modified Hough transform for removal of direct and reflected surface waves from B-scans, NDT & E International, vol. 44, no. 2,  pp. 139-144, 2011.\n","6"
"NG32A. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications I","NG32A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Credible occurrence probabilities for extreme geophysical events","NG32A-01","11:20 AM","11:32 AM","J. J.  Love*","J. J.  Love*","USGS Geomagnetism Program  ","Sessioned","Body: Statistical analysis is made of rare, extreme geophysical events recorded in historical data -- counting the number of events with sizes that exceed chosen thresholds during specific durations of time. Under transformations that stabilize data and model-parameter variances, the most likely Poisson-event occurrence rate applies for both frequentist inference and for Bayesian inference with a Jeffreys prior that ensures posterior invariance under changes of variables. Frequentist confidence intervals and Bayesian (Jeffreys) credibility intervals are approximately the same and easy to calculate. If only a few events have been observed, as is usually the case for extreme events, then these error-bar intervals might be considered to be relatively wide. As examples, from historical records, we estimate most likely long-term occurrence rates, 10-yr occurrence probabilities, and intervals of frequentist confidence and Bayesian credibility for large earthquakes, explosive volcanic eruptions, and magnetic storms.\n","1"
"NG32A. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications I","NG32A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Apparent Multifractality and Dragon Kings in Observed and Synthetic Random Field Samples <i>(Invited)</i>","NG32A-02","11:32 AM","11:44 AM","S. P.  Neuman*","S. P.  Neuman*; M.   Riva; A.   Guadagnini","Univ of Arizona; Politecnico di Milano","Sessioned","Body: Elsewhere we have demonstrated theoretically and on synthetic data that (a) samples from truncated sub-Gaussian random fields (or processes) subordinated to truncated fractional Brownian motion (tfBm) may exhibit apparent multifractality at intermediate ranges of separation scale or lags, with breakdown in power-law scaling at small and large lags, and (b) power-law scaling of such samples may be extended to all lags through the Extended Self-Similarity (ESS) method. Data shown to be consistent with such fields and scaling behaviors included air permeabilities measured on the faces of a laboratory-scale block of tuff, along six boreholes of length up to 45 m drilled into unsaturated fractured tuff, and along two horizontal transects on a 21 m long outcrop of bioturbated sandstone. Here we show the same to hold true for air permeabilities measured on the faces of a laboratory-scale block of Berea sandstone. New features include a distinct anisotropy due to the layered nature of the block and an analysis of extreme values that deviate from power-law tails of the corresponding sample distributions. Three methods of analysis recently proposed in the literature identify some of these extreme values as Dragon Kings, defined by Sornette and coworkers as outliers generated by processes other than those responsible for the rest of a sample. After showing that the Berea data are in part consistent with samples from Lévy stable random fields subordinated to tfBm, we generate synthetic realizations of such fields to demonstrate that they produce outliers which, according to these same tests and a new testing method we propose, may appear to be Dragon Kings even though they are not: all synthetic data have been generated by the same procedure.\n","2"
"NG32A. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications I","NG32A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Helicity, geostrophic balance and mixing in rotating stratified turbulence: a multi-scale problem <i>(Invited)</i>","NG32A-03","11:44 AM","11:56 AM","A.   Pouquet*","A.   Pouquet*; R.   Marino; P.   Mininni; C.   Rorai; D. L.  Rosenberg","","Sessioned","Body: Helicity, geostrophic balance and mixing in rotating stratified turbulence: a multi-scale problemA. Pouquet, R. Marino, P. D. Mininni, C. Rorai & D. Rosenberg, NCARInteractions between winds and waves have important roles in planetary and oceanic boundary layers,  affecting momentum, heat and CO2 transport. Within the Abyssal Southern Ocean at Mid latitude, this may result in a mixed layer which is too shallow in climate models thereby affecting the overall evolution because of poor handling of  wave breaking as in Kelvin-Helmoltz instabilities: gravity waves couple nonlinearly on slow time scales and undergo steepening through resonant interactions, or due to the presence of shear. In the oceans, sub-mesoscale frontogenesis and significant departure from quasi-geostrophy can be seen as turbulence intensifies. The ensuing anomalous vertical dispersion may not be simply modeled by a random walk, due to intermittent structures, wave propagation and to their interactions. Conversely, the energy and seeds required for such intermittent events to occur, say in the stable planetary boundary layer, may come from the wave field that is perturbed, or from winds and the effect of topography.   Under the assumption of stationarity, weak nonlinearities, dissipation and forcing, one obtains large-scale geostrophic balance linking pressure gradient, gravity and Coriolis force. The role of helicity (velocity-vorticity correlations) has not received as much attention, outside the realm of astrophysics when considering the growth of large-scale magnetic fields. However, it is measured routinely in the atmosphere in order to gauge the likelihood of supercell convective storms to strengthen, and it may be a factor to consider in the formation of hurricanes. In this context, we examine the transition from a wave-dominated regime to an isotropic small-scale turbulent one in rotating flows with helical forcing. Using a direct numerical simulation (DNS) on a 3072^3 grid with Rossby and Reynolds numbers of 0.07 and 27000, one can resolve both the Zeman scale at which the inertial and eddy turn-over times equalize, and the dissipation scale. We show that fully helical vertical columns dominate at intermediate scales, presumably self-similar and shrouded by a sea of small-scale vortex filaments as in Kolmogorov turbulence. Helicity has a profound effect on the structures of the flow, and a previously developed model that includes a helical component in its eddy viscosity and eddy noise shows a measurable improvement. Indeed, if dimensionless parameters for inertial and gravity waves are reachable numerically, the Reynolds number is too low in DNS for geophysics unless one uses parametrizations of small scale interactions.For spin-down stably-stratified flows, energy and helicity undergo a substantially slower decay than in the unstratified case, and a type of large-scale cyclostrophic balance is invoked to explain this behavior. The decay rate is similar to that occurring in the unstratified rotating case, as modeled by taking into account the quasi-conservation of helicity. We finally mention helicity production when rotation and stratification are both combined.In conclusion, much remains to be done, e.g. examining transport properties of rotating stratified turbulence, such as the effect of helicity on mixing in geophysical flows that can be studied with high-performance computing allowing multi-scale interactions and intermittency to develop.\n","3"
"NG32A. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications I","NG32A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","The Impact of Natural Hazards such as Turbulent Wind Gusts on the Wind Energy Conversion Process <i>(Invited)</i>","NG32A-04","11:56 AM","12:08 PM","M.   Wächter*","M.   Wächter*; M.   Hölling; P.   Milan; A.   Morales; J.   Peinke","ForWind Center for Wind Energy Research","Sessioned","Body: Wind turbines operate in the atmospheric boundary layer, where they are exposed to wind gusts and other types of natural hazards. As the response time of wind turbines is typically in the range of seconds, they are affected by the small scale intermittent properties of the turbulent wind. We show evidence that basic features which are known for small-scale homogeneous isotropic turbulence, and in particular the well-known intermittency problem, have an important impact on the wind energy conversion process. Intermittent statistics include high probabilities of extreme events which can be related to wind gusts and other types of natural hazards. As a summarizing result we find that atmospheric turbulence imposes its intermittent features on the complete wind energy conversion process. Intermittent turbulence features are not only present in atmospheric wind, but are also dominant in the loads on the turbine, i.e. rotor torque and thrust, and in the electrical power output signal. We conclude that profound knowledge of turbulent statistics and the application of suitable numerical as well as experimental methods are necessary to grasp these unique features and quantify their effects on all stages of wind energy conversion.\n","4"
"NG32A. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications I","NG32A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","11:20 AM","12:20 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Multifractal Analysis of the Small Time-Scale Boundary-Layer Characteristics of the Wind: the Anisotropy and Extremes","NG32A-05","12:08 PM","12:20 PM","G. F.  Fitton*","G. F.  Fitton*; I.   Tchiguirinskaia; D. J.  Schertzer; S.   Lovejoy","Ecole des Ponts ParisTech; McGill University ","Sessioned","Body: Under various physical conditions (mean temperature and velocity gradients, stratification and rotation) atmospheric turbulent flows remain intrinsically anisotropic. The immediate vicinity of physical boundaries rises to a greater complexity of the anisotropy effects. In this paper we address the issue of the scaling anisotropy of the wind velocity fields within the atmospheric boundary layer (ABL). Under the universal multifractal (UM) framework we compare the small time-scale (0.1 to 1,000 seconds) boundary-layer characteristics of the wind for two different case studies. The first case study consisted of a single mast located within a wind farm in Corsica, France. Three sonic anemometers were installed on the mast at 22, 23 and 43m, measuring three-dimensional wind velocity data at 10Hz. Wakes, complex terrain and buoyancy forces influenced the measurements. The second case study (GROWIAN experiment in Germany) consisted of an array of propeller anemometers measuring wind speed inflow data at 2.5Hz over flat terrain.  The propeller anemometers were positioned vertically at 10, 50, 75, 100, 125 and 150m with four horizontal measurements taken at 75, 100 and 125m. The spatial distribution allowed us to calculate the horizontal and vertical shear structure functions of the horizontal wind. Both case studies are within a kilometre from the sea.For the first case study (10Hz measurements in a wind farm test site) the high temporal resolution of the data meant we observed Kolmogorov scaling from 0.2 seconds (with intermittency correction) right up to 1,000 seconds at which point a scaling break occurred. After the break we observed a scaling power law of approximately 2, which is in agreement with Bolgiano-Obukhov scaling theory with intermittency correction. However, for the second case study (2.5Hz on flat terrain) we only observed Kolmogorov scaling from 6.4 seconds (also with intermittency correction). The spectra of horizontal velocity components remain anisotropic over high frequencies, where u1 most scales as Bolgiano-Obukhov and u2 scales as Kolmogorov. The scaling law of the vertical shears of the horizontal wind in the array varied from Kolmogorov to Bolgiano-Obukhov with height depending on the condition of stability. We interpret the results with the UM anisotropic model that greatly enhances our understanding of the ABL structure. Comparing the two case studies we found in both cases the multifractality parameter of about 1.6, which remains close to the estimates obtained for the free atmosphere. From the UM parameters, the exponent of the power law of the distribution of the extremes can be predicted. Over small scales, this exponent is of about 7.5 for the wind velocity, which is a crucial result for applications within the field of wind energy.\nURL: http://leesu.univ-paris-est.fr/-WAUDIT-\n","5"
"NG33A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? I (Video On-Demand)","NG33A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","1:40 PM","2:10 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","Statistical and Physical Aspects of Self-Organized Criticality : Solar Flares and Astrophysical Phenomena <i>(Invited)</i>","NG33A-01","1:40 PM","1:55 PM","M. J.  Aschwanden*","M. J.  Aschwanden*","Lockheed-Martin ATC","Sessioned","Body: We develop a quantitative model based on fundamental scaling lawsthat predicts the powerlaw distributions of self-organized criticality(SOC) systems. The fractal-diffusive SOC model is based onthree fundamental relationships: (1) The scale-free probabilitytheorem that determines the distribution of spatial scalesdepending on the Euclidean dimension of the SOC system;(2) a spatio-temporal relationship that is well-approximatedwith a diffusion equation; and (3) a physical scaling lawbetween the observable and the geometric avalanche volume.The first two properties have universal validity for SOC processes,while the third property depends on the specific observed physicalsystem. Comparing the theoretical predictions with the observedpowerlaws of size distributions in astrophysical systems we findacceptable agreement for the cases of lunar craters, asteroid belts,Saturn rings, outer radiation belt electron bursts, solar flares,soft gamma-ray repeaters, and blazars, if we apply the linearflux-volume scaling law. Discrepancies are found for magnetosphericsubstorms, stellar flares, pulsar glitches, black holes, and cosmicrays, which apparently require a nonlinear flux-volume scaling.We discuss also the role of turbulence, which is related to thespatial scaling law occurring in SOC systems.\nURL : http://www.lmsal.com/~aschwand/eprints/2012_SOC13.pdf\n","1"
"NG33A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? I (Video On-Demand)","NG33A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","1:40 PM","2:10 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","The Complexity of Radial Transport of Radiation Belt Electrons at Earth <i>(Invited)</i>","NG33A-02","1:55 PM","2:10 PM","A. Y.  Ukhorskiy*","A. Y.  Ukhorskiy*; M. I.  Sitnov; B. T.  Kress","JHU/APL; Dartmouth College","Sessioned","Body: Earth’s outer radiation belt is populated by relativistic electrons that produce a complex dynamical response to varying geomagnetic activity. One fundamental process sculpting global state of the belt is radial transport of electrons across their drift shells. Radial transport is induced by the interaction of electron drift motion with the electric and magnetic field fluctuations in  the ULF frequency range. In this paper we discuss physical properties of radial transport using the example of transport induced by global magnetospheric compressions. Electron motion in the solar wind driven ULF oscillations becomes stochastic due to overlap of electron populations trapped in the vicinities of drift resonances with adjacent harmonics of the field spectrum. In spite of the underlying stochasticity, particle transport does not become diffusive. This is attributed to the fact that phase correlations in electron motion do not have time to decay due to finite size of the system. This can explain the nonlinearity of the outer belt response to the solar wind: similar driving can produce different global states of the belt.  \n","2"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Testing Stochastic Models for Climate Field Reconstructions using Instrumental Data <i>(Invited)</i>","NG33B-01","2:10 PM","2:25 PM","J.   Werner*","J.   Werner*; A.   Toreti; J.   Luterbacher","Justus Liebig University Giessen","Sessioned","Body: Over the last decades, several different methods have been used to reconstruct past climatic change. These  methods consist of an - often statistical - model and a related inference step. While recently a lot of the discussion has been focused on the latter (Smerdon et al. 2011, Christiansen et al. 2011), we here turn to the modelling part.A series of recent pseudoproxy experiments (PPE) focused on climate field reconstructions (Tingley+Huybers 2010a,b; Werner et al. 2012) has used Bayesian inference together with a localized stochastic description of the spatio-temporal evolution of climate field variables: Rather than using large patterns over the full spatial domain to describe the climate field variables, local temporal evolution and spatial coherence were modelled directly. While the stochastic model, a multivariate AR(1) process, was based on few simple assumptions it could nevertheless reconstruct most of the climate variability in the used dataset. Here we show how such a simple localized model could be derived from available observational data or at least be validated using the Kramers-Moyal-Expansion (KME). While KME often can require large amounts of data, we show that at least some results are stable in the context of PPEs with respect to data availability. Finally we apply this method to real world climate data from the CRU and the Global Historical Climate Network (GHCN) to arrive at a suitable model for European gridded mean summer temperature reconstructions.Smerdon J.E. et al. JClim 24, 1284-1309 (2011)Tingley M.P. and Huybers P. JClim 10, 2759-2781, 2782-2800 (2010a,b)Christiansen, B. and Ljundqvist, F.C. JClim 24, 6013-6034 (2011)Werner J.P. et al. JClim accepted (2012)\n","1"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Climate sensitivity as a continuous function of frequency inferred from instrumental and Late Holocene paleoclimate records <i>(Invited)</i>","NG33B-02","2:25 PM","2:40 PM","P.   Huybers*","P.   Huybers*; T.   Laepple; C.   Proistosescu","Harvard University; Alfred Wegener Institute","Sessioned","Body: An attempt is made to empirically infer a sensitivity function for the surface temperature response to radiative forcing at frequencies ranging from once per month to once per seven-thousand years.  First, the spectrum of Late Holocene temperature variability is estimated using instrumental, coral, Mg/Ca, and alkenone indicators of surface temperature.  A correction is applied for the effects of aliasing, bioturbation, and other sources of noise that would otherwise bias this spectral estimate.  Second, the spectrum of radiative forcing associated with synoptic, volcanic, solar, and greenhouse gas variability is estimated from a separate collection of instrumental and proxy records as well as long model simulations.  Finally, the ratio of the temperature spectral estimate to that of the radiative forcing is obtained.  This ratio trends toward greater values out to the longest-resolved timescale of seven-thousand years.  It may be that temperature variations unrelated to radiative forcing are increasingly prominent at longer timescales.  Or, a nonlinear response to radiative forcing may account for the excess temperature variability at long timescales.  However, if these are not first order determinants, the ratio may be interpreted as a gain function, in which case it indicates that temperature becomes increasingly sensitive to radiative forcing out to at least millennial timescales and implies that the longer a radiative perturbation is maintained, the larger the temperature response.\n","2"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Long-range Memory in Earth's Global Temperature and its Implications for Future Global Warming","NG33B-03","2:40 PM","2:55 PM","K.   Rypdal*","K.   Rypdal*; L.   Oestvand","University of Tromso","withdrawn","","3"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Megadroughts: a framework for assessing risk in the coming century <i>(Invited)</i>","NG33B-04","2:55 PM","3:10 PM","T.   Ault*","T.   Ault*; J. E.  Cole; J. T.  Overpeck; G. T.  Pederson; D. M.  Meko","NCAR; University of Arizona; University of Arizona; USGS; University of Arizona","Sessioned","Body: Projected changes in global rainfall patterns will likely alter water supplies and ecosystems in semiarid regions during the coming century. Instrumental and paleoclimate data indicate that natural hydroclimate fluctuations tend to be more energetic at low-frequencies (mul- tidecadal to multicentury) than at high (interannual) frequencies. This tendency can be quantified using “power-law coefficients” that relate spectral density to frequency. Here we show that global climate models used in the 4th and 5th IPCC assessments do not generally reproduce the power-law coefficients observed in nature, even when run for many centuries or forced by 20th century boundary conditions. Our findings suggest that these models thus underesti- mate the risk of future decadal and longer megadroughts. To assess future megadrought risk using paleoclimate data, we propose a method for rescaling projected precipitation changes using local estimates of the power-law coefficient. Where observational data are reliable, this method can provide a more complete view of megadrought risk. In the Southwest, for instance, IPCC projections suggest the risk of a megadrought in the coming century is about one in ten; our analysis suggests that the risk is at least one in six for most of the Southwest, and as high as one in three in certain areas – findings that have major implications for drought risk management in the region.\n","4"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Turbulence Parameterizations and the Scaling Problem in Climate Models <i>(Invited)</i>","NG33B-05","3:10 PM","3:25 PM","J.   Teixeira*","J.   Teixeira*","Jet Propulsion Laboratory","Sessioned","Body: The atmosphere and the ocean are turbulent fluids. Most of these turbulent processes are not resolved explicitly in climate models: the grid-resolutions are too coarse. However, the small-scale sub-grid processes (turbulence, convection, clouds) play a key role in regulating the large-scale climate. All these scales, from small-scale turbulence to planetary circulations need to be represented in climate models. Modern approaches to tackle this scaling problem in climate models are discussed. In particular new ideas to unify the representation of turbulence and convection in climate models, and to appropriately take into account the different physical scales and their interplay with the model grid-scale, are presented in some detail.\n","5"
"NG33B.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate I (Video On-Demand)","NG33B","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","2:10 PM","3:40 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Micro-scale fluorescence signals: a transition from continuous to discrete scale","NG33B-06","3:25 PM","3:40 PM","H.   Yamazaki*","H.   Yamazaki*; M. J.  Doubell; J.   Prairie; Y.   Sagara; C.   Locke; A.   Nimmo-Smith","Tokyo Univ Marine Sci & Tech; South Australian Research and Development Institute; University of North Carolina at Chapel Hill; University of Plymouth","Sessioned","Body:  Micro-scale aquatic ecosystems are the engine for earth's biogeochemical cycles.  Phytoplankton fix inorganic carbon to organic carbon through the photosynthetic process.  Although phytoplankton are single-cell organisms, they often appear in an aggregated form that elevates local fluorescence signal intensity.  How intermittent are these features?  We have developed a new free-fall microstructure profiler (TurboMAP-L).  Fluorescence profiles measured by TurboMAP-L and a conventional fluorescence probe are in good agreement at one-meter scale average.  However, the fluorescence signals revealed by the LED fluorescence probe are intermittent at cm scale.  Millimeter scale fluorescence signals obtained from the laser probe are even more intermittent than the cm scale LED signals.  The source of the millimeter-scale strong signals identified from the DSL images are coagulated discrete material ranging between a few 100 μm and a few millimeters scale.  Unfortunately, the DSL images are not well focused, so the details of the coagulated matter are not clear.  Therefore, a recently developed holographic imaging system was combined with the TurboMAP-L operation in order to identify the detail of the millimeter scale coagulated material.  We show that fluorescence signals at millimeter scale exhibit high values of coefficient of variation and the signals are no longer a Gaussian process.  We found a transition scale that separates a continuous Gaussian process to a discrete event series. We are also developing a new NPZ ecosystem model based on our finding.  We will present the consequence of our new model that may alter the way in which the global biogeochemical cycle should be treated.\n","6"
"NG34A. Lorenz Lecture (Video On-Demand)","NG34A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","4:00 PM","5:00 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Turcotte Award presented to Asim Biswas",,"4:00 PM","4:12 PM",,,,,,"1"
"NG34A. Lorenz Lecture (Video On-Demand)","NG34A","Oral","Nonlinear Geophysics (NG)","05-Dec-2012","4:00 PM","5:00 PM","104 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Fighting Chaos: Applications of Breeding","NG34A-02","4:12 PM","5:00 PM","E.   Kalnay*","E.   Kalnay*","Univ Maryland","Sessioned","Body: I will discuss basic concepts of chaos, and describe techniques that have allowed taking advantage of chaos and improve forecasts and their information. One example is “breeding of instabilities” a very simple technique to estimate the fastest growing instabilities. Breeding allows predicting when a regime change will take place and how long will the new regime last in the famous Lorenz (1963) “unpredictable chaotic model”, something that surprised Lorenz himself. These techniques can be applied to any dynamic chaotic system. Some examples include detection of ocean instabilities and their physical origin, breeding in coupled ocean-atmosphere systems, detecting instabilities in the atmosphere of Mars, and breeding on the phase-space reconstructed from single time series using the time-delay embedding method. Finally I’ll discuss the implications of these results for data assimilation.\n","2"
"NG41A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? II Posters","NG41A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","THE 2009 ALL-TIME MINIMUM IN AP WAS NOT DURING “SOLAR SUNSPOT MINIMUM”: WHY NOT?","NG41A-1539","8:00 AM","8:00 AM","B.   Tsurutani*","B.   Tsurutani*; E.   Echer; W. D.  Gonzalez","Jet Propulsion Laboratory, Calif. Inst. Tech. ; INPE","Sessioned","Body: Minima in geomagnetic activity (MGA) at Earth at the ends of SC23 and SC22 have been identified. The two MGAs (called MGA23 and MGA22, respectively) were present in 2009 and 1997, delayed from the sunspot number minima in 2008 and 1996 by ~1/2-1 years. Part of the solar and interplanetary causes of the MGAs were exceptionally low solar (and thus low interplanetary) magnetic fields. Another important factor in MGA23 was the disappearance of equatorial and low latitude coronal holes and the appearance of midlatitude coronal holes. The location of the holes relative to the ecliptic plane led to low solar wind speeds and low IMF (Bz) variances (σBz2) and normalized variances (σBz2/B02) at Earth, with concomitant reduced solar wind-magnetospheric energy coupling. One result was the lowest ap indices in the history of ap recording.   The results presented here are used to comment on the possible solar and interplanetary causes of the low geomagnetic activity that occurred during the Maunder Minimum. \n","1"
"NG41A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? II Posters","NG41A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","Revealing Hidden Electron Holes in the Auroral Current Regions with Cluster","NG41A-1540","8:00 AM","8:00 AM","J. S.  Pickett*","J. S.  Pickett*; R.   Pottelette; I.   Christopher; C.   Forsyth; A. N.  Fazakerley","Univ Iowa; LPP; UCL Mullard Space Science Laboratory","Sessioned","Body: Using high time resolution Cluster Wideband (WBD) waveform data obtained in both the upward and downward auroral current regions, we present evidence, for the first time, of fast (few 10s of microseconds) and very fast (5-8 microseconds) Electrostatic Solitary Waves (ESWs), which are usually considered to be the signature of the presence of electron holes.  The fast ESWs have long been hidden in previous observations due to limitations of the instrumentation that samples in the time domain, preservation of the data only in the frequency domain after onboard transformation, or sampling only in the frequency domain with filterbanks. Thus, through comparison with the Cluster WBD data, we show that the broadband spectra obtained by the FAST spacecraft in the auroral current regions are consistent with ESWs having time durations on the order of 10 microseconds or less.  We provide the properties of the hidden ESWs for a few different auroral region transits by the Cluster spacecraft.  We compare the properties of these fast ESWs to those observed in a laboratory experiment (Lefebvre et al., 2010) involving electron beam injection, where the ESWs were concluded to be generated from a lower hybrid instability driven by parallel currents.  We conclude by briefly discussing the possibilities for the generation of these fast ESWs observed by Cluster, including the two stream instability and resonant interaction with beam electrons.\n","2"
"NG41A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? II Posters","NG41A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","Modes of response of the ring current and radiation belts to interplanetary drivers","NG41A-1541","8:00 AM","8:00 AM","D.   Vassiliadis*","D.   Vassiliadis*; X.   Shao; M. W.  Liemohn; M.   Tornquist; M. E.  Koepke","West Virginia University; University of Maryland; University of Michigan","Sessioned","Body: It is often mentioned that the dynamic regimes of magnetic storms are difficult to categorize, with each storm being a distinct response to solar wind driving of the magnetosphere. We report on the ring current response to interplanetary drivers and compare with the known modes of response of the energetic electron flux. The Hot Electron and Ion Drift Integrator (HEIDI) model is used to reproduce 20 storms driven by high-speed streams (HSS) and 20 storms driven by interplanetary coronal mass ejections (ICMEs). Observations of energetic electrons at 2 MeV during those storms are available from the SAMPEX and POLAR missions. While the ring current is driven by slowly-varying convective electric fields in the tail, the energetic electrons of the radiation belts respond to faster drivers such as impulses and waves. We use principal component analysis and filter techniques to compare the ion phase-space density and energetic electron flux dynamics. We find that the modes of response (P0, P1, and V1) of the electron flux are related to spatial and temporal modes of the ring current. The V1 mode corresponds to the intensification of the ring current during the main phase, and the P0 and P1 peak fluxes correspond to ion dynamic effects below and above the plasmapause respectively. The mechanisms present in HEIDI are ion energization (via wave-particle interaction) and loss (via wave-particle interactions, charge exchange, and Coulomb collisions). Finally the ICME-driven storms have spatiotemporal features related to all three electron-flux peaks while most HSS-driven storms display only two modes (P1 and V1) above the plasmapause. \n","3"
"NG41A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? II Posters","NG41A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","SOME FRACTAL DIMENSION ALGORITHMS AND THEIR APPLICATION TO TIME SERIES ASSOCIATED WITH  THE Dst A GEOMAGNETIC INDEX.","NG41A-1542","8:00 AM","8:00 AM","F.   Cervantes*","F.   Cervantes*; J.   Gonzalez; C.   Real; L.   Hoyos","UAM-AZCAPOTZALCO","Sessioned","Body: ABSTRACT:Chaotic invariants like fractal dimensions are used to characterize non-linear time series. The fractal dimension is an important characteristic of fractals that contains information about their geometrical structure at multiple scales. In this work four fractal dimension estimation algorithms are applied to non-linear time series. The algorithms employed are the Higuchi's algorithm, the Petrosian's algorithm, the Katz's Algorithm and the Box counting method.The analyzed time series are associated with natural phenomena, the Dst a geomagnetic index which monitors the world wide magnetic storm; the Dst index is a global indicator of the state of the Earth’s geomagnetic activity.The time series used in this work show a behavior self-similar, which depend on the time scale of measurements. It is also observed that fractal dimensions may not be constant over all time scales. \n","4"
"NG41A.* Dynamic Regimes of Space Plasmas: Deterministic or Stochastic? II Posters","NG41A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): SPA-Aeronomy (SA)SPA-Magnetospheric Physics (SM)SPA-Solar and Heliospheric Physics (SH)","Effects of Density Fluctuations on Weakly Nonlinear Alfven Waves:  An IST Perspective","NG41A-1543","8:00 AM","8:00 AM","R.   Hamilton*","R.   Hamilton*; N.   Hadley","Dept Math Eng & CS","Sessioned","Body: The effects of random density fluctuations on oblique, 1D, weakly nonlinear Alfven waves is examined through a numerical study of an analytical model developed by Ruderman [M.S. Ruderman, Phys. Plasmas, 9 (7), pp. 2940-2945, (2002).]. Consistent with Ruderman’s application to the one-parameter dark soliton, the effects on both one-parameter bright and dark solitons, the two-parameter soliton as well as pairs of one-parameter solitons were similar to that of Ohmic dissipation found by Hamilton et al. [R. Hamilton, D. Peterson, and S. Libby, J. Geophys. Res 114, A03104,doi:10.1029/2008JA013582 (2009).]  It was found in all cases where bright or two-parameter solitons are present initially, that the effects of density fluctuations results in the eventual damping of such compressive wave forms and the formation of a train of dark solitons, or magnetic depressions.\n","5"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","EXPLICIT COMPUTATIONS OF INSTANTONS AND LARGE DEVIATIONS IN BETA-PLANE TURBULENCE","NG41B-1544","8:00 AM","8:00 AM","J.   Laurie*","J.   Laurie*; F.   Bouchet; O.   Zaboronski","Ecole Normale Supérieure de Lyon; University of Warwick","Sessioned","Body: We use a path integral formalism and instanton theory in order to make explicit analytical predictions about large deviations and rare events in beta-plane turbulence.The path integral formalism is a concise way to get large deviation results in dynamical systems forced by random noise. In the most simple cases, it leads to the same results as the Freidlin-Wentzell theory, but it has a wider range of applicability. This approach is however usually extremely limited, due to the complexity of the theoretical problems. As a consequence it provides explicit results in a fairly limited number of models, often extremely simple ones with only a few degrees of freedom. Few exception exist outside the realm of equilibrium statistical physics.We will show that the barotropic model of beta-plane turbulence is one of these non-equilibrium exceptions. We describe sets of explicit solutions to the instanton equation, and precise derivations of the action functional (or large deviation rate function). The reason why such exact computations are possible is related to the existence of hidden symmetries and conservation laws for the instanton dynamics.We outline several applications of this apporach. For instance, we compute explicitly the very low probability to observe flows with an energy much larger or smaller than the typical one. Moreover, we consider regimes for which the system has multiple attractors (corresponding to different numbers of alternating jets), and discuss the computation of transition probabilities between two such attractors. These extremely rare events are of the utmost importance as the dynamics undergo qualitative macroscopic changes during such transitions.\n","1"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","  “Bunched Black Swans” in Complex Geosystems: Cross-Disciplinary Approaches to the Additive and Multiplicative Modelling of Correlated Extreme Bursts.","NG41B-1545","8:00 AM","8:00 AM","N. W.  Watkins*","N. W.  Watkins*; M.   Rypdal; O.   Lovsletten","British Antarctic Survey (NERC);  University of Warwick; University of Tromso","Sessioned","Body:  For all natural hazards, the question of when the next “extreme event” (c.f. Taleb’s “black swans”) is expected is of obvious importance. In the environmental sciences users often frame such questions in terms of average “return periods”, e.g. “is an X meter rise in the Thames water level a 1-in-Y year event ?”. Frequently, however, we also care about the emergence of correlation, and whether the probability of several big events occurring in close succession is truly independent, i.e. are the black swans “bunched”.  A “big event”, or a “burst”, defined by its integrated signal above a threshold, might be a single, very large, event, or, instead, could in fact be a correlated series of “smaller” (i.e. less wildly fluctuating) events. Several available stochastic approaches provide quantitative information about such bursts, including  Extreme Value Theory (EVT); the theory of records; level sets; sojourn times; and models of space-time “avalanches” of activity in non-equilibrium systems.  Some focus more on the probability of single large events. Others are more concerned with extended dwell times above a given spatiotemporal threshold: However, the state of the art is not yet fully integrated, and the above-mentioned approaches differ in fundamental aspects. EVT is perhaps the best known in the geosciences. It is concerned with the distribution obeyed by the extremes of datasets, e.g. the 100 values obtained by considering the largest daily temperature recorded in each of the years of a century. However, the pioneering work from the 1920s on which EVT originally built was based on independent identically distributed samples, and took no account of memory and correlation that characterise many natural hazard time series. Ignoring this would fundamentally limit our ability to forecast; so much subsequent activity has been devoted to extending EVT to encompass dependence. A second group of approaches, by contrast, has notions of time and thus possible non-stationarity explicitly built in. In record breaking statistics, a record is defined in the sense used in everyday language, to be the largest value yet recorded in a time series, for example, the 2004 Sumatran Boxing Day earthquake was at the time the largest to be digitally recorded. The third group of approaches (e.g. avalanches) are explicitly spatiotemporal and so also include spatial structure. This presentation will discuss two examples of our recent work on the burst problem. We will show numerical results extending the preliminary results presented in [Watkins et al, PRE, 2009] using a standard additive model, linear fractional stable motion (LFSM). LFSM explicitly includes both heavy tails and long range dependence, allowing us to study how these 2 effects compete in determining the burst duration and size exponent probability distributions. We will contrast these simulations with new analytical studies of bursts in a multiplicative process, the multifractal random walk (MRW). We will present an analytical derivation for the scaling of the burst durations and make a preliminary comparison with data from the AE index from solar-terrestrial physics. We believe our result is more generally applicable than the MRW model, and that it applies to a broad class of multifractal processes.\nURL: http://link.aps.org/doi/10.1103/PhysRevE.79.041124\n","2"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Extremes Value Theory for Dynamical System","NG41B-1546","8:00 AM","8:00 AM","V.   Lucarini*","V.   Lucarini*; D.   Faranda; J.   Wouters","University of Hamburg; University of Reading","Sessioned","Body: Extreme Value Theory has established itself an one of the most relevant mathematical methods for the investigation of geophysical data, as extremes play a vital role in the study of hazards. A very lively debate exists on the possibility of deriving extreme value laws for observables of deterministic dynamical systems. We will present an overview of some crucial results that allow to use extremes of selected observables in mixing dynamical systems for investigating the properties of the attractor, and we will briefly discuss the most relevant effects resulting from the introduction of noise in the system.\n","3"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Extreme Values Analysis of McMurdo Dry Valleys Long Term Ecological Research (LTER)","NG41B-1547","8:00 AM","8:00 AM","R.   Li*","R.   Li*; M. N.  Gooseff","Harvard University; Penn State University; Penn State University","Sessioned","Body: AbstractThe McMurdo Dry Valleys, Antarctica is often referred to as an extreme environment because of cold mean annual temperatures (-20 degrees C), and very dry conditions (<10 cm water equivalent precipitation annually).  However, the long-term database of the McMurdo Long Term Ecological Research project (>20 years in some cases) has not yet formally been analyzed to determine if statistically extreme events occur in this otherwise “extreme” ecosystem.  We analyzed limnology, stream, and meteorology datasets with the extRemes R software package. For each time series read, the extRemes package produced a Probability Plot, a Quantile Plot, a Return Level Plot, and a Density Plot of Generalized Extreme Value (GEV) Distribution. The four plots indicate the extent to which the observed distribution fits the GEV distribution. We found that, in particular, the conductivity of Delta Stream and Lost Seal Stream has all of daily means, daily maximums and daily minimums well fitted in GEV. The relative humidity of Commonwealth Glacier, Howard Glacier and Taylor Glacier is only well fitted in daily means and daily minimums, but daily maximums. On the contrary, radiation levels and soil temperatures never fit the GEV distribution. The other time series are fitted only in one or none of daily means, daily maximums and daily minimums. \nURL: http://www.mcmlter.org/data_home.htm\n","4"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","The probability density function (PDF) of Lagrangian Turbulence","NG41B-1548","8:00 AM","8:00 AM","B.   Birnir*","B.   Birnir*","UC Santa Barbara; UC Santa Barbara","Sessioned","Body: The statistical theory of Lagrangian turbulence is derived from the stochastic Navier-Stokes equation. Assuming that the noise in fully-developed turbulence is a generic noisedetermined by the general theorems in probability, the central limit theorem and the large deviation principle, we are able to formulate and solve the Kolmogorov-Hopf equation for the invariant measure of the stochastic Navier-Stokes equations. The intermittency corrections to the scaling exponents of the structure functions require a multiplicative (multipling the fluid velocity) noise in the stochastic Navier-Stokes equation. We let this multiplicative noise, in the equation, consists of a simple (Poisson) jump process and then show how the Feynmann-Kac formula produces the log-Poissonian processes, found by She and Leveque, Waymire and Dubrulle. These log-Poissonian processes give the intermittency corrections that agree with modern direct Navier-Stokes simulations (DNS) and experiments. The probability density function (PDF) plays a key role when direct Navier-Stokes simulations or experimental results are compared to theory. The statistical theory of turbulence is determined, including the scaling of the structure functions of turbulence,by the invariant measure of the Navier-Stokes equation and the PDFs for the various statistics (one-point, two-point, N-point) can be obtained by taking the trace of the corresponding invariant measures. Hopf derived in 1952 a functional equation for the characteristic function (Fourier transform) of the invariant measure. In distinction to the nonlinear Navier-Stokes equation, this  is a linear functional differential equation. The PDFs obtained from the invariant measures for the velocity differences (two-point statistics) are shown to be the four parameter generalized hyperbolic distributions, found by Barndorff-Nilsen. These PDF have heavy tails and a convex peak at the origin. A  suitable projection of the Kolmogorov-Hopf equations is  the differential equation determining the generalized hyperbolic distributions. Then we compare these PDFs with DNS results and experimental data. \nURL: http://cnls.math.ucsb.edu/publications\n","5"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Outliers and Extremes: Dragon-Kings or Dragon-Fools?","NG41B-1549","8:00 AM","8:00 AM","D. J.  Schertzer*","D. J.  Schertzer*; I.   Tchiguirinskaia; S.   Lovejoy","U. Paris-Est; McGill U.","Sessioned","Body: Geophysics seems full of monsters like Victor Hugo’s Court of Miracles and monstrous extremes have been statistically considered as outliers with respect to more normal events. However, a characteristic magnitude separating abnormal events from normal ones would be at odd with the generic scaling behaviour of nonlinear systems, contrary to “fat tailed” probability distributions and self-organized criticality.More precisely, it can be shown [1] how the apparent monsters could be mere manifestations of a singular measure mishandled as a regular measure. Monstrous fluctuations are the rule, not outliers and they are more frequent than usually thought up to the point that (theoretical) statistical moments can easily be infinite. The empirical estimates of the latter are erratic and diverge with sample size. The corresponding physics is that intense small scale events cannot be smoothed out by upscaling. However, based on a few examples, it has also been argued [2] that one should consider “genuine” outliers of fat tailed distributions so monstrous that they can be called “dragon-kings”. We critically analyse these arguments, e.g. finite sample size and statistical estimates of the largest events, multifractal phase transition vs. more classical phase transition. We emphasize the fact that dragon-kings are not needed in order that the largest events become predictable. This is rather reminiscent of the Feast of Fools picturesquely described by Victor Hugo. [1] D. Schertzer, I. Tchiguirinskaia, S. Lovejoy et P. Hubert (2010): No monsters, no miracles: in nonlinear sciences hydrology is not an outlier! Hydrological Sciences Journal, 55 (6) 965 – 979.  [2] D. Sornette (2009): Dragon-Kings, Black Swans and the Prediction of Crises. International Journal of Terraspace Science and Engineering 1(3), 1-17.\nURL: http://leesu.univ-paris-est.fr/Hydro-Meterologie-et-Complexite-HM,685\n","6"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","The Multifractal Flood Frequency Analysis to Account Long Range Dependencies and the Clustering of Extremes","NG41B-1550","8:00 AM","8:00 AM","I.   Tchiguirinskaia*","I.   Tchiguirinskaia*; D. J.  Schertzer; S.   Lovejoy","Ecole des Ponts ParisTech; McGill University ","Sessioned","Body: The classical quantile distributions in existing flood studies often rely on two hypotheses that are questionable: stationarity and independency of the components of the time series. We discuss how to better (statistically) predict the floods by using a physically based approach that accounts long range dependencies and the clustering of extremes often resulting in fat tailed (i.e., an algebraic type) probability distributions. It established on systems that respect a scale symmetry over a wide range of space-time scales to determine the relationship between flood magnitude and return period for a wide range of aggregation periods. The results were obtained during the CEATI Project “Multifractals and physically based estimates of extreme floods”. The ambition of this project was to investigate very large data sets of reasonable quality (e.g., daily stream flow data recorded for at least 20 years for several thousands of gages distributed all over Canada and the USA). The multifractal parameters such as the mean intermittency parameter and the multifractality index were estimated on 8332 time series. Obtained results demonstrate that beyond the classical sampling of the extremes and its limitations, there is the possibility to eliminate long-range dependency by uncovering a stochastic process whose fractional integration would generate the observed long-range dependent process. The results confirm the dependence of parameter estimates on the length of available data. Then developing a metric for parameter estimation error became a principal step in uncertainty evaluation with respect to the multifractal estimates. A technique for estimating confidence intervals with the help of a Bayesian approach was developed. A detailed comparison of multifractal quantile plots and paleoflood data validates the forthcoming use of the multifractal flood frequency analysis.\nURL: http://leesu.univ-paris-est.fr/-Multifractal-Flood-Frequency-\n","7"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Cyanobacterial Blooms and Turbulence Intermittency in Lakes, a Multifractal Correlation Analysis","NG41B-1551","8:00 AM","8:00 AM","Y.   Mezemate*","Y.   Mezemate*; I.   Tchiguirinskaia; B.   Lemaire; B.   Vincon Leite ; C.   Bonhomme; D. J.  Schertzer; S.   Lovejoy","U. Paris-Est; McGill U.","Sessioned","Body: Proliferation of noxious cyanobacteria in lakes is an environmental issue and a matter of public health. In the framework of the PLUMMME project, we investigate the predictability of these events with the help of precursory fields, which are easy to measure (e.g. water temperature). The classical approach would rely on second order correlations at a given scale of cyanobacteria fluorescence with the precursors. However, this would not be consistent with the multiscale variability of lake dynamics resulting from nonlinear interactions between different scales and processes., We therefore performed spectral analyses of the velocity, temperature and cyanobacteria fluorescence measurements obtained in the framework of the PROLIPHYC project, to get preliminary estimates of their scaling ranges. For instance, the temperature spectrum over small scales is rather similar to that of a passive scalar. To go beyond the limitations of a second order statistical analysis, we performed multifractal analyses of these fields, with the help of Trace Moment and Double Trace Moment techniques. The estimated scaling moment function K(q) is clearly nonlinear with respect to the statistical moment order q.  These fields are therefore multifractal and consequently intermittent. As a result, we proceed to a multifractal correlation analysis between these fields, i.e. a correlation analysis across scales and for various statistical order q’s, in particular between temperature and cyanobacteria fluorescence .In conclusion, we discuss the predictability of the proliferation of cyanobacteria from temperature measurements, which results from their multifractal correlation\nURL: http://leesu.univ-paris-est.fr/Hydro-Meterologie-et-Complexite-HM,685\n","8"
"NG41B. Multiplicity of Scales, Dynamics, and Extremes in Geophysics: Theory, Validation, and Applications II Posters","NG41B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Cryosphere (C)Earth and Planetary Surface Processes (EP)Global Environmental Change (GC)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Detection of High Quality Rainfall Data to Improve Flood Resilience","NG41B-1552","8:00 AM","8:00 AM","T. C.  Hoang*","T. C.  Hoang*; I.   Tchiguirinskaia; D. J.  Schertzer; S.   Lovejoy","Vietnam Water Resources University; Ecole des Ponts ParisTech; McGill University ","Sessioned","Body: European flood management systems require reliable rainfall statistics, e.g. the Intensity-duration-Frequency curves for shorter and shorter durations and for a larger and larger range of return periods. Preliminary studies showed that the number of floods depends on the quality of available data, e.g. the time resolution quality. These facts suggest that a particular attention should be paid to the rainfall data quality in order to adequately investigate flood risk aiming to achieve flood resilience.The potential consequences of changes in measuring and recording techniques have been somewhat discussed in the literature with respect to a possible introduction of artificial inhomogeneities in time series. In this direction, we developed a first version of a SERQUAL procedure to automatically detect the effective time resolution of highly mixed data. We show that most of the rainfall time series have a lower recording frequency than that is assumed. This question is particularly important for operational hydrology, because an error on the effective recording high frequency introduces biases in the corresponding statistics. It is therefore essential to quantify the quality of the rainfall time series before their use.Due to the fact that the multiple scales and possible scaling behaviour of hydrological data are particularly important for many applications, including flood resilience research, this paper first investigates the sensitivity of the scaling estimates and methods to the deficit of short duration rainfall data, and consequently propose a few simple criteria for a reliable evaluation of the data quality. The SERQUAL procedure enable us to extract high quality sub-series from longer time series that will be much more reliable to calibrate and/or validate short duration quantiles and hydrological models.\n","9"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Geostrophic balance and the emergence of helicity in rotating stratified turbulence","NG41C-1553","8:00 AM","8:00 AM","R.   Marino*","R.   Marino*; P.   Mininni; D. L.  Rosenberg; A.   Pouquet","Institute for Mathematics Applied to Geosciences (IMAGe), CISL/NCAR; Departamento de Fìsica, Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires and IFIBA, CONICET","Sessioned","Body: We perform  numerical simulations of decaying rotating stratified turbulence and show, in the Boussinesq framework, that helicity (velocity-vorticity correlation), as observed  in super-cell storms and hurricanes, is created due to geostrophic balance common to large-scale atmospheric and oceanic flows. Helicity emerges from the joint action of eddies and of inertial and gravity waves of respective frequencies f and N, and it occurs when the waves are  sufficiently strong, with N/f < 3. Outside this regime, and up  to the highest Reynolds number obtained in this study, namely Re ≈ 10^4,  helicity production is found to be persistent for N/f as large as ~ 17.\n","1"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Scaling of vortex generation by breaking surface gravity waves.","NG41C-1554","8:00 AM","8:00 AM","N. E.  Pizzo*","N. E.  Pizzo*; W. K.  Melville","University of California San Diego ","Sessioned","Body: The connection between wave dissipation by breaking deep water surface gravity waves and the resulting turbulence and mixing is crucial for an improved understanding of air-sea interaction processes.  In this study, we consider the relationship between a breaking wave and an impulsively forced fluid, allowing us to build upon the classical work on vortex ring phenomena to quantify the circulation generated by a breaking wave.  From this we find that the circulation $\Gamma = \chi c^3/g$, where $\chi$ is a proportionality factor, $c$ is the phase speed of the wave and $g$ is the acceleration due to gravity. Using a scaling argument, we show that $\chi= \alpha (hk)^{\frac{3}{2}}$, where $hk$ is a breaking slope parameter and $\alpha$ is a constant. This formula then allows us to find a direct relationship between the circulation and the wave energy dissipation rate due to breaking, $\epsilon$. We find agreement between our model and the limited available experimental data. An application of this theory to ocean surface processes will be discussed. \n","2"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Modeling Second-Order Chemical Reactions using Cellular Automata","NG41C-1555","8:00 AM","8:00 AM","N. E.  Hunter*","N. E.  Hunter*; C. C.  Barton; P. G.  Seybold; M. M.  Rizki","Wright State University; Wright State University; Wright State University; Wright State University","Sessioned","Body: Cellular automata (CA) are discrete, agent-based, dynamic, iterated, mathematical computational models used to describe complex physical, biological, and chemical systems. Unlike the more computationally demanding molecular dynamics and Monte Carlo approaches, which use “force fields” to model molecular interactions, CA models employ a set of local rules. The traditional approach for modeling chemical reactions is to solve a set of simultaneous differential rate equations to give deterministic outcomes. CA models yield statistical outcomes for a finite number of ingredients. The deterministic solutions appear as limiting cases for conditions such as a large number of ingredients or a finite number of ingredients and many trials. Here we present a 2-dimensional, probabilistic CA model of a second-order gas phase reaction A + B → C, using a MATLAB basis. Beginning with a random distribution of ingredients A and B, formation of C emerges as the system evolves. The reaction rate can be varied based on the probability of favorable collisions of the reagents A and B. The model permits visualization of the conversion of reagents to products, and allows one to plot concentration vs. time for A, B and C. We test hypothetical reaction conditions such as: limiting reagents, the effects of reaction probabilities, and reagent concentrations on the reaction kinetics. The deterministic solutions of the reactions emerge as statistical averages in the limit of the large number of cells in the array. Modeling results for dynamic processes in the atmosphere will be presented. \n","3"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Physical laboratory modeling of rain cell movement","NG41C-1556","8:00 AM","8:00 AM","J. d.  Lima*","J. d.  Lima*; M. P.  de Lima","Univ Coimbra; Institute of Marine Research (IMAR-CMA); Polytechnic Institute of Coimbra","Sessioned","Body: Modeling hydrologic response normally assumes that rainfall storms are stationary, i.e., a storm upon arrival over a hillslope or catchment remains stationary during the rainfall event and then disappears instantaneously. However, these assumptions might introduce errors in model results. They are far from the real rainfall distributions that are highly variable both in space and time. To contribute to the increased understanding of the effect of storm movement on overland flow and erosion dynamics, there have been several attempts to conduct experimental work, under controlled conditions, to create in the laboratory these nonlinear interactions. This implies the simulation of rainfall over physical models (e.g. soil flumes). This study reports results on the investigation of several schemes for the simulation of rainfall events in the laboratory and the implications for the characteristics of the simulations. Laboratory experiments were conducted using several spraying nozzles that generate a rain cell like structure, i.e. with a non-uniform rainfall distribution. The laboratory set-up permits the movement of the simulated rain cells over the physical models, generating non-static storms moving along different directions; the simulation is accompanied by the generation of wind that changes the characteristics of the simulated rain, namely the rain intensity and drop fall angle and velocity. The formed raindrop distribution and fall velocity are recorded using a laser disdrometer.\n","4"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Large scale statistical fluctuations of precipitation in Portugal during the 20th century","NG41C-1557","8:00 AM","8:00 AM","M. P.  de Lima*","M. P.  de Lima*; F.   Espírito Santo","Institute of Marine Research (IMAR-CMA); Polytechnic Institute of Coimbra; Institute of Meteorology","Sessioned","Body: The impact of changes in climate variables on society and the environment is a major issue worldwide. For example, variations in precipitation over daily, seasonal, annual, and decadal time-scales have an impact on water balances. Although large ranges of spatial and temporal scales are involved, the local impact can be affected by local conditions and regional specificities. This is particularly true and relevant for Portugal, where climate variables are very irregular in space and time.In this study we explore the statistics and temporal structure of precipitation from Portugal over wide ranges of scales using scaling and multifractal methods. In particular, spectral analysis locates the dominant frequencies, and is a useful exploratory tool to identify the upper and lower scales that bound scale-invariant regimes. Moreover, it allows us to investigate climatic fluctuations in the data, over the largest scales, as well as high frequency dynamics revealed by the small scales. The instrumental data investigated are from various locations scattered across Portugal; some of the time series date back to the 19th century. These precipitation time series are the longest available in this geographic region. The focus is on the low frequency weather regime characterized by a spectral plateau with relatively small spectral exponent defined by the power spectrum. This regime extends out to the time scale after which the spectral exponent increases again (i.e. with decreasing frequency), which is interpreted as the signature of the climate regime. The results highlight scaling properties in the data from different origins and identify scaling regimes of special interest for the understanding of climate multi-decadal variability and trends and the establishment of climate change scenarios.\n","5"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Trends, noise and re-entrant long-term persistence in Arctic sea ice","NG41C-1558","8:00 AM","8:00 AM","S.   Agarwal*","S.   Agarwal*; W.   Moon; J. S.  Wettlaufer; J. S.  Wettlaufer","Indian Institute of Technology Guwahati; Yale University; Yale University; Yale University; Nordic Instituite of Theoritical Physics","Sessioned","Body: We examine the long-term correlations and multi-fractal properties of daily satellite retrievals of Arctic sea ice albedo and extent, for periods of approximately 23 years and 32 years, respectively. The approach harnesses a recent development called multifractal temporally weighted detrended fluctuation analysis, which exploits the intuition that points closer in time are more likely to be related than distant points. In both datasets, we extract multiple crossover times, as characterized by generalized Hurst exponents, ranging from synoptic to decadal. The method goes beyond treatments that assume a single decay scale process, such as a first-order autoregression, which cannotbe justifiably fitted to these observations. Importantly, the strength of the seasonal cycle ‘masks’ long-term correlations on time scales beyond seasonal. When removing the seasonal cycle from the original record, the ice extent data exhibit white noise behaviour from seasonal to bi-seasonal time scales, whereas the clear fingerprints of theshort (weather) and long (approx. 7 and 9 year) time scales remain, the latter associated with the recent decay in the ice cover. Therefore, long-term persistence is re-entrant beyond the seasonal scale and it is not possible to distinguish whether a given ice extent minimum/maximum will be followed by a minimum/maximum that is larger or smaller in magnitude.\n","6"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Phytoplankton dynamics and blooms: study of the spectral dynamics and extreme intensities using high frequency data","NG41C-1559","8:00 AM","8:00 AM","J.   Derot*","J.   Derot*; F. G.  Schmitt; V.   Gentilhomme; S.   Zongo","CNRS-LOG","Sessioned","Body: We consider in this study the fluorescence time series from an automatic measuring buoy in the Eastern English Channel (Boulogne-sur-mer, France). The data are recorded at an automatic station equipped with physic-chemical measuring devices with time resolution of 20 minutes. The fluorescence data are measured from 2004 to present and the fluorescence sensor covers measurement from 0 up to 50 FFU.The fluorescence data from 2004 to 2012 reveal very large fluctuations at all scales showing the different intensities that are often associated with phytoplankton blooms. We consider the dynamics by studying the Fourier power-law regimes and also by using empirical mode decomposition of the time series. In order to consider the extremes, we estimate the probability density function of fluorescence and characterize its extremes by comparing lognormal and power law fits. We finally perform year-by-year analyses of the dynamics and extreme statistics, in order to obtain universal behaviour in relation with mean annual abundance.\n","7"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","Stochastic properties of the water level time series in the Eastern English channel, France","NG41C-1560","8:00 AM","8:00 AM","F. G.  Schmitt*","F. G.  Schmitt*; A.   Crapoulet; A.   Hequette","CNRS","Sessioned","Body: We consider here water level time series recorded in the Eastern English Channel by the SHOM (Service Hydrographique et Oceanographique de la Marine, France) in the port of Dunkerque, every hour from 1956 to 2010. Water level is a complex quantity, influenced by deterministic astronomic forcing (tides, daily cycle, etc.) and also by stochastic forcing: water temperature, atmospheric pressure, turbulence. The deterministic forcing are strong and can be used to reconstruct synthetic water level predictions, also provided hourly by the SHOM. Stochastic forcing exist at all scales from minutes to centuries. Here we use the two datasets to explore the statistical and dynamical properties of both series, deterministic reconstruction and experimental measurements. We estimate power spectra, and return times statistics for different water level thresholds. We show that the measured time series has some scaling properties (between day and year) that are not shown by the synthetic series, indicating that this is a signature of the stochastic forcing. We also show that, for large thresholds, return time statistics between synthetic series and measured ones, are markedly different. Applications of this study belong to littoral flood risk assessments.\n","8"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","The Relation Between the Statistics of Open Ocean Currents and the Temporal Correlations of the Wind-Stress","NG41C-1561","8:00 AM","8:00 AM","G.   Bel*","G.   Bel*; Y.   Ashkenazy","Ben-Gurion University of the Negev","withdrawn","","9"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","The climate is not what you expect","NG41C-1562","8:00 AM","8:00 AM","S.   Lovejoy*","S.   Lovejoy*; D.   Varon; D. J.  Schertzer","Physics, McGill University, 3600 University St.; LEESU, Ecole des Ponts ParisTech, Université Paris Est","Sessioned","Body: Prevailing definitions of climate are not much different from “the climate is what you expect, the weather is what you get”.  Using a variety of sources including reanalyses and paleo data, and aided by notions and analysis techniques from Nonlinear Geophysics, we argue that this dictum is fundamentally wrong.  In addition to the weather and climate, there is a qualitatively distinct intermediate regime extending over a factor of ≈ 1000 in scale.  For example, mean temperature fluctuations increase up to about 5 K at 10 days (the lifetime of planetary structures), then decrease to about 0.2 K at 30 years, and then increase again to about 5 K at glacial-interglacial scales.Both deterministic GCM’s with fixed forcings (“control runs”) and stochastic turbulence-based models reproduce the first two regimes, but not the third.  The middle regime is thus a kind of low frequency “macroweather” not “high frequency climate”.  Regimes whose fluctuations increase with scale appear unstable whereas regimes where they decrease appear stable.  If we average macroweather states over periods ≈ 30 years, the results thus have low variability.  In this sense, macroweather is what you expect.We can use the critical duration of ≈ 30 years to define (fluctuating) “climate states”.  As we move to even lower frequencies, these states increasingly fluctuate – appearing unstable so that the climate is not what you expect.  The same methodology allows us to categorize climate forcings according to whether their fluctuations decrease or increase with scale and this has important implications for GCM’s and for climate change and climate predictions.\n","10"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","A Characterization of Pleistocene Climate as Revealed by Empirical Mode Decomposition","NG41C-1563","8:00 AM","8:00 AM","M. J.  Rodrigues*","M. J.  Rodrigues*; C. D.  Camp; P. A.  Martin; A.   Gerber","California Polytechnic State University; Indiana University – Purdue University Indianapolis ","Sessioned","Body: A consensus as to the characterization of the Pleistocene’s climate with respect to Milankovich theory (the forcing of climate by orbital dynamics) has remained elusive. In part, this is due of the shortcomings of classical techniques such as Fourier analysis in the study of nonlinear, nonstationary data. Confounding this problem, the age-depth relationship used to produce reconstructed time series of proxy data for past climate derived from ocean sediments often are tuned by assuming that the records have some component of climate change associated to one of the orbital parameters. Recently, a new time-series of proxy data for the waxing and waning of the ice ages has been constructed devoid of orbital assumptions -- thereby allowing for clearer testing of the validity of Milankovich theory and related hypothesis for the timing and amplitude of the Pleistocene ice ages. We analyze this newly constructed record using a relatively new data-adaptive technique known as empirical mode decomposition (EMD), which is well suited for the study of nonlinear and nonstationary time data. Our EMD analysis clearly isolates the various components of this complicated time series and provides new insight into the behavior of the climate during the Pleistocene. \n","11"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)","How Many Water Masses Fill the Ocean?: A Spectral Unmixing Approach ","NG41C-1564","8:00 AM","8:00 AM","G.   Gebbie*","G.   Gebbie*","Woods Hole Oceanographic Inst.","Sessioned","Body: An inversion of oceanic property distributions reveals that the importance of surface regions to the filling of the interior ocean follows simple scaling laws (Gebbie & Huybers 2011). For example, 15% of the surface area fills 85% of the ocean interior volume, reminiscent of the 80-20 law in statistics and economics. Furthermore, the Nth most important surface box (when discretized at 2 by 2 degree spatial resolution) contributes about 1/N times the volume filled by the most important box. This shallow power law appears to indicate that many thousand surface locations all significantly influence the interior ocean, but traditional water mass analyses have been successful with just a handful of water masses. If optimal sets of water properties are chosen (i.e., water masses), how many water masses are necessary to explain oceanic spatial variability: just a handful or many thousand? The waters at any interior location are composed of a distribution of surface waters, and the optimal water masses will be the combinations of surface waters that recur the most often, usually due to homogenization in isolated ocean basins or geometrical constrictions that favor the passage of particular waters. In satellite image analysis, the mathematical problem of extracting the mixture of constituent materials in the visible spectrum, called spectral unmixing, is shown to be equivalent to the optimal water mass problem. Using a nonlinear optimization method borrowed from engineering, the ocean is spectrally unmixed and the most important water masses are found and ranked. This method shows the maximum fraction of ocean variability explained by any given number of water masses. In particular, we find the number of water masses needed to explain 95% of ocean property variability, and reconcile the differences to the previous studies that suggested the number should be very small or very large.\n","12"
"NG41C.* Nonlinear and Scaling Processes in the Atmosphere and Ocean at All Scales, From Microscales to Climate II Posters","NG41C","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Biogeosciences (B)Global Environmental Change (GC)Ocean Sciences (OS)"," Investigating the Mid-Pleistocene Transition via Data and Dynamical Systems Analyses.","NG41C-1565","8:00 AM","8:00 AM","C. D.  Camp*","C. D.  Camp*; S.   Oestreicher; M. J.  Rodrigues","California Polytechnic State University; University of Minnesota","Sessioned","Body: The mid-Pleistocene transition is an excellent opportunity for investigating the variability of the Earth's climate, however the cause of this transition remains elusive. The data records of the Pleistocene exhibit a transition from a dominant 41kyr periodicity to a dominant 100kyr periodicity; but this occurs during a period when the orbital forcing from 100kyr cycles in eccentricity is getting weaker while the orbital forcing from the 41kyr cycles in obliquity remains strong. An analysis applying empirical mode decomposition (EMD) to a recently constructed benthic record devoid of orbital tuning suggests that the transition consists of a persistent 41kyr cycle with an emergent 100kyr cycle. A nonlinear paleoclimate model coupling global ice volume, atmospheric carbon and oceanic deep water formation, is used to investigate the source of the emergent 100kyr cycle. This model exhibits an internal oscillation with a periodicity of 100kyr and contains several Hopf bifurcations at reasonable parameter values. These bifurcations provide a potential explanation for the mid-Pleistocene transition consistent with signal extracted in the EMD analysis of the benthic record. An new internal 100kyr oscillation of earth's climate may have appeared via a bifurcation, phase locked to the weak eccentricity forcing.\n","13"
"NG41D. Particle Filters for Nonlinear Data Assimilation I","NG41D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","9:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Improved diffusion Monte Carlo and the Brownian fan <i>(Invited)</i>","NG41D-01","8:00 AM","8:15 AM","J.   Weare*","J.   Weare*; M.   Hairer","University of Chicago; University of Warwick","Sessioned","Body: Diffusion Monte Carlo (DMC) is a workhorse of stochastic computing.  It was invented forty years ago as the central component in a Monte Carlo technique for estimating various characteristics of quantum mechanical systems.  Since then it has been used in applied in a huge number of fields, often as a central component in sequential Monte Carlo techniques (e.g. the particle filter).   DMC computes averages of some underlying stochastic dynamics weighted by a functional of the path of the process.  The weight functional could represent the potential term in a Feynman-Kac representation of a partial differential equation (as in quantum Monte Carlo) or it could represent the likelihood of a sequence of noisy observations of the underlying system (as in particle filtering).  DMC alternates between an evolution step in which a collection of samples of the underlying system are evolved for some short time interval, and a branching step in which, according to the weight functional, some samples are copied and some samples are eliminated.  Unfortunately for certain choices of the weight functional DMC fails to have a meaningful limit as one decreases the evolution time interval between branching steps.  We propose a modification of the standard DMC algorithm. The new algorithm has a lower variance per workload, regardless of the regime considered. In particular, it makes it feasible to use DMC in situations where the ``naive'' generalization of the standard algorithm would be impractical, due to an exponential explosion of its variance.  We numerically demonstrate the effectiveness of the new algorithm on a standard rare event simulation problem (probability of an unlikely transition in a Lennard-Jones cluster), as well as a high-frequency data assimilation problem.   We then provide a detailed heuristic explanation of why, in the case of rare event simulation, the new algorithm is expected to converge to a limiting process as the underlying stepsize goes to 0.  This is shown rigorously in the simplest possible situation of a random walk, biased by a linear potential.  The resulting limiting object, which we call the ``Brownian fan'', is a very natural new mathematical object of independent interest.\nURL : http://arxiv.org/abs/1207.2866\n","1"
"NG41D. Particle Filters for Nonlinear Data Assimilation I","NG41D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","9:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Implicit assimilation for marine ecological models <i>(Invited)</i>","NG41D-02","8:15 AM","8:30 AM","B.   Weir*","B.   Weir*; R.   Miller; Y. H.  Spitz","Oregon State University","Sessioned","Body: We use a new data assimilation method to estimate the parameters of a marineecological model.  At a given point in the ocean, the estimated values of theparameters determine the behaviors of the modeled planktonic groups, and thusindicate which species are dominant.  To begin, we assimilate in situobservations, e.g., the Bermuda Atlantic Time-series Study, the Hawaii OceanTime-series, and Ocean Weather Station Papa.  From there, we estimate theparameters at surrounding points in space based on satellite observations ofocean color.  Given the variation of the estimated parameters, we divide theocean into regions meant to represent distinct ecosystems.  An importantfeature of the data assimilation approach is that it refines the confidencelimits of the optimal Gaussian approximation to the distribution of theparameters.  This enables us to determine the ecological divisions with greateraccuracy.\n","2"
"NG41D. Particle Filters for Nonlinear Data Assimilation I","NG41D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","9:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Data Assimilation with Optimal Maps","NG41D-03","8:30 AM","8:45 AM","T.   El Moselhy*","T.   El Moselhy*; Y.   Marzouk","MIT","Sessioned","Body: Tarek El Moselhy and Youssef MarzoukMassachusetts Institute of TechnologyWe present a new approach to Bayesian inference that entirely avoids Markov chain simulation and sequential importance resampling, by constructing a map that pushes forward the prior measure to the posterior measure. Existence and uniqueness of a suitable measure-preserving map is established by formulating the problem in the context of optimal transport theory. The map is written as a multivariate polynomial expansion and computed efficiently through the solution of a stochastic optimization problem.While our previous work [1] focused on static Bayesian inference problems, we now extend the map-based approach to sequential data assimilation, i.e., nonlinear filtering and smoothing. One scheme involves pushing forward a fixed reference measure to each filtered state distribution, while an alternative scheme computes maps that push forward the filtering distribution from one stage to the other. We compare the performance of these schemes and extend the former to problems of smoothing, using a map implementation of the forward-backward smoothing formula.Advantages of a map-based representation of the filtering and smoothing distributions include analytical expressions for posterior moments and the ability to generate arbitrary numbers of independent uniformly-weighted posterior samples without additional evaluations of the dynamical model. Perhaps the main advantage, however, is that the map approach inherently avoids issues of sample impoverishment, since it explicitly represents the posterior as the pushforward of a reference measure, rather than with a particular set of samples. The computational complexity of our algorithm is comparable to state-of-the-art particle filters. Moreover, the accuracy of the approach is controlled via the convergence criterion of the underlying optimization problem. We demonstrate the efficiency and accuracy of the map approach via data assimilation in several canonical dynamical models, e.g., a stochastic volatility model, as well as the Lorenz-63 and Lorenz-96 systems.[1] Moselhy, T. A., Marzouk, Y. M. Bayesian inference with optimal maps. arXiv:1109.1516. Journal of Computational Physics (in press, 2012).\n","3"
"NG41D. Particle Filters for Nonlinear Data Assimilation I","NG41D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","8:00 AM","9:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Weighted Ensemble Square Root Filters for Non-linear, Non-Gaussian, Data Assimilation","NG41D-04","8:45 AM","9:00 AM","D. M.  Livings*","D. M.  Livings*; P.   van Leeuwen","University of Reading","withdrawn","","4"
"NG41E. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics I","NG41E","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","9:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Data assimilation in the low noise regime <i>(Invited)</i>","NG41E-01","9:00 AM","9:15 AM","J.   Weare*","J.   Weare*; E.   Vanden-Eijnden","University of Chicago; New York University","Sessioned","Body: On-line data assimilation techniques such as ensemble Kalman filters and particle filters tend to lose accuracy dramatically when presented with an unlikely observation.  Such observation may be caused by an unusually large measurement error or reflect a rare fluctuation in the dynamics of the system.  Over a long enough span of time it becomes likely that one or several of these events will occur.  In some cases they are signatures of the most interesting features of the underlying system and their prediction becomes the primary focus of the data assimilation procedure.  The Kuroshio or Black Current that runs along the eastern coast of Japan is an example of just such a system.  It undergoes infrequent but dramatic changes of state between a small meander during which the current remains close to the coast of Japan, and a large meander during which the current bulges away from the coast.  Because of the important role that the Kuroshio plays in distributing heat and salinity in the surrounding region, prediction of these transitions is of acute interest.  { Here we focus on a regime in which both the stochastic forcing on the system and the observational noise are small.  In this setting large deviation theory can be used to understand why standard filtering methods fail and guide the design of the more effective data assimilation techniques.   Motivated by our large deviations analysis we propose several data assimilation strategies capable of efficiently handling rare events such as the transitions of the Kuroshio.  These techniques are tested on a model of the Kuroshio and shown to perform much better than standard filtering methods.\nURL : http://arxiv.org/abs/1202.4952\n","1"
"NG41E. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics I","NG41E","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","9:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Stochastic averaging and jet formation in geostrophic turbulence <i>(Invited)</i>","NG41E-02","9:15 AM","9:30 AM","F.   Bouchet*","F.   Bouchet*; C.   Nardini; T.   Tangarife","Ecole Normale Superieure de Lyon and CNRS","Sessioned","Body: We consider the formation of large scale structures (zonal jets and vortices), in geostrophic turbulence forced by random forces. We study the limit of a time scale separation between inertial dynamics on one hand, and the effect of forces and dissipation on the other hand. We prove that stochastic averaging can be performed explicitly in this problem, which is unusual in turbulent systems. It is then possible to integrate out all fast turbulent degrees of freedom, and to get explicitly an equation that describe the slow evolution of zonal jets.The equation for the slow evolution of zonal jets, is a one dimensional stochastic differential equation with multiplicative noise. The average is described by a non-linear Fokker-Planck equation. This equation describe the attractors for the dynamics (alternating zonal jets, whose number depend on the force spectrum), and the relaxation towards those attractors. We describe regime where the system has several attractors for the same force spectrum. Stochastic averaging in systems with two separated time scale involve the computation of determinants of Ornstein--Ulhenbeck processes. In systems governed by partial differential equations, those are quantities which are usually extremely hard to compute and to study. In our study, we prove that those determinants factorize as product of simpler determinants. Each of these simpler objects can be computed relying on equilibrium statistical mechanics. The overall processes is however a genuine non-equilibrium one, making the result unique.\nURL : http://perso.ens-lyon.fr/freddy.bouchet/\n","2"
"NG41E. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics I","NG41E","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","9:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","A coarse grained stochastic particle interacting system for tropical convection <i>(Invited)</i>","NG41E-03","9:30 AM","9:45 AM","B.   Khouider*","B.   Khouider*","University of Victoria","Sessioned","Body: Climate models (GCMs)  fail to represent adequately the variability associated with organized convection in the tropics. This deficiency is believed  to hinder medium and long range weather forecasts, over weeks to months. GCMs use very complex sub-grid models, known as cumulus parameterizations, to represent the effects of clouds and convection as well as other unresolved processes. Cumulus parameterizations are intrinsically deterministic and are typically based on the quasi-equilibrium theory, which assumes that convection instantaneously consumes the atmospheric instability produced by radiation.  In this talk, I will discuss a stochastic model  for organized tropical convection based on a particle interacting system defined on a microscopic lattice.  An order parameter is assumed to take the values 0,1,2,3 at a any given lattice site according to whether it is a clear site or it is occupied by a cloud of a one of the three types: congestus, deep, or stratiform, following intuitive rules motivated by recent  satellite observations and  various field campaigns conducted over the Indian Ocean and Western Pacific. The microscopic Markov process is  coarse-grained systematically to obtain a multidimensional birth-death process with immigration, following earlier work done by Katsoulakis, Majda, and Vlachos (JCP 2003) for the case of the Ising model where the order parameter takes the values 0 and 1. The coarse grained birth-death process is a stochastic model, intermediate between the microscopic lattice model and the deterministic mean field limit,   that is used to represent the sub-grid scale variability of the underlying physical process (here the cloud cover) with a negligible computational overhead and yet permits both local interactions between  lattice sites and two-way interactions between the cloud cover and the large-scale climate dynamics. The new systematic coarse-graining, developed here for the multivalued order parameter, provides a unifying framework,  generalizing the stochastic multicloud model of Khouider, Biello, and Majda (2010),  that can be used for many other applications in physical sciences and engineering.        \n","3"
"NG41E. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics I","NG41E","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","9:00 AM","10:00 AM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Understanding observed skewed climate statistics as a response to Correlated Additive and Multiplicative noise (CAM noise) forcing <i>(Invited)</i>","NG41E-04","9:45 AM","10:00 AM","P. D.  Sardeshmukh*","P. D.  Sardeshmukh*; G. P.  Compo; M. C.  Penland","University of Colorado; ESRL/NOAA","Sessioned","Body: The governing equations for atmospheric and oceanic evolution are obviously nonlinear. However, in many contexts the dynamics of climate anomalies on weekly to millennial scales are found to be nearly indistinguishable from that of a stochastically forced damped linear system, and even very simple low-order prediction models based on this approximation are competitive with comprehensive numerical weather and climate models. In this paradigm, natural variability is viewed simply as a linear superposition of randomly excited linear modes (RELM), and forced variability is the response to time-varying forcing given by the associated linear response operator. The stochastic noise forcing of the RELM represents an approximate accounting of incoherent (i.e., unpredictable) multi-scale nonlinear interactions in the system. There are several features of observed climate variability, most notably the often substantially asymmetric behavior of positive and negative anomalies, that are apparently inconsistent with this simple paradigm, with implications for the role of coherent nonlinear scale interactions.  We have recently shown that this apparent inconsistency can be resolved by allowing the stochastic noise forcing in the paradigm to have correlated additive and multiplicative noise (CAM noise) components. In this talk we will also show how CAM noise forcing, whose amplitude is different for positive and negative state anomalies, can explain the very different temporal persistence characteristics of positive and negative atmospheric circulation anomalies over the “blocking” regions of the north Pacific and north Atlantic oceans that are usually attributed to coherent nonlinear dynamics.\n","4"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Time-Series Modeling of Tide Gauge Records for Monitoring of the Crustal Activities Related to Oceanic Trench Earthquakes around Japan","NG43A-1566","1:40 PM","1:40 PM","H.   Nagao*","H.   Nagao*; T.   Higuchi; S.   Miura; D.   Inazu","The Institute of Statistical Mathematics; The University of Tokyo; National Institute for Earth Science and Disaster Prevention","Sessioned","Body: Tide gauge observations along the coastline of Japan have recorded the land sinking due to the continuous subduction of the oceanic plates, indicating that stress and strain energies have been accumulating at the plate boundary, which would eventually cause large oceanic trench earthquakes like the 2011 Great East Japan Earthquake. The proposed method extracts such long-term activities of the Earth's crust together with rapid displacements related to earthquakes, even before the establishment of the Global Positioning System (GPS), from monthly mean data of the sea levels. A state space model decomposes the tide gauge time-series into trend, seasonal, autoregressive, and observation noise components, each of which are estimated using the particle filter (PF) algorithm. The spatial and temporal distributions of the extracted trend component clearly indicate high risk regions, near which giant earthquakes have occurred or are predicted to occur. A multivariate analysis of the observatories located at the northeast coast of Japan successfully determines the past crustal displacement in the case of the 1978 Off-Miyagi Earthquake. The proposed method has potential application for monitoring crustal activities related to the accumulation of earthquake energy.\n","1"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Particle Kalman Filtering: A Nonlinear Bayesian Framework for Ensemble Kalman Filters","NG43A-1567","1:40 PM","1:40 PM","I.   Hoteit*","I.   Hoteit*; X.   Luo; D.   Pham","KAUST; CNRS","withdrawn","","2"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Particle filter with a proposal distribution generated by the ensemble transform Kalman filter","NG43A-1568","1:40 PM","1:40 PM","S.   Nakano*","S.   Nakano*; G.   Ueno","The Inst of Statistical Math","Sessioned","Body: The particle filter (PF) provides an approximation of a non-Gaussian probability density function (PDF) of the system state on the basis of the importance sampling/resampling approach. However, the PF usually requires a prohibitively large ensemble size to achieve a good estimation. Accordingly, the PF tends to require huge computational cost. One way to reduce the computational cost is to use the proposal PDF similar to the posterior PDF. In order to obtain a good proposal PDF, we consider to use the ensemble transform Kalman filter (ETKF), which is one of ensemble square root filters. If we obtain a proposal PDF by using the ETKF, we can efficiently generate a large number of samples from the proposal PDF. We then perform the importance sampling/resampling to represent the posterior PDF. The weight in the importance sampling/resampling procedure can be efficiently calculated for each of the samples due to some favorable properties of the ETKF. As the ETKF is derived under the assumption of a linear Gaussian observation model, it does not necessarily provide a good estimate in the case with non-linear or non-Gaussian observation. However, by introducing the importance sampling/resampling procedure as done in the normal PF, we can take into consideration a non-linear or non-Gaussian property of the observation. In this paper, we explain about the algorithm in which the proposal PDF is obtained using the ETKF. We also compare it with other algorithms which combines ensemble Kalman filters with the PF. \n","3"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Implicit particle filters and applications","NG43A-1569","1:40 PM","1:40 PM","X.   Tu*","X.   Tu*","University of Kansas","Sessioned","Body: Implicit particle filters use a new sampling technique which finds high-probability samples of multi- dimensional probability densities by solving equations with a random input. With this new  strategy, the particles generated by the filter will  focus on  high probability regions of the posterior probability density and, thus, the filter  is applicable even if the state dimension is large. We will present the details of implicit particle filters and some  applications to large scale problems.\n","4"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Recent Results from Application of the Implicit Particle Filter to High-dimensional Problems","NG43A-1570","1:40 PM","1:40 PM","R.   Miller*","R.   Miller*; B.   Weir; Y. H.  Spitz","Oregon State Univ","Sessioned","Body: We present our most recent results on the application of the implicit particle filter to a stochastic shallow water model of nearshore circulation. This highly nonlinear model has approximately 30,000 state variables, and, in our twin experiments, we assimilate 32 observed quantities. Application of most particle methods to problems of this size are subject to sample impoverishment. In our implementation of the implicit particle filter, we have found that manageable size ensembles can still retain a sufficient number of independent particles for reasonable accuracy. \n","5"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Implicit particle methods and their connection to weak and strong 4D-Var","NG43A-1571","1:40 PM","1:40 PM","M.   Morzfeld*","M.   Morzfeld*; E.   Atkins; A. J.  Chorin","Lawrence Berkeley National Lab; University of California, Berkeley","Sessioned","Body: The implicit particle filter is a Monte Carlo method for data assimilation. The idea is to guide the particles to remain in the high-probability regions of the posterior pdf. This is done in two steps. First, the high-probability regions are identified by a numerical minimization; second, samples within the high-probability regions are obtained by solving algebraic equations with a random right-hand-side. Specifically, the implicit particle filter finds the mode of the posterior pdf and then solves algebraic equations to obtain samples in the neighborhood of this mode. In variational data assimilation, one finds the mode of the posterior pdf. There is thus a connection between the implicit particle filter and variational data assimilation. In particular, one can turn variational codes into implicit particle filters by adding a sampling step (i.e. solving simple algebraic equations). The benefit can be that the implicit filter improves the state estimate by approximating the conditional mean, which is the minimum mean square error estimate. We present an example in detail to explain the implicit particle filter in its variational implementation.\n","6"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","Numerical experiments with an implicit particle filter for the shallow water equations","NG43A-1572","1:40 PM","1:40 PM","I.   Souopgui*","I.   Souopgui*; A. J.  Chorin; M.   Hussaini","Florida State University; Lawrence Berkeley National Laboratory","Sessioned","Body: The estimation of initial conditions for the shallow water equations for a given set of later data is a well known test problem for data assimilation codes. A popular approach to this problem is the variational method (4D-Var), i.e. the computation of the mode of the posterior probability density function (pdf) via the adjoint technique. Here, we improve on 4D-Var by computing the conditional mean (the minimum least square error estimator) rather than the mode (a biased estimator) and we do so with implicit sampling, a Monte Carlo (MC) importance sampling method.The idea in implicit sampling is to first search for the high-probability region of the posterior pdf and then to find samples in this region. Because the samples are concentrated in the high-probability region, fewer samples are required than with competing MC schemes. The search for the high-probability region can be implemented by a minimization that is very similar to the minimization in 4D-Var, and we make use of a 4D-Var code in our implementation. The samples are obtained by solving algebraic equations with a random right-hand-side. These equations can be solved efficiently, so that the additional cost of our approach, compared to traditional 4D-Var, is small.The long-term goal is to assimilate experimental data, obtained with the CORIOLIS turntable in Grenoble (France), to study the drift of a vortex. We present results from numerical twin experiments as a first step towards our long-term goal. We discretize the shallow water equations on a square domain ($2.5\mbox{m}\times 2.5\mbox{m}$) using finite differences on a staggered grid of size $2^8\times 2^8$ and a fourth order Runge-Kutta. We assume open boundary conditions and estimate the initial state (velocities and surface height) given noisy observations of the state. We solve the optimization problem using a 4D-Var code that relies on a L-BFGS method; the random algebraic equations are solved with random maps, i.e. we look for solutions in given, but random, directions of the state space.In our numerical experiments, we varied the availability of the data (in both space and time) as well as the variance of the observation noise. We found that the implicit particle filter is reliable and efficient in all scenarios we considered. The implicit sampling method could improve the accuracy of the traditional variational approach. Moreover, we obtain quantitative measures of the uncertainty of the state estimate ``for free,'' while no information about the uncertainty is easily available using the traditional 4D-Var method only.\n","7"
"NG43A. Particle Filters for Nonlinear Data Assimilation II Posters","NG43A","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Space Science Informatics (IN)Ocean Sciences (OS)","VARIATIONAL PARTICLE FILTER FOR IMPERFECT MODELS","NG43A-1573","1:40 PM","1:40 PM","C.   Baehr*","C.   Baehr*","Météo-France; Université Toulouse III","withdrawn","","8"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Nonlinear Eddy-Eddy Interactions in Dry Atmospheres Macroturbulence","NG43B-1574","1:40 PM","1:40 PM","F.   Ait Chaalal*","F.   Ait Chaalal*; T.   Schneider","California Institute of Technology","Sessioned","Body: The statistical moment equations derived from the atmospheric equation of motions are not closed. However neglecting the large-scale eddy-eddy nonlinear interactions in an idealized dry general circulation model (GCM), which is equivalent to truncating the moment equations at the second order, can reproduce some of the features of the general circulation ([1]), highlighting the significance of eddy-mean flow interactions and the weakness of eddy-eddy interactions in atmospheric macroturbulence ([2]). The goal of the present study is to provide new insight into the rôle of these eddy-eddy interactions and discuss the relevance of a simple stochastic parametrization to represent them. We investigate in detail the general circulation in an idealized dry GCM, comparing full simulations with simulations where the eddy-eddy interactions are removed. The radiative processes are parametrized through Newtonian relaxation toward a radiative-equilibrium state with a prescribed equator to pole temperature contrast. A convection scheme relaxing toward a prescribed convective vertical lapse rate mimics some aspects of moist convection. The study is performed over a wide range of parameters covering the planetary rotation rate, the equator to pole temperature contrast and the vertical lapse rate. Particular attention is given to the wave-mean flow interactions and to the spectral budget. It is found that the no eddy-eddy simulations perform well when the baroclinic activity is weaker, for example for lower equator to pole temperature contrasts or higher rotation rates: the mean meridional circulation is well reproduced, with realistic eddy-driven jets and energy-containing eddy length scales of the order of the Rossby deformation radius. For a stronger baroclinic activity the no eddy-eddy model does not achieve a realistic isotropization of the eddies, the meridional circulation is compressed in the meridional direction and secondary eddy-driven jets emerge. In addition, the baroclinic wave activity does not reach the upper troposphere in association with a very weak or absent Rossby wave absorption in the upper subtropical troposphere. Understanding these deficiencies and the rôle of the eddy-eddy nonlinear interactions in determining the mean meridional circulation paves the way to the development of stochastic third order moments parametrizations, to eventually build GCMs that directly solve for the flow statistics and that could provide a deeper understanding of anthropogenic and natural climate changes.  [1] O’Gorman, P. A., & Schneider, T. 2007, Geophysical Research Letters, 34, 22801[2] Schneider, T., and C. C. Walker, 2006, Journal of the Atmospheric Sciences, 63, 1569-1586.\n","1"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Multi-level Dynamical Systems: Connecting the Ruelle Response Theory and the Mori-Zwanzig Approach","NG43B-1575","1:40 PM","1:40 PM","J.   Wouters*","J.   Wouters*; V.   Lucarini","KlimaCampus Hamburg","Sessioned","Body: In this paper we consider the problem of disentangling multi-level systems by connecting the seemingly unrelated approaches of the Mori-Zwanzig projection operator technique and of the Ruelle response theory, for which we propose a new derivation. In a previous paper we have shown that by using the Ruelle response theory it is possible to construct a surrogate dynamics for the slow variables only such that the expectation value of any observable agrees, up to second order, to its expectation evaluated on the full dynamics, where both slow and fast variables are involved. We prove here, using a Dyson expansion, that such surrogate dynamics agree up to second order to the effective dynamics one can derive by expanding perturbatively the Mori-Zwanzing projection operator, which creates, instead, an accurate representation of the trajectories of the slow variables. In the case of e.g. geophysical fluid dynamics, this implies that the parametrizations of unresolved processes suited for prediction (numerical weather forecast) and those suited for the representation of long term statistical properties (climate) are closely related, if one takes into account, in addition to the widely adopted stochastic forcing, the usually neglected memory effects. This bears relevance for the current trend of aiming at seamless prediction.\n","2"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Data-Driven Model Reduction and Climate Prediction: Nonlinear Stochastic, Energy-Conserving Models With Memory Effects","NG43B-1576","1:40 PM","1:40 PM","D. A.  Kondrashov*","D. A.  Kondrashov*; M. D.  Chekroun; M.   Ghil","University of California, Los Angeles","Sessioned","Body: Comprehensive dynamical climate models aim to simulate past, present and future climate; more recently, they also attempt to predict climate on longer and longer time scales. These models, commonly known as general circulation models or global climate models (GCMs) represent a broad range of time and space scales and use a state vector that has many millions of degrees of freedom. Considerable work, both theoretical and data-based, has shown that much of the observed climate variability can be represented with a substantially smaller number of degrees of freedom.While detailed weather prediction out to a few days requires high numerical resolution, it is fairly clear that a major fraction of climate variance can be predicted in a much lower-dimensional phase space. Low-dimensional models (LDMs) can simulate and predict this fraction of variability, provided they are able to account for (i) linear and nonlinear interactions between the resolved high-variance climate components; and (ii) the interactions between the small number resolved components and the daunting number of unresolved ones.Here we will present applications of a particular data-driven LDM approach, namely an energy-conserving formulation of empirical model reduction (EMR). As an operational methodology, EMR constructs a low-order nonlinear system of prognostic equations driven by stochastic forcing; it estimates both the dynamical operator and the properties of the driving noise directly from observations or from a high-order model's simulation. The multi-level EMR structure for modeling the stochastic forcing allows one to capture feedback between high- and low-frequency components of the variability, thus parameterizing the fast scales, often referred to as the noise, in terms of the memory of the slow scales, referred to as the signal.In real-time ENSO prediction, EMR already proved to be highly competitive among state-of-the art dynamical and statistical models. New opportunities for EMR prediction will be illustrated in the framework of Past Noise Forecasting, by utilizing on the one hand the EMR-estimated history of the driving noise, and on the other hand the phase of low-frequency variability estimated by advanced time series analysis.\nURL: http://www.atmos.ucla.edu/tcd\n","3"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Selection of optimal complexity for ENSO-EMR model by minimum description length principle","NG43B-1577","1:40 PM","1:40 PM","E. M.  Loskutov*","E. M.  Loskutov*; D.   Mukhin; A.   Mukhina; A.   Gavrilov; D. A.  Kondrashov; A. M.  Feigin","Institute of Applied Physics; UCLA","Sessioned","Body: One of the main problems arising in modeling of data taken from natural system is finding a phase space suitable for construction of the evolution operator model. Since we usually deal with strongly high-dimensional behavior, we are forced to construct a model working in some projection of system phase space corresponding to time scales of interest. Selection of optimal projection is non-trivial problem since there are many ways to reconstruct phase variables from given time series, especially in the case of a spatio-temporal data field. Actually, finding optimal projection is significant part of model selection, because, on the one hand, the transformation of data to some phase variables vector can be considered as a required component of the model. On the other hand, such an optimization of a phase space makes sense only in relation to the parametrization of the model we use, i.e. representation of evolution operator, so we should find an optimal structure of the model together with phase variables vector.In this paper we propose to use principle of minimal description length (Molkov et al., 2009) for selection models of optimal complexity. The proposed method is applied to optimization of Empirical Model Reduction (EMR) of ENSO phenomenon (Kravtsov et al. 2005, Kondrashov et. al., 2005). This model operates within a subset of leading EOFs constructed from spatio-temporal field of SST in Equatorial Pacific, and has a form of multi-level stochastic differential equations (SDE) with polynomial parameterization of the right-hand side. Optimal values for both the number of EOF, the order of polynomial and number of levels are estimated from the Equatorial Pacific SST dataset.References:Ya. Molkov, D. Mukhin, E. Loskutov, G. Fidelin and A. Feigin, Using the minimum description length principle for global reconstruction of dynamic systems from noisy time series, Phys. Rev. E, Vol. 80, P 046207, 2009Kravtsov S, Kondrashov D, Ghil M, 2005: Multilevel regression modeling of nonlinear processes: Derivation and applications to climatic variability. J. Climate, 18 (21): 4404-4424.D. Kondrashov, S. Kravtsov, A. W. Robertson and M. Ghil, 2005. A hierarchy of data-based ENSO models. J. Climate, 18, 4425–4444.\n","4"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Diffusive evolution of experimental braided rivers","NG43B-1578","1:40 PM","1:40 PM","M. D.  Reitz*","M. D.  Reitz*; E.   Lajeunesse; D. J.  Jerolmack; A.   Limare; F.   Metivier; O.   Devauchelle","Lamont-Doherty Earth Observatory, Columbia University; Institut de Physique du Globe de Paris; University of Pennsylvania","Sessioned","Body: Braided rivers are complex systems in which a network of ephemeral, interacting channels continually migrate to create a rapidly changing landscape, with activity on a range of scales from channel to network organization. A previously proposed formulation in the literature has described the macroscopic behavior of braided rivers with a relationship between sediment flux and system slope that has the form of diffusion. This deterministic relationship has yet to be shown to be a true expression of stastistical diffusion on the macroscopic scale that results from stochastic behavior at the unit scale. We present results of a set of ~1m-scale experiments of braided rivers forming over a bed of monodisperse glass beads, designed to quantify both the characteristics of individual channels and the statistics of the system, and to test the extent to which statistical diffusion is applicable to braided rivers. Our data consist of repeat high-resolution topography scans, which provide data on both topographic relief and water depth values. The experiments evolve from an initial flat bed, allowing us to study the approach of the system to a steady state. We find that, although channels migrate rapidly, they have stable, self-similar geometries organized to a critical Shields stress criterion, which suggests that the timescale of channel geometry organization is small compared to dynamic channel timescales. Analysis of the channel network through time shows a decorrelation that is random and memoryless, and which occurs over time and space scales that yield a diffusivity estimate consistent with the deterministic theoretical prediction. Further investigation shows that many aspects of the system dynamics can be directly described with this diffusional framework. The timescale to equilibrium slope and topographic steady state, the rate at which correlation lengthscales increase through time, and the dependence of the equilibrium slope on sediment flux can all be described with diffusivities that are consistent with the theoretical prediction. Additionally, we demonstrate that the rate at which channels move to cover the landscape is both analytically soluble and the same as the rate at which the slope is adjusted to its equilibrium value, thus providing a mechanism and rate for the diffusive signal propagation between the unit and system scales. The emergent picture of our braided river system is one in which sediment transport drives the interaction of dynamic but equilibrium channels, which in turn act as the elements of randomness that effect diffusive behavior at the system scale.\n","5"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","ANN-based empirical modeling of SST variability in Equatorial Pacific region ","NG43B-1579","1:40 PM","1:40 PM","D.   Mukhin*","D.   Mukhin*; A.   Mukhina; A.   Gavrilov; E. M.  Loskutov","Istitute of Applied Physics","Sessioned","Body: The new method for empirical modeling of SST dynamics in Equatorial Pacific region is suggested. The model is based on artificial neural network (ANN) parameterization and has a form of discrete stochastic evolution operator mapping some sequence of system’s state on the next one.  It operates in space of principal spatial EOFs constructed from SST field. The most important point of the method is finding the optimal structural parameters of the model such as dimension of variables vector, i.e. number of principal EOFs used for modeling, number of states used for prediction, and number of neurons determining quality of approximation. Actually, we need to solve the model selection problem, i.e. we want to obtain a model of optimal complexity in relation to analyzed time series.  We use MDL approach for this purpose: the model providing most data compression is chosen. The method is applied to time series of SST fields taken from INMCM4.0 climate model as well as from IRI datasets.\n","6"
"NG43B. Stochasticity, Multiplicity of Scales, Memory, and Statistical Mechanics in Geophysics II Posters","NG43B","Poster","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","6:00 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Hydrology (H)Natural Hazards (NH)Ocean Sciences (OS)","Rough parameter dependence in geophysical fluid models: The role of Ruelle-Pollicott resonances","NG43B-1580","1:40 PM","1:40 PM","M. D.  Chekroun*","M. D.  Chekroun*; J.   Neelin; D. A.  Kondrashov; J. C.  McWilliams; M.   Ghil","UCLA; University of Hawaii","Sessioned","Body: There is a rapidly growing interest in understanding and quantifying the uncertainties observed in climate simulations with general circulation models (GCMs). Various approaches have been proposed for uncertainty quantification (UQ), but thefundamental mechanisms at the origin of sensitive behavior of model statistics remain unclear.At the same time, observations have demonstrated that the variability of turbulent flows in the atmosphere, oceans and climate in general exhibits recurrent large-scale patterns. These patterns, while evolving irregularly in time, manifest characteristic dominant frequencies across a large range of time scales, from intraseasonal through seasonal-to-interannual and up to interdecadal.Based on the modern spectral theory of dissipative and chaotic dynamical systems, we will show in this talk how the associated low-frequency variability (LFV) may be formulated in terms of Ruelle-Pollicott (RP) resonances. Our main result is that the spectral gap between the dominant RP-resonance and the rest of them plays a major role in the roughness of theparameter dependence observed for several model statistics and for a fixed but arbitrary observable. This result will be illustrated by using an intermediate-complexity, El-Nino--Southern Oscillation model.The model statistics are most sensitive for the smallest spectral gaps; such small gaps turn out to correspond to regimes where the LFV is more pronounced, while auto-correlations decay more slowly. Theoretical arguments strongly suggest thatsuch links between model sensitivity and the role of LFV in the model's behavior are not limited to the particular model analyzed here and could hold much more generally.\n","7"
"NG43C.* Statistical Geodynamics I","NG43C","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","2:25 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Horton and Tokunaga self-similarity in basic models of branching, aggregation, time series <i>(Invited)</i>","NG43C-01","1:40 PM","1:55 PM","I.   Zaliapin*","I.   Zaliapin*; Y.   Kovchegov","University of Nevada, Reno; Oregon State University","Sessioned","Body: Hierarchical branching structures are readily seen in river and drainage networks, lightening, botanical trees, vein structure of leaves, snowflakes, and bronchial passages, to mention but a few. Empirical evidence reveals a surprising similarity among natural hierarchies of diverse origin; many of them are closely approximated by so-called self-similar trees (SSTs). A two-parametric subclass of Tokunaga SSTs plays a special role in theory and applications, as it has been shown to emerge in unprecedented variety of modeled and natural phenomena. The Tokunaga SSTs with a broad range of parameters are seen in studies of river networks, aftershock sequences, vein structure of botanical leaves, numerical analyses of diffusion limited aggregation, two dimensional site percolation, and nearest-neighbor clustering in Euclidean spaces. The omnipresence of Tokunaga self-similarity hints at the existence of universal underlying mechanisms responsible for its appearance and prompts the question: What basic probability models may generate Tokunaga self-similar trees? This paper reviews the existing results on Tokunaga self-similarity of the critical binary Galton-Watson process, also known as Shreve’s random topology model or equiprobable binary tree model. We then present new analytic results that establish Horton and Tokunaga self-similarity in (i) level-set tree representation of white noise, (ii) level-set tree representation of random walk and Brownian motion, and (iii) Kingman’s coalescent process. We also formulate a conjecture, based on extensive numerical experiments, about Tokunaga self-similarity for the (iv) additive and (v) multiplicative coalescents as well as (vi) fractional Brownian motion. The listed processes are among the essential building blocks in natural and computer sciences modeling. Accordingly, the results of this study may provide at least a partial explanation for the presence of Horton and Tokunaga self-similarity in observed and modeled branching structures. Our results also reveal interesting topological equivalence classes for coalescent processes and time series. \n","1"
"NG43C.* Statistical Geodynamics I","NG43C","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","2:25 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Virtual California: studying earthquakes through simulation","NG43C-02","1:55 PM","2:10 PM","M. K.  Sachs*","M. K.  Sachs*; E. M.  Heien; D. L.  Turcotte; M. B.  Yikilmaz; J. B.  Rundle; L. H.  Kellogg","University of California Davis; University of California Davis","Sessioned","Body: Virtual California is a computer simulator that models earthquake fault systems. The design of Virtual California allows for fast execution so many thousands of events can be generated over very long simulated time periods. The result is a rich dataset, including simulated earthquake catalogs, which can be used to study the statistical properties of the seismicity on the modeled fault systems. We describe the details of Virtual California's operation and discuss recent results from Virtual California simulations.\n","2"
"NG43C.* Statistical Geodynamics I","NG43C","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","1:40 PM","2:25 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Web-Based Real Time Earthquake Forecasting and Personal Risk Management","NG43C-03","2:10 PM","2:25 PM","J. B.  Rundle*","J. B.  Rundle*; J. R.  Holliday; W. R.  Graves; D. L.  Turcotte; A.   Donnellan","University of California; University of California; Jet Propulsion Lab; Open Hazards group","Sessioned","Body: Earthquake forecasts have been computed by a variety of countries and economies world-wide for over two decades. For the most part, forecasts have been computed for insurance, reinsurance and underwriters of catastrophe bonds.  One example is the Working Group on California Earthquake Probabilities that has been responsible for the official California earthquake forecast since 1988.   However, in a time of increasingly severe global financial constraints, we are now moving inexorably towards personal risk management, wherein mitigating risk is becoming the responsibility of individual members of the public.  Under these circumstances, open access to a variety of web-based tools, utilities and information is a necessity.  Here we describe a web-based system that has been operational since 2009 at www.openhazards.com and www.quakesim.org.  Models for earthquake physics and forecasting require input data, along with model parameters.  The models we consider are the Natural Time Weibull (NTW) model for regional earthquake forecasting, together with models for activation and quiescence.  These models use small earthquakes (‘seismicity-based models”) to forecast the occurrence of large earthquakes, either through varying rates of small earthquake activity, or via an accumulation of this activity over time. These approaches use data-mining algorithms combined with the ANSS earthquake catalog. The basic idea is to compute large earthquake probabilities using the number of small earthquakes that have occurred in a region since the last large earthquake.  Each of these approaches has computational challenges associated with computing forecast information in real time.  Using 25 years of data from the ANSS California-Nevada catalog of earthquakes, we show that real-time forecasting is possible at a grid scale of 0.1o.  We have analyzed the performance of these models using Reliability/Attributes and standard Receiver Operating Characteristic (ROC) tests. We show how the Reliability and ROC tests allow us to judge data completeness and estimate error.  It is clear from much of the analysis that data quality is a major limitation on the accurate computation of earthquake probabilities. We discuss the challenges and pitfalls in serving up these datasets over the web.\nURL: www.openhazards.com, www.quakesim.org\n","3"
"NG43D. The Fluid Dynamics of Planets and Stars I","NG43D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","2:25 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","An Overview of Disk Weather, by Hubert Klahr",,"2:25 PM","2:40 PM",,,,,,"1"
"NG43D. The Fluid Dynamics of Planets and Stars I","NG43D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","2:25 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Vortices and flux tubes: The crossover <i>(Invited)</i>","NG43D-02","2:40 PM","2:55 PM","A.   Bracco*","A.   Bracco*; E. A.  Spiegel","Georgia Tech; Columbia University","Sessioned","Body: The sun has magnetic flux tubes that cause sunspots by locally inhibiting convection near its surface. Jupiter has vortices that make the great red spot and other such blemishes. Why are there no similar vortices on the sun? How is the difference in the two kinds of system controlled by the magnetic Prandtl number?  What happens at the crossover between the two behaviors? The transition between velocity and magnetically dominated regimes is the driving question of this work. It should occur somewhere in the enormous range in Prandtl number between the sun and planets like Jupiter. Objects that lie in between these vastly different extremes are Brown Dwarfs that have such low mass that they do not burn hydrogen in their cores. These objects are now being actively observed though there is as yet no direct evidence bearing on the present calculations. Other possibly interesting conditions may arise in certain disks around newborn stars where planetary systems are thought to be forming. These may be cool enough to place them in an interesting parameter range for the competition we describe.Using 2D calculations, we seek a quantitative measure of the relative importance of the two vector fields seen in the calculations, statistical or spectral, topological or structural. \n","2"
"NG43D. The Fluid Dynamics of Planets and Stars I","NG43D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","2:25 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","A Three-dimensional Model for Quasi-geostrophic Convection in a Rotating Cylindrical Annulus with Steeply Sloping Endwalls <i>(Invited)</i>","NG43D-03","2:55 PM","3:10 PM","M. A.  Calkins*","M. A.  Calkins*; P.   Marti; K. A.  Julien","University of Colorado, Boulder","Sessioned","Body: The rotating cylindrical annulus with sloping endwalls has served as a useful analogue for understanding convection in planetary cores and deep atmospheres since it was first developed by Busse.  The primary, though often ignored, limitation of the original model is that it is valid only for boundaries with asymptotically small slopes.  We present a three-dimensional model of the rotating cylindrical annulus that maintains geostrophic balance at leading order and is valid for endwalls with steep (i.e.~order one) slopes.  This extension allows for better comparison to the more realistic case of rapidly rotating spheres and spherical shells where strongly sloping boundaries are present.  A linear stability analysis shows that as the slope becomes steeper the most unstable eigenmode is typified by increased axial variation.  Furthermore, it is shown that very small increases in the buoyancy forcing lead to eigenmodes with complex axial structure, suggesting that such modes will be excited in strongly forced (i.e.~nonlinear) quasi-geostrophic convection. We discuss the ramifications of these findings for understanding convection in geophysical and astrophysical settings.\n","3"
"NG43D. The Fluid Dynamics of Planets and Stars I","NG43D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","2:25 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Rapid energy exchange between inertia-gravity waves and mesoscale eddies at fronts. <i>(Invited)</i>","NG43D-04","3:10 PM","3:25 PM","L. N.  Thomas*","L. N.  Thomas*","Stanford University","Sessioned","Body: Inertia-gravity waves, mesoscale eddies, and lateral density gradients (or fronts) are ubiquitous on rapidly rotating planets.  Classical theory predicts that the interaction between the fast, unbalanced waves and the slow, balanced eddies should be weak. A new theory demonstrates, however, that this interaction can be strong in regions of frontogenesis, where mesoscale strain intensifies lateral density gradients. Such frontogenetic strain leads to an exponentially fast increase in the vertical shear of the along-front geostrophic flow and a concomitant cross-front ageostrophic circulation that is vertically-sheared as well.  These changes in geostrophic flow modify the polarization relation of inertia-gravity waves that are present, making their horizontal velocity rectilinear and resulting in a Reynolds stress that draws energy from the eddies. The process is most effective for waves of low frequency and for a geostrophic flow with low Richardson number. Nonetheless, even in a background flow that is initially strongly stratified, frontogenesis leads to an exponentially fast reduction in the Richardson number, facilitating a rapid energy extraction by the waves. The kinetic energy transferred from eddies is ultimately lost to the unbalanced ageostrophic circulation through shear production and hence the inertia-gravity waves play a catalytic role in loss-of-balance. In the oceans on our planet, a large fraction of the kinetic energy is contained in low-frequency inertia-gravity waves and fronts are widespread. Therefore, this mechanism could play a significant role in the removal of kinetic energy from both the internal wave and mesoscale eddy fields.\nURL : http://pangea.stanford.edu/~leift/\n","4"
"NG43D. The Fluid Dynamics of Planets and Stars I","NG43D","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","2:25 PM","3:40 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Precessionally driven flow in an oblate spheroidal cavity of arbitrary eccentricity","NG43D-05","3:25 PM","3:40 PM","K.   Zhang*","K.   Zhang*; K.   Chan; X.   Liao","University of Exeter; University of Hong Kong; SHAO","Sessioned","Body: In the early stage of the Earth's evolution,the Earth was rotating much faster and, consequently,its liquid core wasmore flattening in the shape of an oblate spheroid with  a larger eccentricity.The Earth' mantle and its fluid core would be coupled via both topographical and viscous effects.We investigate,  through  both asymptotic and numerical analysis,precessionally driven flow of a homogeneous fluid confined in an oblatespheroidal cavity of  arbitrary eccentricity.The precessionally driven flow is primarily characterized by three dimensionless parameters:the shape parameter (eccentricity), the Ekman number and the Poincar\'{e} number.We derive a time-dependent asymptotic solution in the mantle frame of referencesatisfying the non-slip boundary condition in a spheroidal cavity of arbitrary eccentricity.No prior assumptionabout the spatial-temporal structure of the time-dependent precessing flow is made in the asymptotic analysis.Direct numerical simulation in the same frame of reference,using an EBE (Element-By-Element)finite element method suitable for non-spherical geometry, is also carried out,showing a satisfactory agreement between the asymptoticsolution and the nonlinear numerical simulationfor sufficiently small Ekman and Poincar\'{e} numbers.A large number of nonlinear direct  numerical simulations over the three-parameter spaceare performed to reveal a variety of different nonlinear  phenomenaof the precessionally driven flow.\n","5"
"NG44A.* Stochastic Parameterizations in Numerical Weather and Climate Models I","NG44A","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Systematic Error Model Error: The Impact of Increased Horizontal Resolution versus Improved Stochastic and Deterministic Parameterizations <i>(Invited)</i>","NG44A-01","4:00 PM","4:15 PM","J.   Berner*","J.   Berner*; T.   Jung; T.   Palmer","NCAR; AWI; University of Oxford","Sessioned","Body: Long-standing systematic model errors in both tropics and extra-tropics of the ECMWF model run at a horizontal resolution typical for climate models are investigated. Based on the hypothesis that the misrepresentation of unresolved scales contributes to the systematic model error, three model refinements that attempt their representation — fluctuating or deterministically — are investigated.Increasing horizontal resolution to explicitly simulate smaller-scale features, representing subgrid-scale fluctuations by a stochastic parameterization and improving the deterministic physics-parameterizations all lead to a decrease in the systematic bias of the Northern Hemispheric circulation. These refinements reduce the overly zonal flow and improve the model’s ability to capture the frequency of blocking. However, the model refinements differ greatly in their impact in the tropics: While improving the deterministic and introducing stochastic parameterizations reduces the systematic precipitation bias and improves the characteristics of convectively-coupled waves and tropical variability in general, increasing horizontal resolution has little impact.The fact that different model refinements can lead to reductions in systematic model error is consistent with our hypothesis that unresolved scales play an important role. At the same instance our findings warrant a cautionary note: if a model refinement leads to an improvement, it is important to make sure that the model error was reduced for the right dynamical reasons. We postulate that if stochastic parameterization should be an important element of next generation climate models, stochasticity should be incorporated within the design of physical model parameterizations and advancements in the dynamical core development and not added a posteriori.\nURL : http://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-11-00297.1\n","1"
"NG44A.* Stochastic Parameterizations in Numerical Weather and Climate Models I","NG44A","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Climatic impacts of a stochastic parameterization of air–sea fluxes <i>(Invited)</i>","NG44A-02","4:15 PM","4:30 PM","P. D.  Williams*","P. D.  Williams*","University of Reading","Sessioned","Body: The atmosphere and ocean are coupled by the exchange of fluxes across the ocean surface.  Air–sea fluxes vary partly on scales that are too small and fast to be resolved explicitly in numerical models of weather and climate, making them a candidate for stochastic parameterization.  This presentation proposes a nonlinear physical mechanism by which stochastic fluctuations in the air–sea buoyancy flux may modify the mean climate, even though the mean fluctuation is zero.  The mechanism relies on a fundamental asymmetry in the physics of the ocean mixed layer: positive surface buoyancy fluctuations cannot undo the vertical mixing caused by negative fluctuations.  The mechanism has much in common with Stommel's mixed-layer demon.  The presentation demonstrates the mechanism in climate simulations with a comprehensive coupled atmosphere–ocean general circulation model (SINTEX-G).In the SINTEX-G simulations with stochastic air–sea buoyancy fluxes, significant changes are detected in the time-mean oceanic mixed-layer depth, sea-surface temperature, atmospheric Hadley circulation, and net upward water flux at the sea surface.  Also, El Niño Southern Oscillation (ENSO) variability is significantly increased.  The findings demonstrate that noise-induced drift and noise-enhanced variability, which are familiar concepts from simple climate models, continue to apply in comprehensive climate models with millions of degrees of freedom.  The findings also suggest that the lack of representation of sub-grid variability in air–sea fluxes may contribute to some of the biases exhibited by contemporary climate models.Reference:  Williams, PD (2012) Climatic impacts of stochastic fluctuations in air–sea fluxes.  Geophysical Research Letters, vol 39, L10705, DOI: 10.1029/2012GL051813.\nURL : http://dx.doi.org/10.1029/2012GL051813\n","2"
"NG44A.* Stochastic Parameterizations in Numerical Weather and Climate Models I","NG44A","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:00 PM","4:45 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","A stochastic parametrization scheme for deep convection and its scale adaptivity","NG44A-03","4:30 PM","4:45 PM","R. J.  Keane*","R. J.  Keane*; G. C.  Craig; C.   Keil; G.   Zängl","Meteorologisches Institut der Universität München; Deutscher Wetterdienst","Sessioned","Body: Stochastic parametrization of deep convection is an important technique in geophysical modeling, since many NWP and regional climate models have grid lengths of the order of tens of kilometers, where deep convection is not resolved explicitly, but where the grid boxes are not large enough that an ensemble-mean convective response to a given resolved forcing can be assumed. A stochastic parametrization for deep convection, where individual clouds are randomly selected from a probability distribution derived from a statistical-mechanics-based treatment of the variability in the grid-box, will be presented.Having outlined the details of the scheme itself, its behaviour over different scales and in response to different grid lengths will be shown. Neglecting any new resolved processes that are introduced (which should be acceptable for deep convection over scales of the order of tens of kilometers), a scheme should ideally be “scale independent”, in the sense that extra variability is introduced appropriately as the grid length is reduced. Conventional (i.e. not stochastic) convection schemes are unable to do this by design, since they assume a fixed response to a given grid-scale forcing, regardless of how few clouds are present inside the grid box. However, such scale independence is important in geophysical modeling, particularly when more than one grid length is used in the same model. It is therefore of great interest to investigate how far a stochastic scheme can enhance this scale independence over conventional schemes, and this will form the focus of this presentation.\n","3"
"NG44B. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis I","NG44B","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Lagrangian descriptors and their applications to oceanic and atmospheric flows <i>(Invited)</i>","NG44B-01","4:45 PM","5:00 PM","A. M.  Mancho*","A. M.  Mancho*","CSIC","Sessioned","Body: Geometry has been a very useful approach for studying dynamical systems. At the basis are Poincare ideas of seeking structures on the phase space that divide it into regions corresponding to trajectories with different dynamical fates. These ideas have demonstrated to be very powerful for the description of transport in purely advective flows and important applications have been found in geophysics. This presentation explores the performance of new Lagrangian tools, so called, Lagrangian descriptors [1,2,3], which are based on the integration along trajectories of bounded positive scalars which express an intrinsic geometrical or physical property of the trajectory.  We analyze the convenience of different descriptors from several points of view and compare outputs with other methods proposed in the literature. We discuss applications of these new tools on oceanic datasets taken from altimeter satellites on the Kuroshio region, and on reanalysis data on the Antarctic polar vortex [4,5,6].This research has been supported by MINECO under grants MTM2011-26696 and ICMAT Severo Ochoa project SEV-2011-0087 and CSIC under grant ILINK-0145. Computational support from CESGA and CCC-UAM is acknowledged.[1] J. A. J. Madrid, A. M. Mancho. Distinguished trajectories in time dependent vector fields. Chaos 19 (2009), 013111-1-013111-18.[2] C. Mendoza, A. M. Mancho. The hidden geometry of ocean flows. Physical Review Letters 105 (2010), 3, 038501-1-038501-4. [3], A. M. Mancho, S. Wiggins, J. Curbelo, C. Mendoza. In preparation.[4] A. de la Cámara, A. M. Mancho, K. Ide, E. Serrano, C.R. Mechoso. Routes of transport  across the Antarctic polar vortex in the southern spring. Journal of Atmospheric Sciences 69, 2 (2012).[5] C. Mendoza, A. M. Mancho, M. H. Rio. The turnstile mechanism across the Kuroshio current: analysis of dynamics in altimeter velocity fields. Nonlinear Proc. Geoph 17 (2010), 2, 103-111.[6] Carolina Mendoza, Ana M. Mancho. The Lagrangian description of aperiodic flows: a case study of the Kuroshio Current.  Nonlinear Processes in Geophysics (2012) arxiv:1006.3496\n","1"
"NG44B. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis I","NG44B","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Transport Barriers in 3D Ekman-driven Circulations <i>(Invited)</i>","NG44B-02","5:00 PM","5:15 PM","L. J.  Pratt*","L. J.  Pratt*; I. I.  Rypina; T. M.  Ozgokmen; Y.   Bebieva","WHOI; University of Miami; Utrecht University","Sessioned","Body: As a model of an idealized ocean eddy with a horizontal swirling circulation plus overturning we consider flow in a rotating cylinder, driven by an imposed surface stress and Ekman layers at the surface.  We use a fully nonlinear numerical model to obtain velocity fields that are either steady or time periodic.  Chaotic advection occurs when a radially symmetric state is perturbed and this leads to a fascinating collection of barriers and chaotic regions in 3D. Stirring and mixing in these flows is thus very patchy.  Different regimes are mapped out over the parameter ranges of Ekman and Rossby numbers (E and Ro) that are appropriate for mesoscale and sub-mesoscale eddies.  For shallow eddies E is O(1), transport barriers are robust, and chaotic mixing and transport is very limited.  Deep eddies experience weaker barriers. We use a version of the KAM theorem along with a new expression for width of resonant layers to interpret the results.\n","2"
"NG44B. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis I","NG44B","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Short-term Dispersal of Fukushima-derived Radionuclides off Japan: Modeling Efforts and Model-data Inter-comparison","NG44B-03","5:15 PM","5:30 PM","I. I.  Rypina*","I. I.  Rypina*; S. R.  Jayne; S.   Yoshida; A. M.  Macdonald; E.   Douglass; K.   Buesseler","WHOI; Naval Research Laboratory","Sessioned","Body: As a result of the Tohoku earthquake and tsunami on March 11, 2011, the Fukushima nuclear power plants were damaged and radioactive isotopes were released to the atmosphere and into the ocean. In order to assess the levels of contamination, a field study was conducted on June 4-18 that focused on measuring radionuclide isotopes including Cs-137 in surface and subsurface waters and biota off Japan coast. To interpret these field measurements, we carried out numerical simulations of the short-term spreading of the Fukushima-derived radionuclides. The results are used to investigate the dominant mechanisms governing the short-term spread of radiation within the North Pacific, and to place the measured radioactive isotope concentrations in the context of the physical oceanographic circulation.\n","3"
"NG44B. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis I","NG44B","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Transport across the Tropical Tropopause Layer <i>(Invited)</i>","NG44B-04","5:30 PM","5:45 PM","B.   Legras*","B.   Legras*","Ecole Normale Supérieure ","Sessioned","Body: Among the regions of the atmosphere most sensitive to transport, the Tropical Tropopause Layer (TTL) is also one where the transport issues ar less well understood in spite of a number of recently made progresses. We will present the main results about transport across the TTL, using data from state of the art reanalysis, and their implications on TTL and lower tropical stratosphere composition. We will also discuss the current limitations due to inaccuracies in the observations and in the modelling. In particular, we will discuss 1) the transit between convective detrainment and the top of the TTL, 2) the role of the zero heating boundary in setting the properties of this transit and 3) the horizontal  transport barriers on the edges and within the TTL.\nURL : htpp://www.lmd.ens.fr/legras\n","4"
"NG44B. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis I","NG44B","Oral","Nonlinear Geophysics (NG)","06-Dec-2012","4:45 PM","6:00 PM","300 (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Diagnosing transport barriers in atmosphere and ocean <i>(Invited)</i>","NG44B-05","5:45 PM","6:00 PM","P.   Haynes*","P.   Haynes*","University of Cambridge","Sessioned","Body: Many atmospheric and oceanic flows naturally divide into mixing regions separated by transport barriers. Identifying these structures and quantifying rates of transport from one mixing region to another is important in order to assess differences between observed and modelled flows and to capture geographical and time variations. The description of the stratospheric polar vortex as a vortex-edge barrier separating two mixing regions -- the 'surf zone' and the interior of the vortex -- was a first important step, but this is a relatively simply case, with a continuous and strong barrier. Other flows of interest, such as the subtropical jet acting as a potential transport barrier between tropical upper troposphere and midlatitude lowermost stratosphere, and the Antarctic Circumpolar Current (ACC), are more challenging to quantify. Complications include strong vertical variation, seasonal variation and strong variations in the streamwise direction. Methods available for quantifying transport and mixing, which have been applied to many of the above flows include particle-based methods, such as calculation of Lagrangian dispersion and stretching rates, and tracer-based methods, such as effective diffusivity and tracer histograms. This talk will discuss some of the advantages and disadvantages of these methods, particularly for more complicated flows with strong streamwise variation. \n","5"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","The large deviation function and recurrent properties of large earthquakes in two-dimensional forest-fire models","NG51A-1761","8:00 AM","8:00 AM","T.   Mitsudo*","T.   Mitsudo*; N.   Kato","Eathquake Research Institute","Sessioned","Body: Time- or slip- predictable model for recurrence of large earthquakes assumes constant critical or residual stress, respectively. However, it has not been confirmed that the assumption of constant critical or residual stress is adequate. It is important to study the effect of the fluctuation of initial and final stress to elucidate the recurrence of large earthquakes. When we see earthquake sequence as a point process, the slip-predictable model corresponds to a renewal process and the fluctuation of residual stress can cause non-renewal properties of earthquake sequence. We conduct numerical simulations of earthquake recurrence by the use of two-dimensional forest-fire models. The idea of relating a cluster which appear in the forest-fire model to the size of an earthquake is after the work of Otsuka(ZISIN,Ser.II,29 137 (1976)). To study the effect of the fluctuation of the residual stress, we investigate two kinds of percolated earthquakes. One is a percolated earthquake that releases all stress in the system and is called a renewal earthquake. The other is a usual percolated earthquake where some stress is left on the model fault after the earthquake and is called a non-renewal earthquake. The model that contains renewal earthquakes corresponds to the renewal process and is called model R. The model that contains non-renewal earthquakes exhibits temporal fluctuation of the residual stress in the system, and is called model N. In the size-frequency distribution of simulated earthquakes, there is a sag of frequency between the percolated earthquakes and the other earthquakes in model R. In contrast, there is no sag in model N. We calculate the mean frequencies of the percolated earthquakes and their large deviation functions to compare the results between the two different percolated earthquakes. The large deviation function characterizes the probability of rare events which are far from the true mean. The large deviation function for the frequency of the percolated earthquakes deviates from that of the homogeneous Poisson process where the earthquakes occur randomly. The trough of the large deviation function of the renewal earthquakes is deeper than the non-renewal earthquakes. This indicates that the renewal earthquakes show higher periodicity than the non-renewal earthquakes.\n","1"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Two-scale Renormalization Group Classification of Stochastic Processes in Geophysics","NG51A-1762","8:00 AM","8:00 AM","J. H.  Cushman*","J. H.  Cushman*; D.   O'malley","Purdue University","Sessioned","Body: Renormalization group operators are used to classify stochastic processes on two time scales. Repeated application of one operator is associated with the long time behavior of the process while the other is associated with the short time behavior of the process. This approach is shown to be robust even in the presence of nonstationary increments generated by non-linear clocks and/or infinite second moments. Fixed points of the operators can be used for further subclassification of processes when appropriate limits exist. Several processes are classifed using the renormalization group scheme. Examples to be classifed include advection-diffusion in an ergodic velocity field, and a model of diffusion in the branching network.\nURL: www.math.purdue.edu/~jcushman/jcushman.html\n","2"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Weibull Statistics for Upper Ocean Currents with the Fokker-Planck Equation","NG51A-1763","8:00 AM","8:00 AM","P. C.  Chu*","P. C.  Chu*","Naval Postgraduate School","Sessioned","Body: Upper oceans typically exhibit of a surface mixed layer with a thickness of a few to several hundred meters. This mixed layer is a key component in studies of climate, biological productivity and marine pollution. It is the link between the atmosphere and the deep ocean and directly affects the air-sea exchange of heat, momentum and gases. Vertically averaged horizontal currents across the mixed layer are driven by the residual between the Ekman transport and surface wind stress, and damped by the Rayleigh friction. A set of stochastic differential equations are derived for the two components of the current vector (u, v).   The joint probability distribution function of (u, v) satisfies the Fokker-Planck equation (Chu, 2008, 2009), with the Weibull distribution as the solution for the current speed. To prove it, the PDF of the upper (0-50 m) tropical Pacific current speeds (w) was calculated from hourly ADCP data (1990-2007) at six stations for the Tropical Atmosphere Ocean project. In fact, it satisfies the two-parameter Weibull distribution reasonably well with different characteristics between El Nino and La Nina events: In the western Pacific, the PDF of w has a larger peakedness during the La Nina events than during the El Nino events; and vice versa in the eastern Pacific. However, the PDF of w for the lower layer (100-200 m) does not fit the Weibull distribution so well as the upper layer. This is due to the different stochastic differential equations between upper and lower layers in the tropical Pacific.  For the upper layer, the stochastic differential equations, established on the base of the Ekman dynamics, have analytical solution, i.e., the Rayleigh distribution (simplest form of the Weibull distribution), for constant eddy viscosity K.  Knowledge on PDF of w during the El Nino and La Nina events will improve the ensemble horizontal flux calculation, which contributes to the climate studies. Besides, the Weibull distribution is also identified from the near-real time ocean surface currents derived from satellite altimeter (JASON-1, GFO,   ENVISAT) and scatterometer (QSCAT) data on 1o   1o resolution for world oceans (60o S to 60o N)   as  “Ocean Surface Current Analyses – Real Time (OSCAR)”. Such a PDF has  little seasonal and interannual variations. Knowledge on PDF of w will improve the ensemble horizontal flux calculation, which contributes to the climate studies.ReferencesChu, P. C., 2008: Probability distribution function of the upper equatorial Pacific current speeds. Geophysical  Research Letters, 35,doi:10.1029/2008GL033669Chu, P. C., 2009: Statistical Characteristics of the Global Surface Current Speeds Obtained from Satellite Altimeter and Scatterometer Data. IEEE Journal of Selected Topics in Earth Observations and Remote Sensing,2(1),27-32.\nURL: http://faculty.nps.edu/pcchu\n","3"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Fault Identification by Unsupervised Learning Algorithm","NG51A-1764","8:00 AM","8:00 AM","S.   Nandan*","S.   Nandan*; U.   Mannu","ETH, Zurich; National Geophysical Research Institute","withdrawn","","4"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Iterative Non-hierarchical Cluster Analysis (INCA): a novel approach to analysing downhole logging and petrophysical data.","NG51A-1765","8:00 AM","8:00 AM","J.   Inwood*","J.   Inwood*; J.   Tudge; P.   Harvey","University of Leicester; University of Wisconsin-Madison","Sessioned","Body: Iterative Non-Hierarchical Cluster Analysis (INCA) is a multivariate statistical approach used to analyse data, suited to large datasets where a defined number of clusters can be hypothesised. Although the fundamentals of this methododology are well-known, its use for the analysis of downhole logging and petrophysical measurements is a novel approach for quantitatively interpreting these datasets. Cluster analysis works by starting with k random clusters then grouping the set of data such that values within a cluster are more similar to each other than to those in the other clusters i.e. to minimise variability within a cluster and maximise variability between clusters. INCA provides a valuable tool for understanding downhole logging and petrophysical datasets by interpreting the weightings attached to each cluster in terms of petrophysical characteristics.The INCA program has been successfully used on datasets from varied geological environments to characterise formations based on their petrophsyical properties alone. Here, we discuss details of the specific algorithms chosen, size constraints and departures from standard commercially available packages. We present examples of results that use a variety of different petrophysical parameters; from spectral gamma ray logs used to independently assess lithology, to resisitivity and sonic logs used to identify the position of major boundaries. Examples of the methodology applied to subduction zone accretionary prism sediments (IODP Expedition 314), oceanic crustal rocks (e.g. ODP Hole 735B) and from continental shelf siliciclastic sediments (IODP Expedition 313) are illustrated.\n","5"
"NG51A.* Statistical Geodynamics II Posters","NG51A","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Earth and Planetary Surface Processes (EP)Earth and Space Science Informatics (IN)Mineral and Rock Physics (MR)Natural Hazards (NH)Planetary Sciences (P)Seismology (S)Tectonophysics (T)Volcanology, Geochemistry, and Petrology (V)","Geophysical Monitoring of Geodynamic Processes of Earth Crust of Central Armenia","NG51A-1766","8:00 AM","8:00 AM","R.   Pashayan*","R.   Pashayan*","Institute of Engineering Seismology","withdrawn","","6"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","IMPACT OF A STOCHASTIC ENERGY BACKSCATTER SCHEME  ON CLIMATE AND VARIABILITY ACROSS TIMESCALES AND RESOLUTIONS","NG51B-1767","8:00 AM","8:00 AM","C.   Sanchez*","C.   Sanchez*","Met Office","Sessioned","Body: Stochastic physics is one of most widely used methods to represent model uncertainty in ensemble prediction systems of weather and climate models. These schemes aim to represent absent or poorly simulated process whose scales are below the truncation scale, they have been proven to be a skilful tool against the common underdispersiveness (lack of internal variability) of these models, as well as theoretically able to improve the mean climate through a noise-induced drift (better variability leads to a better mean climate). However, the formulation of these schemes often relies in  pragmatic assumptions with limited scientific basis, and their physical realism is often challenged.The stochastic energy backscatter method is one of the main formulations of stochastic physics. It is designed to stochastically simulate upscale cascades of energy coming from numerical dissipation, convective subgrid-scale events or subgrid mountain drag.  This scheme has been successfully implemented in many of the most important numerical weather prediction models across the world.  It improves the ensemble skill scores, and under some configurations the mean climate too. In order to understand the impacts of the stochastic energy backscatter concept in a deterministic framework, we use the Stochastic Kinetic Energy Backscatter (SKEB2) scheme in the Met Office Unified Model (MetUM). We explore the impact of SKEB2 across timescales and resolutions in terms of usual model evaluation metrics such as biases or root mean error square, as well as some process-based techniques to diagnose the simulation of tropical and extra-tropical variability, such as cyclone tracking, Lorenz Energy Cycle or Madden Julian Oscillation diagnostics. Our results show that the extra kinetic energy added by SKEB2 can improve the representation of key processes that drive the atmospheric variability, leading to a slight improvement of climate biases. However it degrades the skill of short-range (less than 5 days) deterministic forecasts. \n","1"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","An Extension to the Theory of Fluctuations in an Equilibrium Convective Ensemble","NG51B-1768","8:00 AM","8:00 AM","M. C.  Penland*","M. C.  Penland*; J.   Bao","NOAA/ESRL","Sessioned","Body:    The theory of fluctuations in an equilibrium convective ensemble emerging in the literature is revisited and extended in this study.  The probability of requiring n mutually independently convective plumes and a total cloud-base mass flux M for subgrid convection to occur in a given grid box is derived based on the concept of the grand canonical ensemble, which is well known in classic statistical mechanics.  The probability distribution functions of the cloud-base mass flux and the number of subgrid convective plumes are dependent on the average of each of the two quantities.  This problem has been considered in previous work (e.g., Craig and Cohen 2006), where n was distributed as a Poisson process.  It turns out that deriving the distribution describing n simultaneously with that describing the cloud-base mass flux yields a geometric distribution rather than a Poisson distribution.  In fact, though the two distributions are quite different, they are logically consistent since the geometric distribution can result if the rate parameter of a Poisson distribution is itself random and distributed exponentially.  Other, physically based distributions for the rate parameter are possible, and we introduce one based on a stochastic model of vertical velocity.  The work here is thus an extension rather than an alternative to the Craig-Cohen theory.\n","2"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Stochastic parametrization of ocean mesoscale eddies ","NG51B-1769","8:00 AM","8:00 AM","L.   Zanna*","L.   Zanna*; P.   PortaMana","University of Oxford ","Sessioned","Body: The ocean contains a vigorous mesoscale eddy field with spatial scales of approximately 10 to 100km, evolving over time scales from weeks to months. These eddies are important in establishing the ocean's circulation and tracer properties. Grid spacing of roughly 10 km and smaller are necessary to properly simulate the eddy field, therefore ocean climate models are unlikely to routinely resolve geostrophic eddies and their effect needs to be parametrized. The goal of this study is to construct a stochastic parameterization of mesoscale eddies in ocean models in order to replace or improve current deterministic closure schemes.  A quasi-geostrophic (QG) model in a double-gyre configuration is run at resolution of 7.5 km (eddy-resolving).  The output of the high-resolution model is coarse-grained and used to calculate probability distribution functions for the eddy forcing conditioned on the model state.  A stochastic parametrization is then created using the evaluated conditional probability distribution functions and implemented as Markovian and/or non-Markovian processes in a coarse resolution run of the QG model.  The dynamics of the mean flow, its variability and eddy-mean flow interaction are examined for each case of the stochastic parametrization and compared with deterministic closures of geostrophic eddies.Reference: Porta Mana  PGL and L. Zanna: Stochastic parametrization of ocean mesoscale eddies, In Prep. for J. of Climate, 2012\n","3"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Stochastic Parameterization of Intermittent Mixing in the Stable Boundary Layer","NG51B-1770","8:00 AM","8:00 AM","A. H.  Monahan*","A. H.  Monahan*; Y.   He; N. A.  McFarlane","Univ Victoria","Sessioned","Body: The diurnal cycle of the probability density function (pdf) of lower-atmospheric wind speeds is characterised by a long tail toward high wind speeds within the shallow nocturnal stable boundary layer (SBL).  A potential mechanism for the generation of this tail is intermittent mixing between the normally quiescent SBL and the higher-momentum fluid above.  When included in a state-of-the-art single column model, a stochastic parameterisation of this intermittent mixing is shown to result in simulations of the diurnal evolution of the wind speed pdf that are in close agreement with observations at a tall tower in Cabauw, Netherlands.  In particular, the presence of enhanced wind speed pdf tails in the nocturnal SBL is simulated.\n","4"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Using stochastic NWP ensembles for volcanic ash transport and dispersion model outcomes","NG51B-1771","8:00 AM","8:00 AM","A. K.  Patra*","A. K.  Patra*; M. I.  Bursik; E.   Stefanescu; E.   Pitman; T.   Singh; P.   Singla","University at Buffalo, SUNY ","Sessioned","Body: Ash clouds ejected into the atmosphere by volcanic eruption extend over large areas and can travel thousands of kilometers from the source volcano, disrupting air traffic and posing a significant hazard to air travel. Volcanic ash transport and dispersion models like the PUFF model simulate the ash transport and dispersion.  An important input parameter for such simulations are wind fields. They represent one of the major sources for uncertainties in ash transport and dispersion simulations. Ensemble methods are considered to be an effective way to estimate the probability density function of future states of the atmosphere by addressing uncertainties present in initial conditions and in model approximations. To generate localized wind ensemble we are using the Weather Research and Forecast (WRF) model with various initial conditions. We examine the spatial variability of the wind fields as well as their uncertainty by using two methods to simulate uncertainty on initial conditions. First method was developed by National Centers for Environmental Prediction (NCEP) and it is based on breeding vectors [2], while the second method was proposed by [1] and uses a distribution of the initial conditions to describe the confidence in the knowledge of the initial state of the atmosphere.PUFF runs are performed with the above wind fields for the eruption of Eyjafjallajokull, Iceland which had a peak ash emission in the period 15-20 April 2010.. A variety of model outputs are compiled, including snapshots of airborne-ash concentration (relative to the number of particles released at the start of the simulation) and particle location color-coded by height which shows the sensitivity of these outputs to wind fields.[1] E. Constantinescu, V. Zavala, M. Rocklin, S. Lee, and M. Anitescu. A com-putational framework for uncertainty quantification and stochastic optimiza-tion in unit commitment with wind power generation. IEEE Transactionson Power Systems, 2010.[2] Z. Toth and E. Kalnay. Ensemble forecasting at ncep and the breedingmethod. Mon. Wea. Rev, 126:3292–3302, 1997.\n","5"
"NG51B.* Stochastic Parameterizations in Numerical Weather and Climate Models II Posters","NG51B","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): ","Developing Prescribed Aerosol in CAM5 using random sampling","NG51B-1772","8:00 AM","8:00 AM","J.   Yoon*","J.   Yoon*; P.   Rasch; S. J.  Ghan","Pacific Northwest National Lab","Sessioned","Body: Aerosol processes are computationally expensive. For some applications it is desirable to prescribe rather than predict aerosol concentrations in global climate model. This is much more difficult in CAM5 because of the strong interactions between aerosols and clouds. Our goals are (1) to run CAM5 with prescribed aerosol without predictive aerosol module and (2) to produce climate simulation very similar to that with predicted aerosol. This is achieved using random sampling of log normal distribution of aerosol properties constructed from predicted aerosol run. By using prescribed aerosol, CAM5 can run with less computational burden with preserving the vast of its characteristics. Also, an application of this method is presented. \n","6"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Lifetime and layering of vortices in rotating stratified fluids","NG51C-1773","8:00 AM","8:00 AM","O.   Aubert*","O.   Aubert*; M.   Le Bars; P.   Le Gal","IRPHE","Sessioned","Body: Oceans, atmospheres, accretion disks are natural stratified fluid layers that are influenced by the rotation of the planet or the disk through the Coriolis force. There, it is common to observe long-lived anticyclonic vortices such as Jupiter's Great Red Spot, sometimes surrounded by layers of constant density as the ocean Meddies.In the continuity of the experiments of Griffiths \& Linden (1981) and Hedstrom \& Armi (1988), we reproduce a rotating and linearly stratified environment where freely-decaying or sustained laboratory anticyclonic vortices are created via a short or continuous injection of isodense fluid at mid-depth of the stratified layer. We quantify their long term evolution using PIV measurements to determine their Rossby number $Ro$ at all times. $Ro$ of the freely-decaying vortices decreases in time as seen in Fig. 1. This is theoretically described by the energy conservation equations applied to a gaussian model that fits both laboratory and oceanic vortices. Using this theoretical derivation as well as numerical simulations, we investigate the respective roles of rotation and stratification to explain the longevity of the vortices.$Ro$ of the sustained vortices remains large and allows for the formation of layers above and below the vortices as in Fig. 2, following the double-diffusive instability of McIntyre (1970). Typical length and time scales of the instability are well described by a linear stability analysis based on our gaussian model.Some of these results are applied to natural vortices such as the Meddies or vortices in accretion disks and help to understand their characterictics.\n","1"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Numerical Simulations of Boundary-Driven Dynamos","NG51C-1774","8:00 AM","8:00 AM","K.   White*","K.   White*; N.   Brummell; G. A.  Glatzmaier","University of California, Santa Cruz; University of California, Santa Cruz","Sessioned","Body: An important topic of physics research is how magnetic fields are generated and maintained in the many astrophysical bodies where they are ubiquitously observed. Of particular interest, are reversals of magnetic fields of planets and stars, especially those of the Earth and the Sun. In an attempt to provide intuition on this problem, numerous physical dynamo experiments have been performed in different configurations. Recently, a tremendous breakthrough was made in the Von Karman sodium (VKS) experiments in France when the most realistic laboratory fluid dynamo to date was produced by driving an unconstrained flow in a cylinder of liquid sodium (Monchaux et al, 2007, PRL). One of the curiosities of the VKS experiment however is the effect of the composition of the impellers that drive the flow. Steel blades failed to produce a dynamo, but soft iron impellers, which have much higher magnetic permeability, succeeded. The role of the magnetic properties of the boundaries in boundary-driven dynamos is therefore clearly of interest. Kinematic and laminar numerical dynamo simulations (Giesecke et al, 2010, PRL & Gissinger et al, 2008 EPL) have shed some light but turbulent, nonlinear simulations are necessary. Roberts, Glatzmaier & Clune 2010 created a simplified model of the VKS setup by using three-dimensional numerical simulations in a spherical geometry with differential zonal motions of the boundary replacing the driving impellers of the VKS experiment. We have extended these numerical simulations further towards a more complete understanding of such boundary-forced dynamos. In particular, we have examined the effect of the magnetic boundary conditions - changes in the wall thickness, the magnetic permeability, and the electrical conductivity - on the mechanisms responsible for dynamo generation. Enhanced permeability, conductivity and wall thickness all help dynamo action to different degrees. We are further extending our investigations to asymmetric forcing to examine the possible existence of solutions incorporating field reversals. Asymmetry can quench dynamo action by destroying the complex correlations that are necessary to regenerate axisymmetric poloidal field.\n","2"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Subgrid-scale buoyancy in convection-driven dynamo simulations in a rotating spherical shell","NG51C-1775","8:00 AM","8:00 AM","H.   Matsui*","H.   Matsui*; B. A.  Buffett","UC Berkeley","Sessioned","Body: Buoyancy forces are thought to be responsible for driving vigorous convection in the Earth's liquid core. The buoyancy force is linear in temperature, which ensures that large-scale temperature anomalies drive large-scale flow and small-scale temperature anomalies drive small-scale flow. Therefore, there is no direct transfer between scales. However, when we evaluate the rate of work done by buoyancy forces, we find a correlation between the small-scale temperature and velocity fields, which means that energy is transferred into  the large scales by the one of the nonlinear terms in the governing equations. The specific energy pathway must involve one or more of the subgrid-scale (SGS) terms in the dynamo problem, which includes the SGS heat flux, Reynolds stress, SGS Maxwell stress, and the SGS induction. We seek to identify the energy pathway because large-eddy simulations (LES) based on the dynamic similarity method underestimate the large-scale magnetic energy by nearly 50% compared with that from a fully resolved simulation on a finer grid. Small-scale buoyancy is a likely explanation for the low magnetic energy in the LES because we obtain very similar results to the LES solution in resolved simulation when we perform a resolved simulation using spatially filter to the buoyancy force at each time step to remove small-scale contributions. A clue to the energy pathway is found in our SGS model for the Reynolds stress, which shows a positive (upscale) transfer to kinetic energy to the large scales in a region around the tangential cylinder, consistent with the results inferred from a fully resolved calculation. The region with the positive energy transfer by the Reynolds stress also coincides with vigorous magnetic field generation at the resolved scales in the LES. Thus, the Reynolds stress contributes indirectly to the magnetic field generation by supplying kinetic energy to the region where generation is vigorous. However, it appears that the work done by the Reynolds stress is not large enough to explain contributions of the small scale buoyancy flux at the large scale (i.e. SGS Buoyancy flux). Because none of the other SGS terms have the magnitude or sign required to explain the SGS buoyancy flux, we assume that some of SGS buoyancy flux is transferred to the large scale kinetic energy through the Reynolds stress. By increasing the amplitude of the Reynolds stress by a factor of four, we obtain to better agreement between the work of the Reynolds stress and the SGS buoyancy flux. We also obtain substantial improvements in the simulation over the standard LES.We discuss a parameterization of the Reynolds stress which relies on a local estimate of SGS buoyancy flux to adjust the model coefficient. The local SGS buoyancy flux can be approximated using the SGS heat flux, which is routinely calculated in the standard LES, so the modified parameterization requires few additional computations.\n","3"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Liquid metal suspensions for turbulent dynamo experiments","NG51C-1776","8:00 AM","8:00 AM","E.   Brown*","E.   Brown*; Q.   Xu; N.   Oudalov; Q.   Guo; H.   Jaeger","University of California, Merced; The University of Chicago","Sessioned","Body: I will discuss the potential for using suspensions of magnetic particles in liquid metals for magnetohydrodynamics experiments in the laboratory.  The ability to tune material properties of such suspensions could allow for experiments that in a parameter regime comparable to Earth's outer core.  Specifically,  high conductivity of the liquid metal and high magnetic permeability of the particles could reach the large magnetic Reynolds numbers required to generate a dynamo effect in the laboratory, while additional suspended particles can independently control viscosity and thus the Reynolds number.  A key experimental challenge is to achieve good wetting of micron-sized suspended particles by liquid metals to produce homogenous suspensions.  I will present data on the wetting and rheological properties of liquid gallium and a eutectic gallium-indium alloy (eGaIn).   A rheometer is used to measure a yield stress due to an oxide skin on the surface of liquid metals, which can be controlled and eliminated by surrounding the metal with an acid bath.  We find that this yield stress and the contact contact angle on solid surfaces change at the same critical acid concentration, thereby quantitatively confirming that the wettability of these liquid metals is due to the oxide skin, which can be controlled with the acid bath.  This reveals a tunable tradeoff between good wetting for better suspension and a yield stress which introduces non-Newtonian fluid behavior.  We find that even with this yield stress from an oxide skin or with a small fraction of particles suspended, the shear stresses at high Reynolds numbers match those of Newtonian fluids, suggesting that non-Newtonian fluid properties will not interfere with the turbulent flow structures that may be relevant to dynamos.\n","4"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Internal Gravity Waves modulate the apparent misalignment of Exoplanets around Hot Stars","NG51C-1777","8:00 AM","8:00 AM","T.   Rogers*","T.   Rogers*; D.   Lin","University of arizona; University of California Santa Cruz","Sessioned","Body: We propose that the observed misalignment between extra-solar planets and their hot host stars can be explained by angular momentum transport within the host star.  Observations have shown that this misalignment is preferentially around hot stars, which have convective cores and extended radiative envelopes.  This situation is amenable to substantial angular momentum transport by internal gravity waves (IGW) generated at the convective-radiative interface.  Here we present numerical simulations of this process and show that IGW can modulate the surface rotation of the star.  This leads to an apparent mis-alignment whereby the planets have an angular momentum vector similar to the convection zone or bulk of the star but mis-aligned with the photosphere.\nURL: www.solarphysicist.com\n","5"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Energy Pathways and Scale Interactions in the Ocean","NG51C-1778","8:00 AM","8:00 AM","H.   Aluie*","H.   Aluie*; M. W.  Hecht; G. K.  Vallis; K.   Bryan; R. E.  Ecke; M. E.  Maltrud; B. A.  Wingate","Los Alamos National Laboratory; Princeton/GFDL","Sessioned","Body: Large-scale currents and eddies pervade the ocean and play a prime role in the general circulation and climate. The coupling between scales ranging from $O(10^4)$ km down to $O(1)$ mm presents a major difficulty in understanding, modeling, and predicting oceanic circulation and mixing, where the energy budget is uncertain within a factor possibly as large as ten. Identifying the energy sources and sinks at various scales can reduce such uncertainty and yield insight into new parameterizations. To this end, we refine a novel coarse-graining framework to directly analyze the coupling between scales. The approach is very general, allows for probing the dynamics simultaneously in scale and in space, and is not restricted by usual assumptions of homogeneity or isotropy. We apply these tools to study the energy pathways from high-resolution ocean simulations using LANL’s Parallel Ocean Program. We examine the extent to which the traditional paradigm for such pathways is valid at various locations such as in western boundary currents, near the equator, and in the deep ocean. We investigate the contribution of various nonlinear mechanisms to the transfer of energy across scales such as baroclinic and barotropic instabilities, barotropization, and Rossby wave generation.\n","6"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","A Multiple Scales Asymptotic Framework for Analysis and Simulation of Spatially-Extended Ocean Surface Boundary-Layer Dynamics","NG51C-1779","8:00 AM","8:00 AM","G. P.  Chini*","G. P.  Chini*; Z.   Malecha; K. A.  Julien","University of New Hampshire; University of Colorado","Sessioned","Body: The ocean surface boundary layer (BL), the upper 50-100 meters of the water column that experiences the direct impact of atmospheric forcing, plays a pivotal role in climate dynamics, pollutant dispersal, and marine ecosystem viability.  A vexing challenge in numerical ocean modelling, particularly for climate applications, is parameterizing shear- and thermally-driven convection within the surface BL, which cannot be explicitly resolved in conventional numerical general circulation models (GCMs).  We address this challenge by employing systematic multiple scales asymptotic analysis to formally separate the small-scale, strongly non-hydrostatic BL dynamics from the larger-scale, rotationally-influenced and largely hydrostatic submesoscale upper ocean flows.  This analysis, which furnishes coupled sets of PDEs governing the submesoscale and BL dynamics, has the advantage of retaining only the leading-order dynamical balances appropriate to each scale as well as the leading-order teleconnections between the scales.  After summarizing the derivation of the two-scale system, we discuss the numerical implementation and validation of this multiscale asymptotic framework.  Our results demonstrate more than an order of magnitude acceleration of the computations relative to brute-force DNS.  Moreover, we present clear evidence of upscale energy transfer, in which the BL convection drives coherent large-scale flows.  We conclude by showing how a nonlinear WKBJ analysis of the coupled PDE systems can be used to develop a novel multiscale stability theory for slowly modulated but fully nonlinear BL convection.\n","7"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Dipole Alignment in Rotating MHD Turbulence","NG51C-1780","8:00 AM","8:00 AM","J. V.  Shebalin*","J. V.  Shebalin*; T.   Fu; L.   Morin","NASA JSC; University of Houston; NASA JSC","Sessioned","Body: We present numerical results from long-term CPU and GPU simulations of rotating, homogeneous, magnetohydrodynamic (MHD) turbulence, and discuss their connection to the spherically bounded case. We compare our numerical results with a statistical theory of geodynamo action that has evolved from the ‘absolute equilibrium ensemble theory’ of ideal MHD turbulence, which is based on the ideal MHD invariants are energy, cross helicity and magnetic helicity. However, for rotating MHD turbulence, the cross helicity is no longer an exact invariant, although rms cross helicity becomes quasistationary during an ideal MHD simulation. This and the anisotropy imposed by rotation suggests an ansatz in which an effective, nonzero value of cross helicity is assigned to axisymmetric modes and zero cross helicity to non-axisymmetric  modes. This ‘hybrid statistics’ predicts a large-scale quasistationary magnetic field due to ‘broken ergodicity’, as well as dipole vector alignment with the rotation axis, both of which are observed numerically. We find that only a relatively small value of effective cross helicity leads to the prediction of a dipole moment vector that is closely aligned (< 10 degrees) with the rotation axis. We also discuss the effect of initial conditions, dissipation and grid size on the numerical simulations and statistical theory.\n","8"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Plasma Jet Simulations Using a Generalized Ohm's Law","NG51C-1781","8:00 AM","8:00 AM","J. V.  Shebalin*","J. V.  Shebalin*; F.   Ebersohn; S. S.  Girimaji","Texas A&M University; NASA JSC; University of Houston - Clear Lake","Sessioned","Body: Plasma jets are important physical phenomena in astrophysics and plasma propulsion devices.  A currently proposed dual jet plasma propulsion device to be used for ISS experiments strongly resembles a coronal loop and further draws a parallel between these physical systems [1].   To study plasma jets we use numerical methods which solve the compressible MHD equations using the generalized Ohm’s law[2]. Herein we discuss the crucial underlying physics of these systems along with the numerical procedures we utilize to study them. Recent results from our numerical experiments will be presented and discussed.[1] T. Glover, et al., The VASIMR® VF-200-1 ISS Experiment as a Laboratory for Astrophysics, Poster SM51C-1831, AGU Fall Meeting, San Francisco, December 13-17, 2010.[2] F. Ebersohn, J. V Shebalin, S. Girimaji and D. Staack, Magnetic Field Effects on Plasma Plumes, Paper O2-404, 39th EPS Conference on Plasma Physics, Stockholm, July 2-6, 2012.\n","9"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","The Meridional Secondary Circulation of 3D Vortices in Rotating, Stratified, Shear and its Role in Astrophysical Flows: from a Newly Pale Great Red Spot to Planet Formation","NG51C-1782","8:00 AM","8:00 AM","P. S.  Marcus*","P. S.  Marcus*; P.   Hassanzadeh","UC Berkeley","Sessioned","Body: The interest in understanding the physics of 3D, compact baroclinic vortices in rotating, stratified shear is growing. This is partly due to the fact that vortices in protoplanetary disks attract dust and may be key in planetesimal formation. The interest is also fueled by the unanswered questions about vortices of Jupiter and Saturn and the recent changes of the Jovian vortices. Examples are the appearance of the Red Oval BA in 2005, and the very recent color-change of the Great Red Spot to pale orange, which was observed in July 2012. While the dynamics of 3D baroclinic vortices in rotating stratified flows, even without shear, is poorly understood, the presence of horizontal shear strongly influences their dynamics and further complicates the problem. Studying the physics of planetary vortices and their interaction with the environment requires high-resolution 3D simulations. Ignoring the vertical direction, neglecting the vertical motion (as has been done in almost all published numerical simulations of Jovian vortices because most studies have assumed vertical hydrostatic equilibrium), or the lack of enough resolution eliminates or changes important physical processes such as the secondary circulation. This secondary, ageostrophic flow within the vortices is essential in dust accumulation and agglomeration in vortices in protoplanetary disks. The secondary circulation has been shown to be important in determining the color and cloud patterns in Jovian vortices. For example, the recent color change of the Great Red Spot can be explained by changes in its secondary circulation. It has also been suggested that the persistent rings around the Jovian anticyclones are produces by this secondary circulation. We show that the lifetimes of Jovian vortices depend upon their ability to merge with and absorb smaller vortices and also on the secondary circulations within vortices. The main dissipation mechanism for most astrophysical vortices is thermal radiation rather than viscosity. Jovian vortices have a characteristic radiative time of 4-5 years, but they are observed to outlive this time scale by order(s) or magnitude. The Great Red Spot has existed for centuries, and the White Ovals survived for decades. To account for their longevity, we not only propose that they are forced (by merging with smaller vortices) but also that their unforced decay time is much longer than the radiative time. We examine the mergers of 3D vortices. We also show why unforced vortices have unexpectedly long decay times. The thermal radiation reduces the density anomaly inside the vortex, and consequently disturbs the hydrostatic balance and produces a vertical motion (and hence a secondary circulation).  We discuss the physics of this ageostrophic flow and show that with the help of shear, the secondary circulation can enormously slow down the decay of the density anomaly and hence the vortex. \n","10"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","Instabilities of Magnetized Fluid Flow in an Earth-like Geometry","NG51C-1783","8:00 AM","8:00 AM","M. M.  Adams*","M. M.  Adams*; D. S.  Zimmerman; S. A.  Triana; D. P.  Lathrop","University of Maryland, College Park; University of Maryland, College Park","Sessioned","Body: We present experimental studies of the turbulent flow of a conducting fluid in a spherical shear flow in the presence of a magnetic field. Our experimental apparatus consists of a 60 cm diameter outer spherical shell concentric with an inner sphere, each of which can be rotated independently. Liquid sodium serves as the working fluid, filling the gap between them. The geometry of the experiment, modeled after that of Earth's core, makes these studies relevant to geophysical and astrophysical bodies. We apply an axial magnetic field, and measure the induced magnetic field around the device to obtain information about the global fluid flow. We also measure the torque required to drive the inner and outer spheres at their respective rotation rates, and take pressure measurements. We study how the required torques change with the rotation rate ratio of the two spheres and with the strength of the applied magnetic field. We compare the results with previous experimental results, as well as with theory and numerical predictions. \n","11"
"NG51C. The Fluid Dynamics of Planets and Stars II Posters","NG51C","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric and Space Electricity (AE)Geomagnetism and Paleomagnetism (GP)Ocean Sciences (OS)Planetary Sciences (P)SPA-Solar and Heliospheric Physics (SH)Study of Earth's Deep Interior (DI)","General scaling behavior in Rayleigh-Bénard convection with and without rotation","NG51C-1784","8:00 AM","8:00 AM","E. M.  King*","E. M.  King*; S.   Stellmach; B. A.  Buffett","UC Berkeley; UC Berkeley; WWU Münster","Sessioned","Body: Rotating Rayleigh-Bénard convection provides a simplified dynamical analog for many planetary and stellar fluid systems. We use numerical simulations of rotating Rayleigh-Bénard convection to investigate the scaling behavior of five quantities over a range of Rayleigh (10<sup>3</sup> ≤ Ra ≤ 10<sup>9</sup>), Prandtl (1≤ Pr ≤ 100), and Ekman (10<sup>-6</sup> ≤ E ≤ ∞) numbers. The five quantities of interest are the viscous and thermal boundary layer thicknesses, mean temperature gradients, characteristic horizontal length scales, and flow speeds (Peclet number). We focus, where possible, on scalings with some theoretical basis.  Three parameter regimes in which different scalings apply are quantified: non-rotating, weakly rotating, and rotationally constrained.\n","12"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Passive scalar statistics and its dependence on Lagrangian coherent structures in stochastic flows","NG51D-1785","8:00 AM","8:00 AM","W.   Tang*","W.   Tang*; P.   Walker; M.   Allshouse; D.   del-Castillo-Negrete","Arizona State University; Massachusetts Institute of Technology; Oak Ridge National Lab","withdrawn","","1"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Analyzing & Estimating Fluid Flow Properties via the Ergodicity Defect","NG51D-1786","8:00 AM","8:00 AM","S.   Scott*","S.   Scott*; I. I.  Rypina","Marquette University; Woods Hole Oceanographic Institution","Sessioned","Body: The ergodicity defect has been used as a method for identifying Lagrangian coherent structures in ocean flows – see ( npg-2011-14). The general idea is that the ergodicity defect distinguishes trajectories in terms of how they sample the flow – i.e., in terms of ergodicity - and this in turn is used to identify coherent structures in the flow. In this presentation, we explore how best to use the ergodicity defect for analyzing fluid flow properties both in terms of obtaining a better estimate of the properties and in terms of understanding the transport of material properties by coherent structures in the flow.  For example, we investigate the usefulness of the ergodicity defect for determining an optimal estimate of temperature by weighting Lagrangian drifters via their defect values.\n","2"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Anisotropy and non-universality in scaling laws of the large scale energy spectrum in rotating turbulence","NG51D-1787","8:00 AM","8:00 AM","A.   Sen*","A.   Sen*; A.   Pouquet","University of Colorado, Boulder; NCAR","Sessioned","Body: Rapidly rotating turbulent flow is characterized by the emergence of columnar structures that are representative of quasi-two dimensional behavior of the flow. It is known that when energy is injected into the fluid at an intermediate scale L_f, it cascades towards smaller as well as larger scales. In this paper we analyze the flow in the inverse cascade range at a small but fixed Rossby number, Ro ~ 0.05. Several numerical simulations with helical and non-helical forcing functions are considered in periodic boxes with unit aspect ratio. In order to resolve the inverse cascade range with reasonably large Reynolds number, the analysis is based on large eddy simulations which include the effect of helicity on eddy viscosity and eddy noise. Thus, we model the small scales and resolve explicitly the large scales. We show that the large-scale energy spectrum has at least two solutions: one that is consistent with Kolmogorov-Kraichnan-Batchelor-Leith phenomenology for the inverse cascade of energy in two-dimensional (2D) turbulence with  k_{\perp}^{-5/3} scaling, and the other that corresponds to a steeper  k_{\perp}^{-3} spectrum in which the three-dimensional (3D) modes release a substantial fraction of their energy per unit time to 2D modes. {The spectrum that} emerges {depends on} the anisotropy of the forcing function, the former solution prevailing for forcings in which more energy is injected into 2D modes while the latter prevails for isotropic forcing. In the case of anisotropic forcing, whence the energy goes from the 2D to the 3D modes at low wavenumbers, large-scale shear is created resulting in another time scale \tau_{sh}, associated with shear, thereby producing a k^{-1} spectrum for the total energy with the 2D modes still following a k_{\perp}^{-5/3} scaling. \n","3"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Improving Particle Integration Efficiency in Mantle Convection Simulation by Combining Numerical Integration Techniques","NG51D-1788","8:00 AM","8:00 AM","E. M.  Javan*","E. M.  Javan*; E. H.  Studley; E. M.  Heien; L. H.  Kellogg","University of California Davis","Sessioned","Body:  Tracer particles are often used in simulations of mantle convection and similar phenomenon to track material properties on a fine scale. Particle flow techniques generally use a single high-accuracy numerical integration method, possibly with an adaptive time step. However, convection simulations have strong heterogeneity in the types and linearity of flows. To improve efficiency we investigate exploiting this heterogeneity by using different integration methods depending on the flow pattern near each particle.	 The optimal integration method and time step is based on a measure of flow curvature in a given vector field, and a user specified acceptable level of error. Particles in low curvature flow tend to use Euler's method of integration, while higher curvature requires the use of second or fourth order Runge-Kutta. Our method analyzes a particle's surroundings quickly and responds with the most efficient integration method to maintain an acceptable level of error. We implement this method in the mantle convection simulation code ASPECT and find significant improvement in overall simulation performance while maintaining the same level of accuracy.  We also demonstrate how this method allows a tradeoff between accuracy and speed in these simulations and how it may be applicable to other areas.\n","4"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","A study of caprock continuous-discontinuous fracturing process during CO2-injection into a brine aquifer","NG51D-1789","8:00 AM","8:00 AM","P.   Pan*","P.   Pan*; J.   Rutqvist; F.   Yan; X.   Feng","Institute of Rock and Soil Mechanics, Chinese Academy of Sciences; Lawrance Berkeley National Lab","Sessioned","Body: A numerical study of fracturing process during a deep underground injection of supercritical CO2 in a hypothetical brine aquifer/caprock system is conducted. The injection process is simulated using a newly developed numerical model for multi-phase analysis of CO2 and brine water flow, coupled with heat transfer and rock fracturing behavior. In the modeling, the domain to be solved is discretized into a system composed of cell elements in which the numerical grid and crack geometry are independent of each other. The level-set method is used for tracking the crack location and its propagation path. As a result, no explicit meshing for crack surfaces and no remeshing for crack growth are needed. Discontinuous displacement functions, i.e., the Heaviside function for crack surfaces and asymptotic crack-tip displacement fields, are introduced to represent the discontinuity. We use the “partition of unity” concept to improve the integral precision for elements, including crack surfaces and crack tips. From this, we develop a cellular automaton updating rule to calculate the stress field induced by CO2 injection. CO2 is injected at a constant rate over a 10-year period at a depth of 1,300-1,500 m. the injection zone is overlain by a 100-m-thick caprock, located at 1,200-1,300 m. The caprock is intersected by one or two initial faults with different inclinations. The hydraulic, mechanical as well as hydromechanical responses caused by the injection are studied with consideration of different geo-stress levels. This includes the spread of the CO2 plume(Figure 1), effective stress changes, crack contact, slip, opening and propagation(Figure 2), ground surface uplift, stress-induced or discontinuous deformation-induced permeability changes, and mechanical fracturing behavior. The study shows that the existence of fault and the fault geometries have great influence on stability of caprock and the CO2 migration across the caprock.\n","5"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","A New Discontinuous Method for Simulation of THMC Processes in EGS Reservoirs ","NG51D-1790","8:00 AM","8:00 AM","B.   Zheng*","B.   Zheng*; D.   Elsworth","psu","Sessioned","Body: A new method is introduced to couple the thermal, hydrologic, and chemical processes in the mechanical framework of discrete element models to examine THMC processes in fractured porous media representing EGS reservoirs. A granular model is assembled to represent rock blocks as an assemblage of particles as a “synthetic rock mass”. The essential features are a matrix comprising bonded particles and fractures that allow blocks to slide smoothly past each other. In addition, the model accommodated convective heat transport as a major agent of heat transfer in the system. This model is applied to the geometry of an injector-producer doublet representative of a deep EGS reservoir. In the early stages of injection, the effects of both fracture dilation and the development of new fractures result from high pressure injection of water and sharply augment the system permeability. This creates new fluid flow pathways from the injection wellbore to the production wellbore by connecting relic natural fractures with new fractures. As the injected water traverses the reservoir, thermal energy is recovered from the withdrawal wellbore with time and the temperature of the hot rock region along the fluid flow path decreases. This, in turn, creates new fractures and also further augments the apertures of existing fractures by changing the thermal stress, and as a result enhances system permeability. After long-term production, chemical effects become an important part of the permeability evolution with dissolution induced by stressed asperities contributing to the reduction in permeability in the system together with the effects of reprecipitation.  We assemble a model based on the Newberry demonstration project and evaluate the evolution of permeability with the operation of injection. Analytical comparison confirm that this model can be used to represent the THMC coupled processed effect on the evolution of transport properties.\n","6"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Large Eddy Simulation of the Quasi-Geostrophic Equations of Oceanic Flows","NG51D-1791","8:00 AM","8:00 AM","T.   Iliescu*","T.   Iliescu*; O.   San; Z.   Wang; E.   Foster; A.   Staples","Virginia Tech; Virginia Tech","Sessioned","Body: We developed an approximate deconvolution (AD) large eddy simulation (LES) model for the two-layer quasi-geostrophic equations (QGE). The AD closure modeling approach is appealing for geophysical flows because it needs no additional phenomenological approximations to the original equations, and it can achieve high accuracy by employing repeated (computationally efficient and easy to implement) filtering. We applied the AD-LES model to mid-latitude two-layer square oceanic basins, which are standard prototypes of stratified ocean dynamics models. Compared with a high-resolution simulation, AD-LES yielded accurate results at significantly lower computational cost.The sensitivity of the AD-LES results with respect to changes in input parameters was also performed. We discovered that although the AD-LES model was robust with respect to changes in parameters, changing the spatial filter made a huge difference. Two spatial filters were investigated in the AD-LES model: tridiagonal and elliptic differential. We found the tridiagonal filter did not introduce any numerical dissipation in the AD-LES model. The differential filter, however, added a significant amount, and our numerical results show the new AD-LES model used in with the differential filter can be employed successfully on meshes significantly coarser than the Munk scale and with an eddy viscosity coefficient that is dramatically lower than that used in the original two-layer QGE. Although we do not provide a solution to the longstanding quest for finding a rigorous derivation of the eddy viscosity coefficients used in ocean modeling, we put forth a novel approach, serendipitously discovered in our numerical investigation. The main strength of this new approach is that the modeling error can be disentangled from the numerical discretization error and can be studied separately in this framework. This could lead to more robust and general LES models for large scale geophysical flows. \n","7"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Transport and mixing of microbial population by atmospheric coherent structures","NG51D-1792","8:00 AM","8:00 AM","A.   Bozorg Magham*","A.   Bozorg Magham*; S. D.  Ross","Virginia Tech ","Sessioned","Body: Lagrangian coherent structures (LCSs) provide a new means for discussion of spatiotemporal characteristics of the passive transport and mixing of atmospheric pathogen populations, paving the way for new management strategies regarding the spread of infectious diseases affecting plants, domestic animals, and humans, including identification of probable source regions and forecasts of regions at high risk. We report on the relationship of coherent structures to the patchiness of pathogen populations, and the effects of imperfect forecast wind data on the resultant LCSs. Regarding forecasting LCSs, our main contributions are to quantify the accuracy and sensitivity of such predictions with respect to the forecasting parameters. To obtain more reliable atmospheric LCS features, we have incorporated two more concepts. First is the effect of unresolved turbulent motion; this consideration leads to the stochastic finite-time Lyapunov exponent (SFTLE) field and the resultant stochastic LCS. The second concept is ensemble FTLE/LCS forecasting using individual members of the ensemble wind field forecasts. \n","8"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Lobe dynamics and homoclinic tangles in atmospheric flows","NG51D-1793","8:00 AM","8:00 AM","S.   Naik*","S.   Naik*; S. D.  Ross","Virginia Tech","Sessioned","Body: In recent years, dynamical system theorists have been developing methods to study structures that govern the dynamics of atmospheric and oceanic flows. The primary concern for these flows are the finite time nature and the arbitrary time dependence in contrast to classical dynamical systems. Recent work on 2D quasi-horizontal approximations of atmospheric motion have demonstrated that there are aperiodic, finite-time analogs of homoclinic tangles and lobe dynamics, e.g., around hurricane boundaries. The tools used have been coherent structure boundaries based on ridges of the finite-time Lyapunov exponent (FTLE) field calculated from integrated particle trajectories. There are some ambiguities in the FTLE-based approach which suggests other methods should be attempted. In this work, we apply methods based on Lagrangian descriptors (due to Mancho and co-workers) to locate distinguished hyperbolic trajectories (DHTs) and generate corresponding finite-time stable and unstable manifolds to study lobe dynamics, as applied to atmospheric flow as well as fluid experiments. We compare the Lagrangian descriptor approach with the FTLE-based approach.\nURL: http://www.shaneross.com\n","9"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Stirring by the Asian Monsoon Circulation","NG51D-1794","8:00 AM","8:00 AM","K. P.  Bowman*","K. P.  Bowman*","Texas A&M Univ","Sessioned","Body: The Asian summer monsoon circulation, which is driven primarily by the release of latent heat  by monsoon convection, transports polluted air from the lower troposphere into the upper troposphere and stratosphere.  The upper-level mass outflow drives the Asian monsoon anticyclone, which is one of the largest features of the global atmospheric circulation during the northern hemisphere summer.  The size and strength of the monsoon anticyclone varies in response to fluctuations in monsoon convection, and the anticyclone also interacts with synoptic-scale waves propagating along the subtropical jet that lies on its northern flank.  These fluctuations drive complex transport processes that mix air into the anticyclone and at the same time export air from the monsoon into the global upper troposphere and lower stratosphere.We will present a Lagrangian analysis of transport and mixing by the Asian monsoon, with an emphasis on the mechanisms for transport and mixing, pathways for transport, and mixing rates and timescales.\n","10"
"NG51D. Theoretical, Observational, and Numerical Techniques in Geophysical Flow Analysis II Posters","NG51D","Poster","Nonlinear Geophysics (NG)","07-Dec-2012","8:00 AM","12:20 PM","Hall A-C (Moscone South)","Co-Sponsor(s): |ID of primary accepted session entered into 'notes to Admin': |Co-Sponsor(s): Atmospheric Sciences (A)Ocean Sciences (OS)Tectonophysics (T)","Non-linear effects in a spherical convection experiments with temperature dependent fluid properties: Microgravity experiment and numerical simulations","NG51D-1795","8:00 AM","8:00 AM","F.   Zaussinger*","F.   Zaussinger*; B.   Futterer; C.   Egbers","BTU Cottbus","withdrawn","","11"
